{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('91app_features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['memberid', 'online_ratio', 'total_day_using_percentage',\n",
       "       'actually_using_percentage', 'view_per_date', 'view_per_session',\n",
       "       'session_per_date', 'total_conversion_rate',\n",
       "       'converion_rate_without_offline_return', 'off_cart_c', 'off_fav_c',\n",
       "       'off_view_c', 'on_cart_c', 'on_fav_c', 'on_view_c', 'total_cart_c',\n",
       "       'total_fav_c', 'total_view_c', 'viewtime_ave', 'view_time_med',\n",
       "       '201803F', '201804F', '201805F', '201806F', '201807F', '201808F',\n",
       "       '201809F', '201810F', '201811F', '201812F', '201901F', '201902F',\n",
       "       '201903F', '201904F', '201803M', '201804M', '201805M', '201806M',\n",
       "       '201807M', '201808M', '201809M', '201810M', '201811M', '201812M',\n",
       "       '201901M', '201902M', '201903M', '201904M', '201803S', '201804S',\n",
       "       '201805S', '201806S', '201807S', '201808S', '201809S', '201810S',\n",
       "       '201811S', '201812S', '201901S', '201902S', '201903S', '201904S',\n",
       "       'total_F', 'total_M', 'total_S', 'ave_M', 'ave_M_not_offline_return',\n",
       "       'off_return_item_number', 'off_return_frequency',\n",
       "       'total_discount_percentage', 'online_ratio_without_offline_return',\n",
       "       'buy_time_without_offline_return', 'session_number', 'off_mix_c',\n",
       "       'on_mix_c', 'total_mix_c', 'cart_med_time', 'cart_ave_time',\n",
       "       'cart_within_3', 'cart_within_24', 'view_count_med', 'view_count_ave'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>memberid</th>\n",
       "      <th>online_ratio</th>\n",
       "      <th>total_day_using_percentage</th>\n",
       "      <th>actually_using_percentage</th>\n",
       "      <th>view_per_date</th>\n",
       "      <th>view_per_session</th>\n",
       "      <th>session_per_date</th>\n",
       "      <th>total_conversion_rate</th>\n",
       "      <th>converion_rate_without_offline_return</th>\n",
       "      <th>off_cart_c</th>\n",
       "      <th>...</th>\n",
       "      <th>session_number</th>\n",
       "      <th>off_mix_c</th>\n",
       "      <th>on_mix_c</th>\n",
       "      <th>total_mix_c</th>\n",
       "      <th>cart_med_time</th>\n",
       "      <th>cart_ave_time</th>\n",
       "      <th>cart_within_3</th>\n",
       "      <th>cart_within_24</th>\n",
       "      <th>view_count_med</th>\n",
       "      <th>view_count_ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022923</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027160</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>314792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>394660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>437828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>439730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>519517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>662692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>699538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>908710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>4.107143</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1021490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1033408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1047526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1088973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059946</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>3.590909</td>\n",
       "      <td>2.468750</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1150554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1177990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1210881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1223922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1257310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1257916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1260695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033573</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1266911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1346508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1385861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1387680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1423753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1425472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76371</th>\n",
       "      <td>58899632S3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062657</td>\n",
       "      <td>0.065274</td>\n",
       "      <td>23.480000</td>\n",
       "      <td>20.241379</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408560</td>\n",
       "      <td>0.408560</td>\n",
       "      <td>557.0</td>\n",
       "      <td>830.869565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76372</th>\n",
       "      <td>58899643S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>8.203704</td>\n",
       "      <td>5.034091</td>\n",
       "      <td>1.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76373</th>\n",
       "      <td>58899663S1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76374</th>\n",
       "      <td>58899682S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.110410</td>\n",
       "      <td>5.257143</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76375</th>\n",
       "      <td>58899732S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>3.068966</td>\n",
       "      <td>2.781250</td>\n",
       "      <td>1.103448</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76376</th>\n",
       "      <td>58899761S2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>0.089514</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>7.837838</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>1.054054</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76377</th>\n",
       "      <td>58899763S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76378</th>\n",
       "      <td>58899772S9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76379</th>\n",
       "      <td>58899784S0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.052493</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>8.958333</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533350</td>\n",
       "      <td>0.533350</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>7602.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76380</th>\n",
       "      <td>58899788S2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76381</th>\n",
       "      <td>58899795S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76382</th>\n",
       "      <td>58899867S9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>2.588235</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>152.0</td>\n",
       "      <td>454.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76383</th>\n",
       "      <td>58899873S0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154034</td>\n",
       "      <td>0.154034</td>\n",
       "      <td>10.349206</td>\n",
       "      <td>8.253165</td>\n",
       "      <td>1.253968</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>5598.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76384</th>\n",
       "      <td>58899904S1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.269122</td>\n",
       "      <td>1.305263</td>\n",
       "      <td>1.192308</td>\n",
       "      <td>1.094737</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76385</th>\n",
       "      <td>58899909S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182957</td>\n",
       "      <td>0.185279</td>\n",
       "      <td>6.315068</td>\n",
       "      <td>5.488095</td>\n",
       "      <td>1.150685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76386</th>\n",
       "      <td>58899968S3</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>7.160305</td>\n",
       "      <td>4.609337</td>\n",
       "      <td>1.553435</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>0.073710</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>407</td>\n",
       "      <td>0.092994</td>\n",
       "      <td>0.384025</td>\n",
       "      <td>0.148429</td>\n",
       "      <td>16547.0</td>\n",
       "      <td>22978.823529</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76387</th>\n",
       "      <td>635588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76388</th>\n",
       "      <td>9238639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76389</th>\n",
       "      <td>9387834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76390</th>\n",
       "      <td>9440111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76391</th>\n",
       "      <td>9444853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76392</th>\n",
       "      <td>9451359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76393</th>\n",
       "      <td>9456161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76394</th>\n",
       "      <td>9482145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76395</th>\n",
       "      <td>9491040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76396</th>\n",
       "      <td>9589297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76397</th>\n",
       "      <td>9594328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083135</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>4.542857</td>\n",
       "      <td>3.697674</td>\n",
       "      <td>1.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76398</th>\n",
       "      <td>9621833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76399</th>\n",
       "      <td>9637776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76400</th>\n",
       "      <td>9754589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76401 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         memberid  online_ratio  total_day_using_percentage  \\\n",
       "0           23722           NaN                    0.002849   \n",
       "1           44751           NaN                    0.022923   \n",
       "2           66732           NaN                    0.027160   \n",
       "3          108059           NaN                    0.003058   \n",
       "4          257559           NaN                    0.006061   \n",
       "5          314792           NaN                    0.006116   \n",
       "6          394660           NaN                    0.012019   \n",
       "7          437828           NaN                    0.002770   \n",
       "8          439730           NaN                    0.002817   \n",
       "9          519517           NaN                    0.002488   \n",
       "10         662692           NaN                    0.002941   \n",
       "11         699538           NaN                    0.003125   \n",
       "12         908710           NaN                    0.057279   \n",
       "13        1021490           NaN                    0.002410   \n",
       "14        1033408           NaN                    0.002695   \n",
       "15        1047526           NaN                    0.002469   \n",
       "16        1088973           NaN                    0.059946   \n",
       "17        1150554           NaN                    0.016627   \n",
       "18        1177990           NaN                    0.003257   \n",
       "19        1210881           NaN                    0.002545   \n",
       "20        1223922           NaN                    0.009639   \n",
       "21        1257310           NaN                    0.007481   \n",
       "22        1257916           NaN                    0.010309   \n",
       "23        1260695           NaN                    0.033573   \n",
       "24        1266911           NaN                    0.020460   \n",
       "25        1346508           NaN                    0.005076   \n",
       "26        1385861           NaN                    0.002849   \n",
       "27        1387680           NaN                    0.033981   \n",
       "28        1423753           NaN                    0.002421   \n",
       "29        1425472           NaN                    0.013405   \n",
       "...           ...           ...                         ...   \n",
       "76371  58899632S3      1.000000                    0.062657   \n",
       "76372  58899643S0           NaN                    0.580645   \n",
       "76373  58899663S1      0.000000                    0.027027   \n",
       "76374  58899682S0           NaN                    0.084746   \n",
       "76375  58899732S3      0.000000                    0.252174   \n",
       "76376  58899761S2      0.000000                    0.088161   \n",
       "76377  58899763S0           NaN                    0.026634   \n",
       "76378  58899772S9      0.000000                    0.004292   \n",
       "76379  58899784S0      1.000000                    0.050251   \n",
       "76380  58899788S2      0.000000                    0.085714   \n",
       "76381  58899795S3           NaN                    0.008403   \n",
       "76382  58899867S9      1.000000                    0.089552   \n",
       "76383  58899873S0      1.000000                    0.154034   \n",
       "76384  58899904S1      0.000000                    0.237500   \n",
       "76385  58899909S0           NaN                    0.182957   \n",
       "76386  58899968S3      0.129032                    0.655000   \n",
       "76387      635588           NaN                    0.005495   \n",
       "76388     9238639           NaN                    0.003077   \n",
       "76389     9387834           NaN                    0.009317   \n",
       "76390     9440111           NaN                    0.020050   \n",
       "76391     9444853           NaN                    0.003125   \n",
       "76392     9451359           NaN                    0.026316   \n",
       "76393     9456161           NaN                    0.029484   \n",
       "76394     9482145           NaN                    0.013441   \n",
       "76395     9491040           NaN                    0.026634   \n",
       "76396     9589297           NaN                    0.005128   \n",
       "76397     9594328           NaN                    0.083135   \n",
       "76398     9621833           NaN                    0.013193   \n",
       "76399     9637776           NaN                    0.018182   \n",
       "76400     9754589           NaN                    0.005970   \n",
       "\n",
       "       actually_using_percentage  view_per_date  view_per_session  \\\n",
       "0                       1.000000       1.000000          1.000000   \n",
       "1                       0.026846       3.875000          2.583333   \n",
       "2                       0.108911       4.363636          4.000000   \n",
       "3                       1.000000       2.000000          2.000000   \n",
       "4                       0.250000       1.500000          1.500000   \n",
       "5                       0.016529       1.000000          1.000000   \n",
       "6                       0.016129       1.600000          1.600000   \n",
       "7                       1.000000       1.000000          1.000000   \n",
       "8                       1.000000       3.000000          1.500000   \n",
       "9                       1.000000       4.000000          4.000000   \n",
       "10                      1.000000       4.000000          4.000000   \n",
       "11                      1.000000       5.000000          5.000000   \n",
       "12                      0.068182       4.791667          4.107143   \n",
       "13                      1.000000       1.000000          1.000000   \n",
       "14                      1.000000       1.000000          1.000000   \n",
       "15                      1.000000       1.000000          1.000000   \n",
       "16                      0.261905       3.590909          2.468750   \n",
       "17                      0.122807       2.285714          2.285714   \n",
       "18                      1.000000       3.000000          3.000000   \n",
       "19                      1.000000       1.000000          1.000000   \n",
       "20                      0.040816       4.000000          3.200000   \n",
       "21                      0.076923       1.333333          1.333333   \n",
       "22                      0.072727       2.750000          2.750000   \n",
       "23                      0.264151       4.857143          4.250000   \n",
       "24                      0.093023       4.375000          3.888889   \n",
       "25                      0.038462       2.000000          1.333333   \n",
       "26                      1.000000       3.000000          3.000000   \n",
       "27                      0.038462       2.142857          2.142857   \n",
       "28                      1.000000       1.000000          1.000000   \n",
       "29                      0.121951       2.800000          2.333333   \n",
       "...                          ...            ...               ...   \n",
       "76371                   0.065274      23.480000         20.241379   \n",
       "76372                   0.586957       8.203704          5.034091   \n",
       "76373                   0.030769       1.500000          1.500000   \n",
       "76374                   0.110410       5.257143          4.600000   \n",
       "76375                   0.252174       3.068966          2.781250   \n",
       "76376                   0.089514       8.285714          7.837838   \n",
       "76377                   0.177419       6.090909          6.090909   \n",
       "76378                   1.000000       1.000000          1.000000   \n",
       "76379                   0.052493      10.750000          8.958333   \n",
       "76380                   0.187500       1.666667          1.666667   \n",
       "76381                   0.035714       3.000000          3.000000   \n",
       "76382                   0.094937       2.933333          2.588235   \n",
       "76383                   0.154034      10.349206          8.253165   \n",
       "76384                   0.269122       1.305263          1.192308   \n",
       "76385                   0.185279       6.315068          5.488095   \n",
       "76386                   0.655000       7.160305          4.609337   \n",
       "76387                   0.034483       5.500000          5.500000   \n",
       "76388                   1.000000       4.000000          4.000000   \n",
       "76389                   0.018072       5.333333          5.333333   \n",
       "76390                   0.020888       1.625000          1.625000   \n",
       "76391                   1.000000       2.000000          2.000000   \n",
       "76392                   0.057895       2.636364          2.636364   \n",
       "76393                   0.110092       5.166667          3.444444   \n",
       "76394                   0.059524       3.600000          3.600000   \n",
       "76395                   0.103774       3.000000          2.200000   \n",
       "76396                   0.058824       1.000000          1.000000   \n",
       "76397                   0.330189       4.542857          3.697674   \n",
       "76398                   0.094340       1.200000          1.000000   \n",
       "76399                   0.055046       4.833333          3.625000   \n",
       "76400                   0.125000       2.000000          1.333333   \n",
       "\n",
       "       session_per_date  total_conversion_rate  \\\n",
       "0              1.000000               0.000000   \n",
       "1              1.500000               0.000000   \n",
       "2              1.090909               0.000000   \n",
       "3              1.000000               0.000000   \n",
       "4              1.000000               0.000000   \n",
       "5              1.000000               0.000000   \n",
       "6              1.000000               0.000000   \n",
       "7              1.000000               0.000000   \n",
       "8              2.000000               0.000000   \n",
       "9              1.000000               0.000000   \n",
       "10             1.000000               0.000000   \n",
       "11             1.000000               0.000000   \n",
       "12             1.166667               0.000000   \n",
       "13             1.000000               0.000000   \n",
       "14             1.000000               0.000000   \n",
       "15             1.000000               0.000000   \n",
       "16             1.454545               0.000000   \n",
       "17             1.000000               0.000000   \n",
       "18             1.000000               0.000000   \n",
       "19             1.000000               0.000000   \n",
       "20             1.250000               0.000000   \n",
       "21             1.000000               0.000000   \n",
       "22             1.000000               0.000000   \n",
       "23             1.142857               0.000000   \n",
       "24             1.125000               0.000000   \n",
       "25             1.500000               0.000000   \n",
       "26             1.000000               0.000000   \n",
       "27             1.000000               0.000000   \n",
       "28             1.000000               0.000000   \n",
       "29             1.200000               0.000000   \n",
       "...                 ...                    ...   \n",
       "76371          1.160000               0.172414   \n",
       "76372          1.629630               0.000000   \n",
       "76373          1.000000               0.500000   \n",
       "76374          1.142857               0.000000   \n",
       "76375          1.103448               0.031250   \n",
       "76376          1.057143               1.054054   \n",
       "76377          1.000000               0.000000   \n",
       "76378          1.000000               1.000000   \n",
       "76379          1.200000               0.083333   \n",
       "76380          1.000000               0.666667   \n",
       "76381          1.000000               0.000000   \n",
       "76382          1.133333               0.029412   \n",
       "76383          1.253968               0.012658   \n",
       "76384          1.094737               0.009615   \n",
       "76385          1.150685               0.000000   \n",
       "76386          1.553435               0.076167   \n",
       "76387          1.000000               0.000000   \n",
       "76388          1.000000               0.000000   \n",
       "76389          1.000000               0.000000   \n",
       "76390          1.000000               0.000000   \n",
       "76391          1.000000               0.000000   \n",
       "76392          1.000000               0.000000   \n",
       "76393          1.500000               0.000000   \n",
       "76394          1.000000               0.000000   \n",
       "76395          1.363636               0.000000   \n",
       "76396          1.000000               0.000000   \n",
       "76397          1.228571               0.000000   \n",
       "76398          1.200000               0.000000   \n",
       "76399          1.333333               0.000000   \n",
       "76400          1.500000               0.000000   \n",
       "\n",
       "       converion_rate_without_offline_return  off_cart_c  ...  session_number  \\\n",
       "0                                   0.000000         NaN  ...               1   \n",
       "1                                   0.000000         NaN  ...              12   \n",
       "2                                   0.000000         NaN  ...              12   \n",
       "3                                   0.000000         NaN  ...               1   \n",
       "4                                   0.000000         NaN  ...               2   \n",
       "5                                   0.000000         NaN  ...               2   \n",
       "6                                   0.000000         NaN  ...               5   \n",
       "7                                   0.000000         NaN  ...               1   \n",
       "8                                   0.000000         NaN  ...               2   \n",
       "9                                   0.000000         NaN  ...               1   \n",
       "10                                  0.000000         NaN  ...               1   \n",
       "11                                  0.000000         NaN  ...               1   \n",
       "12                                  0.000000         NaN  ...              28   \n",
       "13                                  0.000000         NaN  ...               1   \n",
       "14                                  0.000000         NaN  ...               1   \n",
       "15                                  0.000000         NaN  ...               1   \n",
       "16                                  0.000000         NaN  ...              32   \n",
       "17                                  0.000000         NaN  ...               7   \n",
       "18                                  0.000000         NaN  ...               1   \n",
       "19                                  0.000000         NaN  ...               1   \n",
       "20                                  0.000000         NaN  ...               5   \n",
       "21                                  0.000000         NaN  ...               3   \n",
       "22                                  0.000000         NaN  ...               4   \n",
       "23                                  0.000000         NaN  ...              16   \n",
       "24                                  0.000000         NaN  ...               9   \n",
       "25                                  0.000000         NaN  ...               3   \n",
       "26                                  0.000000         NaN  ...               1   \n",
       "27                                  0.000000         NaN  ...              14   \n",
       "28                                  0.000000         NaN  ...               1   \n",
       "29                                  0.000000         NaN  ...               6   \n",
       "...                                      ...         ...  ...             ...   \n",
       "76371                               0.172414         NaN  ...              29   \n",
       "76372                               0.000000         NaN  ...              88   \n",
       "76373                               0.500000         NaN  ...               2   \n",
       "76374                               0.000000         NaN  ...              40   \n",
       "76375                               0.031250         NaN  ...              32   \n",
       "76376                               0.783784         NaN  ...              37   \n",
       "76377                               0.000000         NaN  ...              11   \n",
       "76378                               0.000000         NaN  ...               1   \n",
       "76379                               0.083333         NaN  ...              24   \n",
       "76380                               0.666667         NaN  ...               3   \n",
       "76381                               0.000000         NaN  ...               2   \n",
       "76382                               0.029412         NaN  ...              34   \n",
       "76383                               0.012658         NaN  ...              79   \n",
       "76384                               0.009615         NaN  ...             104   \n",
       "76385                               0.000000         NaN  ...              84   \n",
       "76386                               0.073710    0.142857  ...             407   \n",
       "76387                               0.000000         NaN  ...               2   \n",
       "76388                               0.000000         NaN  ...               1   \n",
       "76389                               0.000000         NaN  ...               3   \n",
       "76390                               0.000000         NaN  ...               8   \n",
       "76391                               0.000000         NaN  ...               1   \n",
       "76392                               0.000000         NaN  ...              11   \n",
       "76393                               0.000000         NaN  ...              18   \n",
       "76394                               0.000000         NaN  ...               5   \n",
       "76395                               0.000000         NaN  ...              15   \n",
       "76396                               0.000000         NaN  ...               2   \n",
       "76397                               0.000000         NaN  ...              43   \n",
       "76398                               0.000000         NaN  ...               6   \n",
       "76399                               0.000000         NaN  ...               8   \n",
       "76400                               0.000000         NaN  ...               3   \n",
       "\n",
       "       off_mix_c  on_mix_c  total_mix_c  cart_med_time  cart_ave_time  \\\n",
       "0            NaN       NaN          NaN            NaN            NaN   \n",
       "1            NaN       NaN          NaN            NaN            NaN   \n",
       "2            NaN       NaN          NaN            NaN            NaN   \n",
       "3            NaN       NaN          NaN            NaN            NaN   \n",
       "4            NaN       NaN          NaN            NaN            NaN   \n",
       "5            NaN       NaN          NaN            NaN            NaN   \n",
       "6            NaN       NaN          NaN            NaN            NaN   \n",
       "7            NaN       NaN          NaN            NaN            NaN   \n",
       "8            NaN       NaN          NaN            NaN            NaN   \n",
       "9            NaN       NaN          NaN            NaN            NaN   \n",
       "10           NaN       NaN          NaN            NaN            NaN   \n",
       "11           NaN       NaN          NaN            NaN            NaN   \n",
       "12           NaN       NaN          NaN            NaN            NaN   \n",
       "13           NaN       NaN          NaN            NaN            NaN   \n",
       "14           NaN       NaN          NaN            NaN            NaN   \n",
       "15           NaN       NaN          NaN            NaN            NaN   \n",
       "16           NaN       NaN          NaN            NaN            NaN   \n",
       "17           NaN       NaN          NaN            NaN            NaN   \n",
       "18           NaN       NaN          NaN            NaN            NaN   \n",
       "19           NaN       NaN          NaN            NaN            NaN   \n",
       "20           NaN       NaN          NaN            NaN            NaN   \n",
       "21           NaN       NaN          NaN            NaN            NaN   \n",
       "22           NaN       NaN          NaN            NaN            NaN   \n",
       "23           NaN       NaN          NaN            NaN            NaN   \n",
       "24           NaN       NaN          NaN            NaN            NaN   \n",
       "25           NaN       NaN          NaN            NaN            NaN   \n",
       "26           NaN       NaN          NaN            NaN            NaN   \n",
       "27           NaN       NaN          NaN            NaN            NaN   \n",
       "28           NaN       NaN          NaN            NaN            NaN   \n",
       "29           NaN       NaN          NaN            NaN            NaN   \n",
       "...          ...       ...          ...            ...            ...   \n",
       "76371        NaN  0.408560     0.408560          557.0     830.869565   \n",
       "76372        NaN       NaN          NaN            NaN            NaN   \n",
       "76373   0.000000       NaN     0.000000            NaN            NaN   \n",
       "76374        NaN       NaN          NaN            NaN            NaN   \n",
       "76375        NaN       NaN          NaN            NaN            NaN   \n",
       "76376        NaN       NaN          NaN            NaN            NaN   \n",
       "76377        NaN       NaN          NaN            NaN            NaN   \n",
       "76378        NaN       NaN          NaN            NaN            NaN   \n",
       "76379        NaN  0.533350     0.533350         1064.0    7602.500000   \n",
       "76380        NaN       NaN          NaN            NaN            NaN   \n",
       "76381        NaN       NaN          NaN            NaN            NaN   \n",
       "76382        NaN  0.750000     0.750000          152.0     454.666667   \n",
       "76383        NaN  0.400000     0.400000         5598.0    5598.000000   \n",
       "76384        NaN       NaN          NaN            NaN            NaN   \n",
       "76385        NaN       NaN          NaN            NaN            NaN   \n",
       "76386   0.092994  0.384025     0.148429        16547.0   22978.823529   \n",
       "76387        NaN       NaN          NaN            NaN            NaN   \n",
       "76388        NaN       NaN          NaN            NaN            NaN   \n",
       "76389        NaN       NaN          NaN            NaN            NaN   \n",
       "76390        NaN       NaN          NaN            NaN            NaN   \n",
       "76391        NaN       NaN          NaN            NaN            NaN   \n",
       "76392        NaN       NaN          NaN            NaN            NaN   \n",
       "76393        NaN       NaN          NaN            NaN            NaN   \n",
       "76394        NaN       NaN          NaN            NaN            NaN   \n",
       "76395        NaN       NaN          NaN            NaN            NaN   \n",
       "76396        NaN       NaN          NaN            NaN            NaN   \n",
       "76397        NaN       NaN          NaN            NaN            NaN   \n",
       "76398        NaN       NaN          NaN            NaN            NaN   \n",
       "76399        NaN       NaN          NaN            NaN            NaN   \n",
       "76400        NaN       NaN          NaN            NaN            NaN   \n",
       "\n",
       "       cart_within_3  cart_within_24  view_count_med  view_count_ave  \n",
       "0                NaN             NaN             NaN             NaN  \n",
       "1                NaN             NaN             NaN             NaN  \n",
       "2                NaN             NaN             NaN             NaN  \n",
       "3                NaN             NaN             NaN             NaN  \n",
       "4                NaN             NaN             NaN             NaN  \n",
       "5                NaN             NaN             NaN             NaN  \n",
       "6                NaN             NaN             NaN             NaN  \n",
       "7                NaN             NaN             NaN             NaN  \n",
       "8                NaN             NaN             NaN             NaN  \n",
       "9                NaN             NaN             NaN             NaN  \n",
       "10               NaN             NaN             NaN             NaN  \n",
       "11               NaN             NaN             NaN             NaN  \n",
       "12               NaN             NaN             NaN             NaN  \n",
       "13               NaN             NaN             NaN             NaN  \n",
       "14               NaN             NaN             NaN             NaN  \n",
       "15               NaN             NaN             NaN             NaN  \n",
       "16               NaN             NaN             NaN             NaN  \n",
       "17               NaN             NaN             NaN             NaN  \n",
       "18               NaN             NaN             NaN             NaN  \n",
       "19               NaN             NaN             NaN             NaN  \n",
       "20               NaN             NaN             NaN             NaN  \n",
       "21               NaN             NaN             NaN             NaN  \n",
       "22               NaN             NaN             NaN             NaN  \n",
       "23               NaN             NaN             NaN             NaN  \n",
       "24               NaN             NaN             NaN             NaN  \n",
       "25               NaN             NaN             NaN             NaN  \n",
       "26               NaN             NaN             NaN             NaN  \n",
       "27               NaN             NaN             NaN             NaN  \n",
       "28               NaN             NaN             NaN             NaN  \n",
       "29               NaN             NaN             NaN             NaN  \n",
       "...              ...             ...             ...             ...  \n",
       "76371       1.000000             1.0             1.0        1.636364  \n",
       "76372            NaN             NaN             NaN             NaN  \n",
       "76373            NaN             NaN             NaN             NaN  \n",
       "76374            NaN             NaN             NaN             NaN  \n",
       "76375            NaN             NaN             NaN             NaN  \n",
       "76376            NaN             NaN             1.0        1.200000  \n",
       "76377            NaN             NaN             NaN             NaN  \n",
       "76378            NaN             NaN             NaN             NaN  \n",
       "76379       0.750000             1.0             2.0        2.200000  \n",
       "76380            NaN             NaN             NaN             NaN  \n",
       "76381            NaN             NaN             NaN             NaN  \n",
       "76382       1.000000             1.0             2.0        1.666667  \n",
       "76383       1.000000             1.0             2.5        2.500000  \n",
       "76384            NaN             NaN             NaN             NaN  \n",
       "76385            NaN             NaN             NaN             NaN  \n",
       "76386       0.470588             1.0             2.0        2.619048  \n",
       "76387            NaN             NaN             NaN             NaN  \n",
       "76388            NaN             NaN             NaN             NaN  \n",
       "76389            NaN             NaN             NaN             NaN  \n",
       "76390            NaN             NaN             NaN             NaN  \n",
       "76391            NaN             NaN             NaN             NaN  \n",
       "76392            NaN             NaN             NaN             NaN  \n",
       "76393            NaN             NaN             NaN             NaN  \n",
       "76394            NaN             NaN             NaN             NaN  \n",
       "76395            NaN             NaN             NaN             NaN  \n",
       "76396            NaN             NaN             NaN             NaN  \n",
       "76397            NaN             NaN             NaN             NaN  \n",
       "76398            NaN             NaN             NaN             NaN  \n",
       "76399            NaN             NaN             NaN             NaN  \n",
       "76400            NaN             NaN             NaN             NaN  \n",
       "\n",
       "[76401 rows x 82 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76401, 82)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18015.0\n",
       "mean         1.0\n",
       "std          0.0\n",
       "min          1.0\n",
       "25%          1.0\n",
       "50%          1.0\n",
       "75%          1.0\n",
       "max          1.0\n",
       "Name: cart_within_24, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cart_within_24'].describe() #我的天啊 全部都是一天內都會購買"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inactive users are those whose total_day_using_percentage < 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inactive = df[df['total_day_using_percentage'] < 0.02]\n",
    "df_active =   df[~(df['total_day_using_percentage'] < 0.02)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25676, 50725)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inactive.shape[0], df_active.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# offline buyer are those who purchases only offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_never_buy = df_active[df_active['online_ratio'].isnull()]\n",
    "df_buy = df_active[~df_active['online_ratio'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14429, 82), (36296, 82))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_never_buy.shape, df_buy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_percentile(df, keyword, n):\n",
    "    a_list = df[keyword].tolist()\n",
    "    null_df = df[df[keyword].isnull()]\n",
    "    remaining_df = df[~df[keyword].isnull()]\n",
    "    return_list = []\n",
    "    number_list = []\n",
    "    for i in range(1, n):\n",
    "        number = np.nanpercentile(a_list, int(100/n*i) )\n",
    "        number_list.append(number)\n",
    "        a_df = remaining_df[ remaining_df[keyword] <= number]\n",
    "        remaining_df = remaining_df[~ (remaining_df[keyword] <= number)]      \n",
    "        return_list.append(a_df)\n",
    "    return_list.append(remaining_df)\n",
    "    return return_list, number_list, null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_buy[df_buy['online_ratio_without_offline_return'] <= 0.2]\n",
    "df2 = df_buy[df_buy['online_ratio_without_offline_return'] > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_drop = df_buy[df_buy['online_ratio_without_offline_return'].isnull()] #因為他們只在線下退換貨記錄 沒買過東西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21804, 13535, 957)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape[0] , df2.shape[0], df_drop.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_rate(df1, df2, key_word):\n",
    "    \n",
    "    newdf1, newdf2 = df1[~df1[key_word].isnull()],  df2[~df2[key_word].isnull()]\n",
    "    n1, n2 = newdf1.shape[0] , newdf2.shape[0]\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return (0,0)\n",
    "    \n",
    "    m1, m2 = np.nanmean( newdf1[key_word].tolist() ), np.nanmean( newdf2[key_word].tolist() )\n",
    "    s1, s2 = np.nanstd(newdf1[key_word].tolist()), np.nanstd(newdf2[key_word].tolist())\n",
    "    differnce = m1 - m2\n",
    "    \n",
    "    sp2 = ((n1-1)*(s1**2) + (n2-1)*(s2**2)) / (n1+n2-2)\n",
    "    t = differnce / sqrt(sp2 * (1/n1+1/n2))\n",
    "    return differnce, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_important_difference(df1, df2):\n",
    "    for key_word in ['converion_rate_without_offline_return', 'total_conversion_rate','ave_M', 'ave_M_not_offline_return', 'total_M', 'total_F', 'total_S', 'session_number', 'buy_time_without_offline_return','total_day_using_percentage', 'actually_using_percentage', 'view_per_date', 'view_per_session',\n",
    "       'session_per_date', 'off_return_item_number', 'off_return_frequency', \n",
    "       'off_cart_c', 'off_fav_c', 'off_view_c', 'on_cart_c', 'on_fav_c',\n",
    "       'on_view_c', 'total_cart_c', 'total_fav_c', 'total_view_c',\n",
    "       'viewtime_ave', 'view_time_med', 'total_discount_percentage', 'online_ratio', 'online_ratio_without_offline_return', 'off_mix_c',\n",
    "       'on_mix_c', 'total_mix_c', 'cart_med_time', 'cart_ave_time',\n",
    "       'cart_within_3', 'cart_within_24', 'view_count_med', 'view_count_ave']:\n",
    "        differnce, t = difference_in_rate(df1, df2, key_word)\n",
    "        if abs( t ) > 1.96:\n",
    "            print(key_word, round(differnce, 4)  )\n",
    "        elif  abs( t ) >= 1.5:\n",
    "            print(key_word, round(differnce, 4) ,  'Not so significant' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_important_difference_all(df1, df2):\n",
    "    for key_word in ['converion_rate_without_offline_return', 'total_conversion_rate','ave_M', 'ave_M_not_offline_return', 'total_M', 'total_F', 'total_S', 'session_number', 'buy_time_without_offline_return','total_day_using_percentage', 'actually_using_percentage', 'view_per_date', 'view_per_session',\n",
    "       'session_per_date', 'off_return_item_number', 'off_return_frequency', \n",
    "       'off_cart_c', 'off_fav_c', 'off_view_c', 'on_cart_c', 'on_fav_c',\n",
    "       'on_view_c', 'total_cart_c', 'total_fav_c', 'total_view_c',\n",
    "       'viewtime_ave', 'view_time_med', 'total_discount_percentage', 'online_ratio', 'online_ratio_without_offline_return', 'off_mix_c',\n",
    "       'on_mix_c', 'total_mix_c', 'cart_med_time', 'cart_ave_time',\n",
    "       'cart_within_3', 'cart_within_24', 'view_count_med', 'view_count_ave']:\n",
    "        differnce, t = difference_in_rate(df1, df2, key_word)\n",
    "        if abs( t ) > 1.96:\n",
    "            print(key_word, round(differnce, 4)  )\n",
    "        elif  abs( t ) >= 1.5:\n",
    "            print(key_word, round(differnce, 4) ,  'Not so significant' )\n",
    "        else:\n",
    "            print(key_word, round(differnce, 4) ,  'Not significant' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.2258\n",
      "total_conversion_rate 0.2625\n",
      "ave_M 630.057\n",
      "ave_M_not_offline_return 832.6407\n",
      "total_M 2723.1448\n",
      "total_F 0.5703\n",
      "total_S -328.0011\n",
      "session_number -51.5379\n",
      "buy_time_without_offline_return 0.1441\n",
      "total_day_using_percentage -0.0577\n",
      "actually_using_percentage 0.0179\n",
      "view_per_date -2.8865\n",
      "view_per_session -1.8229\n",
      "session_per_date -0.1354\n",
      "off_return_item_number 0.4775\n",
      "off_return_frequency 0.4262\n",
      "off_fav_c -0.0124\n",
      "on_cart_c 0.1322\n",
      "on_fav_c 0.0727\n",
      "on_view_c 0.0728\n",
      "total_cart_c -0.3243\n",
      "total_fav_c -0.0782\n",
      "total_view_c -0.0655\n",
      "viewtime_ave 3.2647\n",
      "view_time_med 4.8789\n",
      "total_discount_percentage 0.005\n",
      "online_ratio -0.7815\n",
      "online_ratio_without_offline_return -0.7942\n",
      "off_mix_c -0.0126\n",
      "on_mix_c 0.1167\n",
      "total_mix_c -0.3285\n",
      "cart_med_time 18718.0155\n",
      "cart_ave_time 17068.7963\n",
      "cart_within_3 -0.3195\n",
      "view_count_med -0.9525\n",
      "view_count_ave -1.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df1是 offline, df2 是online, df3, df4, df5 依照view conversion rate劃分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008075642857142872, 0.0656, '此可看出要把inactive user分開的重要性')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(df['total_view_c'], 33), np.nanpercentile(df['total_view_c'], 67), '此可看出要把inactive user分開的重要性'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df3, df4, df5], number_list2, null_df2 = split_by_percentile(df2, 'total_view_c', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4497, 82), (4421, 82), (4594, 82), [0.04, 0.09555259999999999], (23, 82))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape , df4.shape , df5.shape  , number_list2, null_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.1043\n",
      "total_conversion_rate -0.1078\n",
      "ave_M -316.056\n",
      "ave_M_not_offline_return -317.1675\n",
      "total_M -4518.1208\n",
      "total_F -0.9893\n",
      "total_S 435.5347\n",
      "session_number 67.5933\n",
      "buy_time_without_offline_return -0.9743\n",
      "total_day_using_percentage 0.0985\n",
      "actually_using_percentage 0.0567\n",
      "view_per_date 1.8443\n",
      "view_per_session 0.9569\n",
      "session_per_date 0.0941\n",
      "off_cart_c -0.0934\n",
      "off_fav_c -0.0512\n",
      "off_view_c -0.0967\n",
      "on_cart_c -0.3215\n",
      "on_fav_c -0.1361\n",
      "on_view_c -0.2512\n",
      "total_cart_c -0.3291\n",
      "total_fav_c -0.125\n",
      "total_view_c -0.2323\n",
      "viewtime_ave -7.8972\n",
      "view_time_med -8.1997\n",
      "total_discount_percentage 0.0116\n",
      "online_ratio -0.0537\n",
      "online_ratio_without_offline_return -0.0511\n",
      "off_mix_c -0.0932\n",
      "on_mix_c -0.365\n",
      "total_mix_c -0.3653\n",
      "cart_med_time 4810.1133\n",
      "cart_ave_time 4471.6021\n",
      "cart_within_3 -0.0899\n",
      "view_count_med 1.6264\n",
      "view_count_ave 1.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df3, df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.0208\n",
      "total_conversion_rate -0.0213\n",
      "ave_M -303.9562\n",
      "ave_M_not_offline_return -300.196\n",
      "total_M -4801.0222\n",
      "total_F -1.3039\n",
      "total_S 192.4816\n",
      "session_number 24.6455\n",
      "buy_time_without_offline_return -1.2486\n",
      "total_day_using_percentage 0.0356\n",
      "actually_using_percentage 0.031\n",
      "view_per_date 0.839\n",
      "view_per_session 0.472\n",
      "session_per_date 0.029\n",
      "off_return_item_number -0.0638\n",
      "off_return_frequency -0.0553\n",
      "off_cart_c -0.0534\n",
      "off_fav_c -0.048\n",
      "off_view_c -0.0276\n",
      "on_cart_c -0.1508\n",
      "on_fav_c -0.0572\n",
      "on_view_c -0.046\n",
      "total_cart_c -0.1476\n",
      "total_fav_c -0.053\n",
      "total_view_c -0.0416\n",
      "viewtime_ave -2.0993\n",
      "view_time_med -1.7038\n",
      "total_discount_percentage 0.0076\n",
      "online_ratio -0.0195\n",
      "online_ratio_without_offline_return -0.0183\n",
      "off_mix_c -0.0517\n",
      "on_mix_c -0.1618\n",
      "total_mix_c -0.1554\n",
      "cart_med_time 2244.8885\n",
      "cart_ave_time 1182.0008\n",
      "cart_within_3 -0.0218\n",
      "view_count_med 0.9568\n",
      "view_count_ave 0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df3, df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.0835\n",
      "total_conversion_rate -0.0865\n",
      "total_F 0.3146\n",
      "total_S 243.0531\n",
      "session_number 42.9478\n",
      "buy_time_without_offline_return 0.2743\n",
      "total_day_using_percentage 0.0629\n",
      "actually_using_percentage 0.0257\n",
      "view_per_date 1.0054\n",
      "view_per_session 0.4849\n",
      "session_per_date 0.0651\n",
      "off_return_item_number 0.0404\n",
      "off_return_frequency 0.0403\n",
      "off_cart_c -0.04\n",
      "off_view_c -0.0691\n",
      "on_cart_c -0.1708\n",
      "on_fav_c -0.0789\n",
      "on_view_c -0.2053\n",
      "total_cart_c -0.1815\n",
      "total_fav_c -0.072\n",
      "total_view_c -0.1907\n",
      "viewtime_ave -5.7978\n",
      "view_time_med -6.4958\n",
      "total_discount_percentage 0.004\n",
      "online_ratio -0.0342\n",
      "online_ratio_without_offline_return -0.0328\n",
      "off_mix_c -0.0415\n",
      "on_mix_c -0.2032\n",
      "total_mix_c -0.2099\n",
      "cart_med_time 2565.2249\n",
      "cart_ave_time 3289.6013\n",
      "cart_within_3 -0.0681\n",
      "view_count_med 0.6696\n",
      "view_count_ave 0.7415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df4, df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可得知，用view_conversion_rate分群之後，df3為深思熟慮型, df5為衝動購物型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRICE 敏感者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = df['ave_M']\n",
    "X = df['total_discount_percentage']\n",
    "T = np.arctan2(Y,X) # for color value\n",
    "plt.scatter(X, Y, s=75,c=T, alpha=.5)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = df['total_M']\n",
    "X = df['total_discount_percentage']\n",
    "T = np.arctan2(Y,X) # for color value\n",
    "plt.scatter(X, Y, s=75,c=T, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 想看一下price_sensitive 對各個group的影響"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_the_effect_of_price_sensitive(df, p = 0.1):\n",
    "    other_sensitive = df[df['total_discount_percentage'] >=p]\n",
    "    other_normal = df[df['total_discount_percentage'] < p]\n",
    "    print( find_important_difference(other_sensitive, other_normal) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.067\n",
      "total_conversion_rate -0.0782\n",
      "ave_M -1048.197\n",
      "ave_M_not_offline_return -1202.288\n",
      "total_M -6578.1091\n",
      "total_F -1.0153\n",
      "total_S 11.8281 Not so significant\n",
      "session_number 4.6849\n",
      "buy_time_without_offline_return -0.8703\n",
      "total_day_using_percentage -0.0094\n",
      "actually_using_percentage -0.0183\n",
      "view_per_session -0.1097 Not so significant\n",
      "session_per_date 0.028\n",
      "off_return_item_number -0.1845\n",
      "off_return_frequency -0.145\n",
      "off_cart_c -0.0345\n",
      "off_view_c -0.0094\n",
      "on_view_c -0.0418 Not so significant\n",
      "total_cart_c -0.0684\n",
      "total_view_c -0.0109\n",
      "viewtime_ave 3.4797\n",
      "view_time_med 1.5904 Not so significant\n",
      "total_discount_percentage 0.1531\n",
      "off_mix_c -0.0267\n",
      "total_mix_c -0.0479\n",
      "cart_med_time 2380.7779 Not so significant\n",
      "cart_within_3 -0.0528\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_M -669.1478\n",
      "ave_M_not_offline_return -701.3459\n",
      "total_M -2017.8737\n",
      "total_S -58.4754 Not so significant\n",
      "view_per_date -0.3405 Not so significant\n",
      "view_per_session -0.2684 Not so significant\n",
      "total_view_c -0.0008 Not so significant\n",
      "viewtime_ave 2.3555\n",
      "total_discount_percentage 0.1492\n",
      "online_ratio -0.0581\n",
      "online_ratio_without_offline_return -0.051\n",
      "total_mix_c -0.0227\n",
      "cart_med_time -1192.3344 Not so significant\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.0056 Not so significant\n",
      "total_conversion_rate 0.0076\n",
      "ave_M -816.5092\n",
      "ave_M_not_offline_return -843.6505\n",
      "total_M -4908.5528\n",
      "total_F -0.4268 Not so significant\n",
      "total_S -84.8243\n",
      "session_number -7.9026 Not so significant\n",
      "buy_time_without_offline_return -0.4957\n",
      "total_day_using_percentage -0.0136 Not so significant\n",
      "view_per_date -0.6497\n",
      "view_per_session -0.3108\n",
      "session_per_date -0.0344\n",
      "off_return_item_number 0.0812 Not so significant\n",
      "off_return_frequency 0.0689 Not so significant\n",
      "total_cart_c -0.0209 Not so significant\n",
      "total_view_c -0.0014\n",
      "total_discount_percentage 0.1467\n",
      "online_ratio -0.0748\n",
      "online_ratio_without_offline_return -0.0655\n",
      "on_mix_c -0.037\n",
      "total_mix_c -0.0476\n",
      "cart_within_3 0.0237 Not so significant\n",
      "view_count_med 0.1968 Not so significant\n",
      "view_count_ave 0.1887 Not so significant\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.0359\n",
      "total_conversion_rate 0.0369\n",
      "ave_M -966.7364\n",
      "ave_M_not_offline_return -998.4339\n",
      "total_M -6749.0223\n",
      "total_F -1.1052\n",
      "total_S -57.7643\n",
      "session_number -7.248\n",
      "buy_time_without_offline_return -1.1005\n",
      "actually_using_percentage 0.0303\n",
      "view_per_date -0.6943\n",
      "view_per_session -0.3976\n",
      "session_per_date -0.038\n",
      "off_fav_c -0.0585\n",
      "on_cart_c 0.0268\n",
      "on_view_c 0.0758\n",
      "total_view_c 0.0679\n",
      "view_time_med 2.5592 Not so significant\n",
      "total_discount_percentage 0.1431\n",
      "online_ratio -0.0356\n",
      "online_ratio_without_offline_return -0.023 Not so significant\n",
      "cart_ave_time -1037.6839 Not so significant\n",
      "cart_within_3 0.0227 Not so significant\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 價格敏感的(大於4.6%折扣比率)的衝動購買者，他們看的次數比較多(卻轉換率也比較高)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 價格敏感的衝動購買者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045875397739231646"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(df5['total_discount_percentage'], 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.0354\n",
      "total_conversion_rate 0.0384\n",
      "ave_M -624.7669\n",
      "ave_M_not_offline_return -626.6557\n",
      "total_M 2938.3914\n",
      "total_F 1.8225\n",
      "total_S 87.5151\n",
      "session_number 16.6812\n",
      "buy_time_without_offline_return 1.657\n",
      "total_day_using_percentage 0.0359\n",
      "actually_using_percentage 0.0548\n",
      "view_per_date -0.2244 Not so significant\n",
      "view_per_session -0.2247 Not so significant\n",
      "session_per_date 0.0071 Not significant\n",
      "off_return_item_number 0.1727\n",
      "off_return_frequency 0.1655\n",
      "off_cart_c -0.0003 Not significant\n",
      "off_fav_c -0.0387 Not so significant\n",
      "off_view_c -0.0097 Not significant\n",
      "on_cart_c -0.0071 Not significant\n",
      "on_fav_c -0.0173 Not significant\n",
      "on_view_c 0.0494\n",
      "total_cart_c -0.0239\n",
      "total_fav_c -0.0264 Not so significant\n",
      "total_view_c 0.0331\n",
      "viewtime_ave 3.2129\n",
      "view_time_med 2.0852\n",
      "total_discount_percentage 0.0903\n",
      "online_ratio -0.1099\n",
      "online_ratio_without_offline_return -0.1004\n",
      "off_mix_c -0.0218 Not significant\n",
      "on_mix_c -0.0289\n",
      "total_mix_c -0.0502\n",
      "cart_med_time -561.7518 Not significant\n",
      "cart_ave_time -53.3865 Not significant\n",
      "cart_within_3 -0.0039 Not significant\n",
      "cart_within_24 0.0 Not significant\n",
      "view_count_med -0.0495 Not significant\n",
      "view_count_ave -0.0285 Not significant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "find_important_difference_all(df5[df5['total_discount_percentage'] >= 0.046], df5[df5['total_discount_percentage'] < 0.046])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 價格敏感的線下購買者 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05547778330369031"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(df1['total_discount_percentage'], 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.012 Not significant\n",
      "total_conversion_rate -0.0191 Not so significant\n",
      "ave_M -1185.5791\n",
      "ave_M_not_offline_return -1327.1678\n",
      "total_M -1502.2387\n",
      "total_F 0.6565\n",
      "total_S 33.3761\n",
      "session_number 6.6995\n",
      "buy_time_without_offline_return 0.59\n",
      "total_day_using_percentage 0.0041\n",
      "actually_using_percentage 0.0095\n",
      "view_per_date -0.0972 Not so significant\n",
      "view_per_session -0.1533\n",
      "session_per_date 0.0164\n",
      "off_return_item_number 0.0551\n",
      "off_return_frequency 0.0665\n",
      "off_cart_c -0.0268\n",
      "off_fav_c -0.0099 Not so significant\n",
      "off_view_c -0.0021 Not significant\n",
      "on_cart_c 0.0021 Not significant\n",
      "on_fav_c -0.0077 Not significant\n",
      "on_view_c -0.0057 Not significant\n",
      "total_cart_c 0.0092 Not significant\n",
      "total_fav_c -0.0035 Not significant\n",
      "total_view_c -0.0006 Not significant\n",
      "viewtime_ave 1.6619 Not so significant\n",
      "view_time_med 0.6486 Not significant\n",
      "total_discount_percentage 0.0969\n",
      "online_ratio 0.0032\n",
      "online_ratio_without_offline_return 0.0037\n",
      "off_mix_c -0.0214\n",
      "on_mix_c -0.0251 Not significant\n",
      "total_mix_c -0.0013 Not significant\n",
      "cart_med_time -3982.5887\n",
      "cart_ave_time -3503.8708\n",
      "cart_within_3 0.0599\n",
      "cart_within_24 0.0 Not significant\n",
      "view_count_med -0.0855\n",
      "view_count_ave -0.0532 Not significant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "find_important_difference_all(df1[df1['total_discount_percentage'] >= 0.0555], df1[df1['total_discount_percentage'] < 0.0555])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以上評論\n",
    "## 對於衝動購物者而言，如果他們還是價格敏感者，那會更提高online_view_conversion_rate，但是他們會比較多在線下買(可能因為折扣多)並且大多不是買線上看到的(可能因為專買線下特價商品)，但線上的轉換率會比較高!!!\n",
    "\n",
    "## 線下的價格敏感者，則轉換率比一般線下購滿者低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'統整一下，目前有1. 不活躍(可能是線上或線下), 2. 線下購買者, 3. 深思猶豫者, 4. 線上一般購買者, 5.衝動型購物者'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'統整一下，目前有1. 不活躍(可能是線上或線下), 2. 線下購買者, 3. 深思猶豫者, 4. 線上一般購買者, 5.衝動型購物者'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('不活躍', 25676)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'不活躍',df_inactive.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('線下購買者', 21804)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'線下購買者', df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('深思猶豫者', 4497)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'深思猶豫者', df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('線上一般購買者', 4421)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'線上一般購買者', df4.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('衝動型購物者', 4594)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'衝動型購物者', df5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('被排除的人', 980)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'被排除的人', null_df2.shape[0] + df_drop.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('還沒被分群的人(他們沒購買過)', 14429)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'還沒被分群的人(他們沒購買過)', df_never_buy.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 現在要給他們建造馬可夫遷移矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2280.0, 1.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile( df['ave_M'], 50), np.nanpercentile( df['total_F'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24456, 48450)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ave_M']<=2280].shape[0], df[df['total_F']<=1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24347, 27951)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ave_M']>2280].shape[0], df[df['total_F']>1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('memberid', '201803F', '201803M', '201803S', '201904S')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.columns[0], df5.columns[20], df5.columns[34], df5.columns[48], df5.columns[61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我要看一下，一個月多少session是過少'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'我要看一下，一個月多少session是過少'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "11.0\n",
      "12.0\n",
      "10.0\n",
      "17.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "17.0\n",
      "12.0\n",
      "19.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "total_session = []\n",
    "for col_name in df.columns[48:62]:\n",
    "    with_session_df = df[df[col_name]>0]\n",
    "    print( np.median(with_session_df[col_name]) )\n",
    "    total_session+= with_session_df[col_name].tolist()\n",
    "    counter += with_session_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.0, 12.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(total_session, 49), np.nanpercentile(total_session, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path propotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(a_dict, percent = True, return_count = False):\n",
    "    def pathname(from_,to):\n",
    "        return \"{}\".format(from_) + \" to \" \"{}\".format(to)\n",
    "    #儲存所有路徑的dict, ex: 1->6,2->6 等等 \n",
    "    path_dict = {}\n",
    "\n",
    "    #需先儲存此人上一個的群\n",
    "    last_classification = 0\n",
    "\n",
    "    #iterate through every list in the group\n",
    "    for i in a_dict.values():\n",
    "        #iterate every classification in each member in the group\n",
    "        first = True\n",
    "        for j in i:     \n",
    "            #如果是第一月，沒有路徑，直接跳到下一個月份\n",
    "            if(first):\n",
    "                last_classification = j\n",
    "                first = False    \n",
    "                continue\n",
    "            \n",
    "            #儲存路徑，ex: {5 to 6 : 1} 代表5到6有一次\n",
    "            else:\n",
    "                #把該路徑的count+1\n",
    "                try:\n",
    "                    path_dict.update( { pathname(last_classification,j) : path_dict[pathname(last_classification,j)] + 1 } )\n",
    "                #第一次出現路徑的情況，就設1\n",
    "                except:\n",
    "                    path_dict.update( { pathname(last_classification,j) : 1 } )\n",
    "                last_classification = j\n",
    "        \n",
    "    path_divided_by_classification_proportion = {}\n",
    "    \n",
    "    #from_count 記錄從某一個classification分出去的總數  Ex : 5 to 1為2 ,5 to 6為 3  則from count有{ 5 : 2+3}\n",
    "    from_count = {}\n",
    "\n",
    "    for key, value in path_dict.items():\n",
    "        try:\n",
    "            from_count.update({str.split(key)[0] : from_count[str.split(key)[0]]+value})\n",
    "        except: #處理第一次dict沒key的情況\n",
    "            from_count.update({str.split(key)[0] : value})\n",
    "            \n",
    "    for key, value in path_dict.items():\n",
    "        for from_key, from_count_value in from_count.items():\n",
    "            if(str.split(key)[0]==from_key):\n",
    "                path_divided_by_classification_proportion.update({key : (value/from_count_value)})\n",
    "    all_data = []    \n",
    "    last_item = -1\n",
    "    tem_data = dict()\n",
    "    for i in  sorted(path_divided_by_classification_proportion.keys()):\n",
    "        if percent:\n",
    "            ratio = '%0.2f%%' %(path_divided_by_classification_proportion[i]*100)\n",
    "        else:\n",
    "            ratio =(path_divided_by_classification_proportion[i])\n",
    "        item = int(i[5])\n",
    "        if item <= last_item:\n",
    "            all_data.append(tem_data)\n",
    "            tem_data = dict()\n",
    "        tem_data[item] = ratio\n",
    "        last_item = item\n",
    "    all_data.append(tem_data)\n",
    "    if return_count:\n",
    "        return pd.DataFrame(all_data), from_count\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開始依照過去歷史給予分類\n",
    "0是沒操作，1是有操作但少於12(但是沒購買)，2是有操作但高於12(但是沒購買)。3,4,5,6分別是FM四象限(F橫M縱)，3是高F高M，4是低F高M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_group_to_dict_of_path(df, percent = True):\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "        a_dict_for_markov[memberID] = [0]*14\n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 是session\n",
    "            34+j 是 M\n",
    "            20+J 是 F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            if  S == 0:\n",
    "                continue\n",
    "            elif  F == 0:\n",
    "                a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "            elif M_ave <= 2280 and F<= 1:\n",
    "                a_dict_for_markov[memberID][j] = 5\n",
    "            elif M_ave > 2280 and F<= 1:\n",
    "                a_dict_for_markov[memberID][j] = 4\n",
    "            elif M_ave <= 2280 and F > 1:\n",
    "                a_dict_for_markov[memberID][j] = 6\n",
    "            elif M_ave > 2280 and F > 1:\n",
    "                a_dict_for_markov[memberID][j] = 3\n",
    "        \n",
    "        \n",
    "    return path(a_dict_for_markov, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "path_df = from_group_to_dict_of_path(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.24%</td>\n",
       "      <td>10.47%</td>\n",
       "      <td>3.65%</td>\n",
       "      <td>1.31%</td>\n",
       "      <td>3.51%</td>\n",
       "      <td>4.50%</td>\n",
       "      <td>1.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.13%</td>\n",
       "      <td>37.03%</td>\n",
       "      <td>16.77%</td>\n",
       "      <td>1.91%</td>\n",
       "      <td>6.34%</td>\n",
       "      <td>7.00%</td>\n",
       "      <td>1.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.16%</td>\n",
       "      <td>23.93%</td>\n",
       "      <td>40.17%</td>\n",
       "      <td>4.91%</td>\n",
       "      <td>8.71%</td>\n",
       "      <td>7.85%</td>\n",
       "      <td>4.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.37%</td>\n",
       "      <td>11.16%</td>\n",
       "      <td>24.72%</td>\n",
       "      <td>24.25%</td>\n",
       "      <td>14.71%</td>\n",
       "      <td>10.06%</td>\n",
       "      <td>8.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.91%</td>\n",
       "      <td>25.68%</td>\n",
       "      <td>30.02%</td>\n",
       "      <td>9.14%</td>\n",
       "      <td>12.38%</td>\n",
       "      <td>6.37%</td>\n",
       "      <td>3.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.01%</td>\n",
       "      <td>29.09%</td>\n",
       "      <td>29.01%</td>\n",
       "      <td>4.01%</td>\n",
       "      <td>6.51%</td>\n",
       "      <td>12.15%</td>\n",
       "      <td>5.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.49%</td>\n",
       "      <td>17.47%</td>\n",
       "      <td>31.49%</td>\n",
       "      <td>8.61%</td>\n",
       "      <td>7.10%</td>\n",
       "      <td>13.58%</td>\n",
       "      <td>13.26%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6\n",
       "0  75.24%  10.47%   3.65%   1.31%   3.51%   4.50%   1.32%\n",
       "1  29.13%  37.03%  16.77%   1.91%   6.34%   7.00%   1.83%\n",
       "2  10.16%  23.93%  40.17%   4.91%   8.71%   7.85%   4.27%\n",
       "3   6.37%  11.16%  24.72%  24.25%  14.71%  10.06%   8.72%\n",
       "4  12.91%  25.68%  30.02%   9.14%  12.38%   6.37%   3.49%\n",
       "5  14.01%  29.09%  29.01%   4.01%   6.51%  12.15%   5.21%\n",
       "6   8.49%  17.47%  31.49%   8.61%   7.10%  13.58%  13.26%"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 每一群的轉移矩陣print出來看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09827479196358788"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df1['buy_time_without_offline_return']) / sum( df1['session_number'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive Their merged conversion rate is:31.18%.\n",
      "Their median of conversion rate is:0.00%.   The path:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1      2      3      4      5      6\n",
      "0  88.02%   7.30%  1.41%  0.28%  1.14%  1.47%  0.37%\n",
      "1  77.82%  18.59%  2.12%  0.13%  0.47%  0.72%  0.14%\n",
      "2  76.25%  18.08%  4.17%  0.07%  0.49%  0.84%  0.09%\n",
      "3  75.96%  13.71%  1.01%  1.91%  1.57%  3.71%  2.13%\n",
      "4  76.80%  17.78%  1.83%  0.33%  1.26%  1.26%  0.74%\n",
      "5  77.35%  18.71%  1.33%  0.19%  0.59%  1.35%  0.49%\n",
      "6  76.63%  15.86%  1.50%  0.67%  1.00%  3.01%  1.34%\n",
      "\n",
      "never_buy Their merged conversion rate is:0.00%.\n",
      "Their median of conversion rate is:0.00%.   The path:\n",
      "        0       1       2\n",
      "0  78.65%  13.39%   7.96%\n",
      "1  32.99%  45.08%  21.93%\n",
      "2  16.43%  32.86%  50.71%\n",
      "\n",
      "offline Their merged conversion rate is:9.83%.\n",
      "Their median of conversion rate is:13.33%.   The path:\n",
      "        0       1       2       3      4       5       6\n",
      "0  79.90%   7.49%   2.35%   1.72%  3.68%   3.31%   1.55%\n",
      "1  30.71%  41.43%  14.43%   2.11%  4.72%   4.56%   2.04%\n",
      "2  10.44%  22.57%  44.53%   3.84%  7.43%   7.25%   3.94%\n",
      "3  12.91%  15.81%  21.59%  17.00%  9.91%   9.60%  13.18%\n",
      "4  17.46%  26.96%  27.39%   6.02%  8.12%   8.43%   5.62%\n",
      "5  16.91%  28.58%  29.25%   3.93%  5.43%   9.54%   6.37%\n",
      "6  13.69%  18.74%  23.76%   7.83%  6.71%  12.24%  17.03%\n",
      "\n",
      "深思熟慮 Their merged conversion rate is:2.48%.\n",
      "Their median of conversion rate is:2.67%.   The path:\n",
      "        0       1       2      3       4       5       6\n",
      "0  66.55%  12.56%  11.85%  0.85%   2.86%   4.23%   1.11%\n",
      "1  19.68%  33.77%  34.30%  0.65%   3.82%   6.74%   1.04%\n",
      "2   4.95%  14.43%  57.87%  1.47%   7.63%  11.50%   2.15%\n",
      "3   2.56%   8.65%  43.48%  7.06%  14.01%  13.28%  10.96%\n",
      "4   5.85%  14.18%  55.03%  2.92%   8.58%   9.81%   3.62%\n",
      "5   6.67%  15.88%  55.59%  1.97%   4.58%  10.92%   4.39%\n",
      "6   3.11%   7.69%  45.73%  5.36%   7.92%  18.63%  11.57%\n",
      "\n",
      "一般人 Their merged conversion rate is:4.38%.\n",
      "Their median of conversion rate is:4.69%.   The path:\n",
      "        0       1       2       3       4       5       6\n",
      "0  69.20%  12.88%   7.68%   1.25%   3.69%   4.16%   1.14%\n",
      "1  22.73%  36.29%  24.46%   1.44%   6.01%   7.71%   1.36%\n",
      "2   7.22%  18.28%  46.24%   3.90%  10.22%  10.38%   3.76%\n",
      "3   2.69%   8.01%  35.14%  18.05%  15.37%  10.32%  10.42%\n",
      "4   6.63%  17.48%  42.62%   6.49%  13.07%   8.92%   4.80%\n",
      "5   8.27%  20.17%  42.48%   3.75%   6.94%  13.23%   5.16%\n",
      "6   3.61%   9.17%  35.91%   8.95%   8.23%  16.56%  17.57%\n",
      "\n",
      "衝動購物 Their merged conversion rate is:7.30%.\n",
      "Their median of conversion rate is:8.33%.   The path:\n",
      "        0       1       2       3       4       5       6\n",
      "0  75.24%  10.47%   3.65%   1.31%   3.51%   4.50%   1.32%\n",
      "1  29.13%  37.03%  16.77%   1.91%   6.34%   7.00%   1.83%\n",
      "2  10.16%  23.93%  40.17%   4.91%   8.71%   7.85%   4.27%\n",
      "3   6.37%  11.16%  24.72%  24.25%  14.71%  10.06%   8.72%\n",
      "4  12.91%  25.68%  30.02%   9.14%  12.38%   6.37%   3.49%\n",
      "5  14.01%  29.09%  29.01%   4.01%   6.51%  12.15%   5.21%\n",
      "6   8.49%  17.47%  31.49%   8.61%   7.10%  13.58%  13.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df_never_buy, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive','never_buy', 'offline', '深思熟慮', '一般人', '衝動購物']\n",
    "\n",
    "for i in range(6):\n",
    "    conversion_r = sum(to_be_printed_df[i]['buy_time_without_offline_return']) / sum( to_be_printed_df[i]['session_number'] )\n",
    "    print(to_be_printed_df_name[i],  'Their merged conversion rate is:%0.2f%%.' %(conversion_r*100)) \n",
    "    print( 'Their median of conversion rate is:%0.2f%%.   The path:'  % (np.nanmedian(to_be_printed_df[i]['converion_rate_without_offline_return'])*100))\n",
    "    print(from_group_to_dict_of_path(to_be_printed_df[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_randomly(a_list):\n",
    "    random_v = random()\n",
    "    new = 0\n",
    "\n",
    "    for i in range( len(a_list) ):\n",
    "        new += a_list[i] \n",
    "        if random_v <= new:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_confusion_metrrix(df, n_month = 13):\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    test_dict = dict()\n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "        a_dict_for_markov[memberID] = [0]*n_month\n",
    "        test_dict[memberID] = [0]*(14-n_month)\n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 是session\n",
    "            34+j 是 M\n",
    "            +J 是 F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            \n",
    "            if j+1 > n_month:\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    test_dict[memberID][j-n_month] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 3\n",
    "            else:\n",
    "                \n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 3\n",
    "                \n",
    "    a_df = path(a_dict_for_markov, False)\n",
    "    a_dict_for_predict = dict() # 上期數字對映一個列表\n",
    "    \n",
    "    for i in range(7):\n",
    "        a_dict_for_predict[i] = list( a_df.iloc[i, :] )\n",
    "        \n",
    "\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    " \n",
    "    for key in test_dict.keys():\n",
    "        last = a_dict_for_markov[key][-1]\n",
    "        next_ = test_dict[key][0]\n",
    "\n",
    "        \n",
    "        # update martix\n",
    "        true_list.append(next_)\n",
    "        pred_list.append( pred_randomly(a_dict_for_predict[last])  )\n",
    "        \n",
    "        if n_month == 12:\n",
    "            last = test_dict[key][0]\n",
    "            next_ = test_dict[key][1]\n",
    "            \n",
    "\n",
    "            true_list.append(next_)\n",
    "            pred_list.append( pred_randomly(a_dict_for_predict[last])  )\n",
    "\n",
    "    return true_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.8710    0.9117     24518\n",
      "           1     0.0411    0.1000    0.0582       860\n",
      "           2     0.0000    0.0000    0.0000        83\n",
      "           3     0.0000    0.0000    0.0000        27\n",
      "           4     0.0034    0.0156    0.0056        64\n",
      "           5     0.0026    0.0108    0.0042        93\n",
      "           6     0.0000    0.0000    0.0000        31\n",
      "\n",
      "   micro avg     0.8351    0.8351    0.8351     25676\n",
      "   macro avg     0.1433    0.1425    0.1400     25676\n",
      "weighted avg     0.9146    0.8351    0.8725     25676\n",
      "\n",
      "\n",
      "offline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5165    0.6054    0.5574      8708\n",
      "           1     0.3146    0.2585    0.2838      5411\n",
      "           2     0.2812    0.3136    0.2965      3138\n",
      "           3     0.0394    0.0387    0.0390       724\n",
      "           4     0.0691    0.0524    0.0596      1413\n",
      "           5     0.0786    0.0557    0.0652      1580\n",
      "           6     0.0816    0.0735    0.0773       830\n",
      "\n",
      "   micro avg     0.3626    0.3626    0.3626     21804\n",
      "   macro avg     0.1973    0.1997    0.1970     21804\n",
      "weighted avg     0.3394    0.3626    0.3486     21804\n",
      "\n",
      "\n",
      "深思熟慮\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4880    0.4709    0.4793       996\n",
      "           1     0.2703    0.2158    0.2400       987\n",
      "           2     0.4716    0.5229    0.4959      1746\n",
      "           3     0.0164    0.0204    0.0182        49\n",
      "           4     0.0802    0.0854    0.0827       246\n",
      "           5     0.0743    0.0724    0.0733       387\n",
      "           6     0.0268    0.0349    0.0303        86\n",
      "\n",
      "   micro avg     0.3665    0.3665    0.3665      4497\n",
      "   macro avg     0.2039    0.2032    0.2028      4497\n",
      "weighted avg     0.3620    0.3665    0.3630      4497\n",
      "\n",
      "\n",
      "一般人\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5278    0.5216    0.5247      1275\n",
      "           1     0.2896    0.2601    0.2741      1011\n",
      "           2     0.3724    0.3771    0.3747      1265\n",
      "           3     0.0763    0.0692    0.0726       130\n",
      "           4     0.0793    0.0959    0.0868       271\n",
      "           5     0.0979    0.1135    0.1051       326\n",
      "           6     0.0676    0.0699    0.0687       143\n",
      "\n",
      "   micro avg     0.3363    0.3363    0.3363      4421\n",
      "   macro avg     0.2158    0.2153    0.2152      4421\n",
      "weighted avg     0.3415    0.3363    0.3386      4421\n",
      "\n",
      "\n",
      "衝動購物\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5907    0.6018    0.5962      1856\n",
      "           1     0.3188    0.2791    0.2976      1125\n",
      "           2     0.2562    0.2761    0.2658       746\n",
      "           3     0.0977    0.1062    0.1018       160\n",
      "           4     0.0778    0.0775    0.0776       271\n",
      "           5     0.0708    0.0772    0.0738       298\n",
      "           6     0.0690    0.0725    0.0707       138\n",
      "\n",
      "   micro avg     0.3718    0.3718    0.3718      4594\n",
      "   macro avg     0.2116    0.2129    0.2119      4594\n",
      "weighted avg     0.3730    0.3718    0.3720      4594\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive', 'offline', '深思熟慮', '一般人', '衝動購物']\n",
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    true_list, pred_list = test_confusion_metrrix(to_be_printed_df[i], n_month = 13)\n",
    "    print( classification_report(true_list, pred_list,   digits = 4))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分開測試準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_confusion_metrrix_seperated(df):\n",
    "    n_month = 13\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    test_dict = dict()\n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "        a_dict_for_markov[memberID] = [0]*n_month\n",
    "        test_dict[memberID] = [0]*(14-n_month)\n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 是session\n",
    "            34+j 是 M\n",
    "            +J 是 F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            \n",
    "            if j+1 > n_month:\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    test_dict[memberID][j-n_month] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 3\n",
    "            else:\n",
    "                \n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 3\n",
    "                \n",
    "    a_df = path(a_dict_for_markov, False)\n",
    "    a_dict_for_predict = dict() # 上期數字對映一個列表\n",
    "    true_dict = dict()\n",
    "    pred_dict = dict()\n",
    "    for i in range(7):\n",
    "        a_dict_for_predict[i] = list( a_df.iloc[i, :] )\n",
    "\n",
    "        true_dict[i] = []\n",
    "        pred_dict[i] = []\n",
    "\n",
    "    for key in test_dict.keys():\n",
    "        last = a_dict_for_markov[key][-1]\n",
    "        next_ = test_dict[key][0]\n",
    "\n",
    "        \n",
    "        # update martix\n",
    "        true_dict[last].append(next_)\n",
    "        pred_dict[last].append( pred_randomly(a_dict_for_predict[last])  )\n",
    "    \n",
    "\n",
    "    return true_dict, pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "true_dict, pred_dict = test_confusion_metrrix_seperated(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.8719    0.9142     23344\n",
      "           1     0.0236    0.0640    0.0344       703\n",
      "           2     0.0088    0.0476    0.0149        63\n",
      "           3     0.0000    0.0000    0.0000        21\n",
      "           4     0.0000    0.0000    0.0000        56\n",
      "           5     0.0052    0.0253    0.0086        79\n",
      "           6     0.0000    0.0000    0.0000        24\n",
      "\n",
      "   micro avg     0.8400    0.8400    0.8400     24290\n",
      "   macro avg     0.1426    0.1441    0.1389     24290\n",
      "weighted avg     0.9242    0.8400    0.8797     24290\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8547    0.7815    0.8165       888\n",
      "           1     0.1270    0.1935    0.1534       124\n",
      "           2     0.0952    0.1429    0.1143        14\n",
      "           3     0.0000    0.0000    0.0000         4\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "           5     0.0000    0.0000    0.0000         6\n",
      "           6     0.0000    0.0000    0.0000         3\n",
      "\n",
      "   micro avg     0.6923    0.6923    0.6923      1040\n",
      "   macro avg     0.1538    0.1597    0.1549      1040\n",
      "weighted avg     0.7462    0.6923    0.7170      1040\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8226    0.6800    0.7445        75\n",
      "           1     0.0588    0.1000    0.0741        10\n",
      "           2     0.0000    0.0000    0.0000         3\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           4     0.0000    0.0000    0.0000         0\n",
      "           5     0.0000    0.0000    0.0000         1\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.5778    0.5778    0.5778        90\n",
      "   macro avg     0.1259    0.1114    0.1169        90\n",
      "weighted avg     0.6920    0.5778    0.6287        90\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6190    0.7647    0.6842        17\n",
      "           1     0.0000    0.0000    0.0000         1\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "           4     0.0000    0.0000    0.0000         3\n",
      "           5     0.0000    0.0000    0.0000         3\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.4815    0.4815    0.4815        27\n",
      "   macro avg     0.1032    0.1275    0.1140        27\n",
      "weighted avg     0.3898    0.4815    0.4308        27\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8421    0.7805    0.8101        82\n",
      "           1     0.1765    0.2727    0.2143        11\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           4     0.0000    0.0000    0.0000         2\n",
      "           5     0.0000    0.0000    0.0000         2\n",
      "           6     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.6837    0.6837    0.6837        98\n",
      "   macro avg     0.1698    0.1755    0.1707        98\n",
      "weighted avg     0.7244    0.6837    0.7019        98\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8875    0.8068    0.8452        88\n",
      "           1     0.0000    0.0000    0.0000         8\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.7172    0.7172    0.7172        99\n",
      "   macro avg     0.1775    0.1614    0.1690        99\n",
      "weighted avg     0.7889    0.7172    0.7513        99\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7600    0.7917    0.7755        24\n",
      "           1     0.0000    0.0000    0.0000         3\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "           5     0.0000    0.0000    0.0000         2\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.5938    0.5938    0.5938        32\n",
      "   macro avg     0.1267    0.1319    0.1293        32\n",
      "weighted avg     0.5700    0.5938    0.5816        32\n",
      "\n",
      "\n",
      "offline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5910    0.8087    0.6829      5610\n",
      "           1     0.1790    0.0762    0.1069      1587\n",
      "           2     0.0046    0.0036    0.0040       277\n",
      "           3     0.0195    0.0120    0.0149       249\n",
      "           4     0.0793    0.0376    0.0510       692\n",
      "           5     0.1028    0.0358    0.0532       809\n",
      "           6     0.0452    0.0262    0.0332       267\n",
      "\n",
      "   micro avg     0.4977    0.4977    0.4977      9491\n",
      "   macro avg     0.1459    0.1429    0.1352      9491\n",
      "weighted avg     0.3957    0.4977    0.4312      9491\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3632    0.3177    0.3389      1901\n",
      "           1     0.4207    0.4113    0.4159      2237\n",
      "           2     0.1283    0.1625    0.1434       603\n",
      "           3     0.0145    0.0206    0.0170        97\n",
      "           4     0.0648    0.0734    0.0688       218\n",
      "           5     0.0611    0.0773    0.0682       207\n",
      "           6     0.0111    0.0114    0.0112        88\n",
      "\n",
      "   micro avg     0.3097    0.3097    0.3097      5351\n",
      "   macro avg     0.1519    0.1535    0.1519      5351\n",
      "weighted avg     0.3248    0.3097    0.3164      5351\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0907    0.0917    0.0912       349\n",
      "           1     0.2120    0.2162    0.2141       754\n",
      "           2     0.4297    0.4331    0.4314      1503\n",
      "           3     0.0547    0.0583    0.0565       120\n",
      "           4     0.0864    0.0784    0.0822       268\n",
      "           5     0.0656    0.0675    0.0665       237\n",
      "           6     0.0299    0.0258    0.0277       155\n",
      "\n",
      "   micro avg     0.2640    0.2640    0.2640      3386\n",
      "   macro avg     0.1384    0.1387    0.1385      3386\n",
      "weighted avg     0.2620    0.2640    0.2630      3386\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2029    0.1346    0.1618       104\n",
      "           1     0.1414    0.1707    0.1547        82\n",
      "           2     0.2195    0.2328    0.2259       116\n",
      "           3     0.1500    0.1348    0.1420        89\n",
      "           4     0.0938    0.1224    0.1062        49\n",
      "           5     0.0526    0.0392    0.0449        51\n",
      "           6     0.1500    0.1935    0.1690        62\n",
      "\n",
      "   micro avg     0.1573    0.1573    0.1573       553\n",
      "   macro avg     0.1443    0.1469    0.1435       553\n",
      "weighted avg     0.1593    0.1573    0.1561       553\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2723    0.1775    0.2149       293\n",
      "           1     0.2329    0.2336    0.2333       321\n",
      "           2     0.2156    0.2828    0.2447       244\n",
      "           3     0.0392    0.0323    0.0354        62\n",
      "           4     0.0900    0.1084    0.0984        83\n",
      "           5     0.0521    0.0575    0.0546        87\n",
      "           6     0.0137    0.0159    0.0147        63\n",
      "\n",
      "   micro avg     0.1847    0.1847    0.1847      1153\n",
      "   macro avg     0.1308    0.1297    0.1280      1153\n",
      "weighted avg     0.1929    0.1847    0.1852      1153\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2551    0.1582    0.1953       316\n",
      "           1     0.2575    0.2687    0.2630       320\n",
      "           2     0.2099    0.2744    0.2379       277\n",
      "           3     0.2333    0.1522    0.1842        46\n",
      "           4     0.0141    0.0175    0.0156        57\n",
      "           5     0.0492    0.0588    0.0536       102\n",
      "           6     0.0606    0.0635    0.0620        63\n",
      "\n",
      "   micro avg     0.1948    0.1948    0.1948      1181\n",
      "   macro avg     0.1542    0.1419    0.1445      1181\n",
      "weighted avg     0.2045    0.1948    0.1952      1181\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2188    0.1556    0.1818       135\n",
      "           1     0.1800    0.1636    0.1714       110\n",
      "           2     0.1411    0.1949    0.1637       118\n",
      "           3     0.0926    0.0820    0.0870        61\n",
      "           4     0.0545    0.0652    0.0594        46\n",
      "           5     0.1204    0.1494    0.1333        87\n",
      "           6     0.1593    0.1364    0.1469       132\n",
      "\n",
      "   micro avg     0.1466    0.1466    0.1466       689\n",
      "   macro avg     0.1381    0.1353    0.1348       689\n",
      "weighted avg     0.1533    0.1466    0.1477       689\n",
      "\n",
      "\n",
      "深思熟慮\n",
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6635    0.6635    0.6635       630\n",
      "           1     0.2154    0.1618    0.1848       173\n",
      "           2     0.0261    0.0441    0.0328        68\n",
      "           3     0.0000    0.0000    0.0000         8\n",
      "           4     0.0370    0.0417    0.0392        24\n",
      "           5     0.0606    0.0513    0.0556        39\n",
      "           6     0.1250    0.1111    0.1176         9\n",
      "\n",
      "   micro avg     0.4763    0.4763    0.4763       951\n",
      "   macro avg     0.1611    0.1534    0.1562       951\n",
      "weighted avg     0.4852    0.4763    0.4799       951\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2406    0.1948    0.2153       231\n",
      "           1     0.3866    0.2958    0.3352       409\n",
      "           2     0.2012    0.2969    0.2399       229\n",
      "           3     0.0000    0.0000    0.0000         3\n",
      "           4     0.0256    0.0400    0.0312        25\n",
      "           5     0.0462    0.0484    0.0472        62\n",
      "           6     0.0000    0.0000    0.0000         6\n",
      "\n",
      "   micro avg     0.2466    0.2466    0.2466       965\n",
      "   macro avg     0.1286    0.1251    0.1241       965\n",
      "weighted avg     0.2728    0.2466    0.2544       965\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0581    0.0595    0.0588        84\n",
      "           1     0.1793    0.1799    0.1796       289\n",
      "           2     0.5849    0.5771    0.5810      1116\n",
      "           3     0.0000    0.0000    0.0000        20\n",
      "           4     0.0979    0.0909    0.0943       154\n",
      "           5     0.0977    0.0991    0.0984       212\n",
      "           6     0.0000    0.0000    0.0000        33\n",
      "\n",
      "   micro avg     0.3857    0.3857    0.3857      1908\n",
      "   macro avg     0.1454    0.1438    0.1446      1908\n",
      "weighted avg     0.3906    0.3857    0.3881      1908\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         4\n",
      "           1     0.1429    0.2500    0.1818         4\n",
      "           2     0.4706    0.2963    0.3636        27\n",
      "           3     0.0000    0.0000    0.0000         3\n",
      "           4     0.2000    0.1667    0.1818         6\n",
      "           5     0.1111    0.5000    0.1818         2\n",
      "           6     0.0000    0.0000    0.0000         4\n",
      "\n",
      "   micro avg     0.2200    0.2200    0.2200        50\n",
      "   macro avg     0.1321    0.1733    0.1299        50\n",
      "weighted avg     0.2940    0.2200    0.2400        50\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0769    0.0667    0.0714        15\n",
      "           1     0.2143    0.1667    0.1875        36\n",
      "           2     0.5804    0.5856    0.5830       111\n",
      "           3     0.1250    0.1667    0.1429         6\n",
      "           4     0.0588    0.0417    0.0488        24\n",
      "           5     0.0000    0.0000    0.0000        15\n",
      "           6     0.0000    0.0000    0.0000         2\n",
      "\n",
      "   micro avg     0.3541    0.3541    0.3541       209\n",
      "   macro avg     0.1508    0.1468    0.1476       209\n",
      "weighted avg     0.3610    0.3541    0.3567       209\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        26\n",
      "           1     0.2041    0.1562    0.1770        64\n",
      "           2     0.5130    0.6037    0.5546       164\n",
      "           3     0.0000    0.0000    0.0000         5\n",
      "           4     0.0000    0.0000    0.0000         6\n",
      "           5     0.1842    0.1556    0.1687        45\n",
      "           6     0.0000    0.0000    0.0000        21\n",
      "\n",
      "   micro avg     0.3505    0.3505    0.3505       331\n",
      "   macro avg     0.1287    0.1308    0.1286       331\n",
      "weighted avg     0.3187    0.3505    0.3320       331\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         6\n",
      "           1     0.0000    0.0000    0.0000        12\n",
      "           2     0.3571    0.4839    0.4110        31\n",
      "           3     0.0000    0.0000    0.0000         4\n",
      "           4     0.1111    0.1429    0.1250         7\n",
      "           5     0.1111    0.1667    0.1333        12\n",
      "           6     0.4286    0.2727    0.3333        11\n",
      "\n",
      "   micro avg     0.2530    0.2530    0.2530        83\n",
      "   macro avg     0.1440    0.1523    0.1432        83\n",
      "weighted avg     0.2156    0.2530    0.2275        83\n",
      "\n",
      "\n",
      "一般人\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7031    0.6864    0.6947       880\n",
      "           1     0.1753    0.1256    0.1463       215\n",
      "           2     0.0112    0.0161    0.0132        62\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.0333    0.0741    0.0460        27\n",
      "           5     0.1034    0.1364    0.1176        44\n",
      "           6     0.0000    0.0000    0.0000        12\n",
      "\n",
      "   micro avg     0.5136    0.5136    0.5136      1246\n",
      "   macro avg     0.1466    0.1484    0.1454      1246\n",
      "weighted avg     0.5318    0.5136    0.5217      1246\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2617    0.2121    0.2343       264\n",
      "           1     0.4511    0.3897    0.4181       426\n",
      "           2     0.2314    0.2719    0.2500       217\n",
      "           3     0.0000    0.0000    0.0000        11\n",
      "           4     0.0545    0.0857    0.0667        35\n",
      "           5     0.0241    0.0455    0.0315        44\n",
      "           6     0.0000    0.0000    0.0000         9\n",
      "\n",
      "   micro avg     0.2843    0.2843    0.2843      1006\n",
      "   macro avg     0.1461    0.1436    0.1429      1006\n",
      "weighted avg     0.3125    0.2843    0.2962      1006\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0957    0.1000    0.0978        90\n",
      "           1     0.2122    0.2039    0.2080       255\n",
      "           2     0.4607    0.4315    0.4456       679\n",
      "           3     0.0351    0.0417    0.0381        48\n",
      "           4     0.0719    0.0948    0.0818       116\n",
      "           5     0.0496    0.0511    0.0504       137\n",
      "           6     0.0577    0.0566    0.0571        53\n",
      "\n",
      "   micro avg     0.2736    0.2736    0.2736      1378\n",
      "   macro avg     0.1404    0.1399    0.1398      1378\n",
      "weighted avg     0.2870    0.2736    0.2799      1378\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         1\n",
      "           1     0.0769    0.1111    0.0909         9\n",
      "           2     0.2162    0.2286    0.2222        35\n",
      "           3     0.3333    0.2143    0.2609        28\n",
      "           4     0.3810    0.2963    0.3333        27\n",
      "           5     0.0714    0.1111    0.0870         9\n",
      "           6     0.0714    0.0833    0.0769        12\n",
      "\n",
      "   micro avg     0.2066    0.2066    0.2066       121\n",
      "   macro avg     0.1643    0.1492    0.1530       121\n",
      "weighted avg     0.2428    0.2066    0.2199       121\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0526    0.0588    0.0556        17\n",
      "           1     0.2381    0.2381    0.2381        42\n",
      "           2     0.4706    0.4528    0.4615       106\n",
      "           3     0.0000    0.0000    0.0000        16\n",
      "           4     0.1622    0.2308    0.1905        26\n",
      "           5     0.0588    0.0400    0.0476        25\n",
      "           6     0.0714    0.1111    0.0870         9\n",
      "\n",
      "   micro avg     0.2780    0.2780    0.2780       241\n",
      "   macro avg     0.1505    0.1617    0.1543       241\n",
      "weighted avg     0.2785    0.2780    0.2771       241\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0690    0.1111    0.0851        18\n",
      "           1     0.1290    0.1481    0.1379        54\n",
      "           2     0.3884    0.3672    0.3775       128\n",
      "           3     0.0000    0.0000    0.0000         9\n",
      "           4     0.1667    0.1034    0.1277        29\n",
      "           5     0.2857    0.2326    0.2564        43\n",
      "           6     0.0556    0.0667    0.0606        15\n",
      "\n",
      "   micro avg     0.2399    0.2399    0.2399       296\n",
      "   macro avg     0.1563    0.1470    0.1493       296\n",
      "weighted avg     0.2564    0.2399    0.2464       296\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         5\n",
      "           1     0.0833    0.1000    0.0909        10\n",
      "           2     0.2553    0.3158    0.2824        38\n",
      "           3     0.0667    0.0833    0.0741        12\n",
      "           4     0.0714    0.0909    0.0800        11\n",
      "           5     0.3125    0.2083    0.2500        24\n",
      "           6     0.2174    0.1515    0.1786        33\n",
      "\n",
      "   micro avg     0.1880    0.1880    0.1880       133\n",
      "   macro avg     0.1438    0.1357    0.1366       133\n",
      "weighted avg     0.2015    0.1880    0.1902       133\n",
      "\n",
      "\n",
      "衝動購物\n",
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7077    0.7710    0.7380      1297\n",
      "           1     0.1350    0.0833    0.1030       264\n",
      "           2     0.0141    0.0179    0.0157        56\n",
      "           3     0.0000    0.0000    0.0000        22\n",
      "           4     0.0274    0.0333    0.0301        60\n",
      "           5     0.1059    0.0811    0.0918       111\n",
      "           6     0.0000    0.0000    0.0000        32\n",
      "\n",
      "   micro avg     0.5613    0.5613    0.5613      1842\n",
      "   macro avg     0.1414    0.1409    0.1398      1842\n",
      "weighted avg     0.5254    0.5613    0.5414      1842\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3280    0.2939    0.3100       347\n",
      "           1     0.3948    0.3431    0.3671       443\n",
      "           2     0.1087    0.1389    0.1220       144\n",
      "           3     0.0000    0.0000    0.0000        15\n",
      "           4     0.0137    0.0196    0.0161        51\n",
      "           5     0.0141    0.0196    0.0164        51\n",
      "           6     0.0455    0.0833    0.0588        12\n",
      "\n",
      "   micro avg     0.2606    0.2606    0.2606      1063\n",
      "   macro avg     0.1292    0.1284    0.1272      1063\n",
      "weighted avg     0.2882    0.2606    0.2730      1063\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0676    0.0847    0.0752        59\n",
      "           1     0.2660    0.2404    0.2525       208\n",
      "           2     0.4361    0.4080    0.4216       326\n",
      "           3     0.0244    0.0294    0.0267        34\n",
      "           4     0.0806    0.0746    0.0775        67\n",
      "           5     0.0615    0.0952    0.0748        42\n",
      "           6     0.0323    0.0333    0.0328        30\n",
      "\n",
      "   micro avg     0.2598    0.2598    0.2598       766\n",
      "   macro avg     0.1383    0.1380    0.1373       766\n",
      "weighted avg     0.2758    0.2598    0.2671       766\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1667    0.0833    0.1111        24\n",
      "           1     0.1000    0.0606    0.0755        33\n",
      "           2     0.2545    0.3043    0.2772        46\n",
      "           3     0.2391    0.2895    0.2619        38\n",
      "           4     0.1200    0.1304    0.1250        23\n",
      "           5     0.0476    0.0588    0.0526        17\n",
      "           6     0.0833    0.1000    0.0909        10\n",
      "\n",
      "   micro avg     0.1780    0.1780    0.1780       191\n",
      "   macro avg     0.1445    0.1467    0.1420       191\n",
      "weighted avg     0.1702    0.1780    0.1704       191\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1667    0.1613    0.1639        31\n",
      "           1     0.1692    0.2000    0.1833        55\n",
      "           2     0.2794    0.3220    0.2992        59\n",
      "           3     0.0556    0.0370    0.0444        27\n",
      "           4     0.0667    0.0667    0.0667        30\n",
      "           5     0.0000    0.0000    0.0000        17\n",
      "           6     0.0000    0.0000    0.0000        12\n",
      "\n",
      "   micro avg     0.1645    0.1645    0.1645       231\n",
      "   macro avg     0.1054    0.1124    0.1082       231\n",
      "weighted avg     0.1492    0.1645    0.1559       231\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2439    0.1370    0.1754        73\n",
      "           1     0.2766    0.3377    0.3041        77\n",
      "           2     0.1889    0.2361    0.2099        72\n",
      "           3     0.0000    0.0000    0.0000        10\n",
      "           4     0.0417    0.0370    0.0392        27\n",
      "           5     0.0909    0.0909    0.0909        44\n",
      "           6     0.1500    0.1765    0.1622        17\n",
      "\n",
      "   micro avg     0.1906    0.1906    0.1906       320\n",
      "   macro avg     0.1417    0.1450    0.1402       320\n",
      "weighted avg     0.1887    0.1906    0.1848       320\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3077    0.1600    0.2105        25\n",
      "           1     0.1667    0.1111    0.1333        45\n",
      "           2     0.1429    0.2326    0.1770        43\n",
      "           3     0.0556    0.0714    0.0625        14\n",
      "           4     0.0769    0.0769    0.0769        13\n",
      "           5     0.0000    0.0000    0.0000        16\n",
      "           6     0.1765    0.1200    0.1429        25\n",
      "\n",
      "   micro avg     0.1326    0.1326    0.1326       181\n",
      "   macro avg     0.1323    0.1103    0.1147       181\n",
      "weighted avg     0.1521    0.1326    0.1344       181\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    true_dict, pred_dict = test_confusion_metrrix_seperated(to_be_printed_df[i])\n",
    "    for i in range(len(true_dict)):\n",
    "        true_list, pred_list = true_dict[i], pred_dict[i]\n",
    "        print(i, classification_report(true_list, pred_list,   digits = 4))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卡方適合度檢定 方法一\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chi2(df, n_month = 13, cut_first_month = False):\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    test_dict = dict()\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "\n",
    "        a_dict_for_markov[memberID] = [0]*n_month\n",
    "        test_dict[memberID] = [0]*(15-n_month)\n",
    "\n",
    "            \n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 是session\n",
    "            34+j 是 M\n",
    "            20+J 是 F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            \n",
    "            if j > n_month - 2 :\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    test_dict[memberID][j-n_month] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 3\n",
    "          \n",
    "            if j < n_month  :\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 3\n",
    "                    \n",
    "        if cut_first_month:\n",
    "            a_dict_for_markov[memberID] = a_dict_for_markov[memberID][1:]\n",
    "            \n",
    "    a_df = path(a_dict_for_markov, False)\n",
    "    test_df, cnt =  path(test_dict, False, True)\n",
    "    \n",
    "    return a_df, test_df, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "def chi2(a_df, test_df, n_dict, print_out = False):\n",
    "    \n",
    "    for i in range(len(n_dict)):\n",
    "        n = n_dict[str(i)]\n",
    "        \n",
    "        expected = np.array( a_df.iloc[i,:] * n )\n",
    "        true = np.array( test_df.iloc[i,:] * n )\n",
    "        chi, p = chisquare( true, expected  )\n",
    "        \n",
    "        if print_out:\n",
    "            print(i, 'p value =', p)\n",
    "            print( true - expected   )\n",
    "            continue\n",
    "            \n",
    "        if p < 0.01:\n",
    "            error = list(  (expected-true) )\n",
    "            max_ = max(error)\n",
    "            min_ = min(error)\n",
    "            idx1, idx2 = error.index(max_),  error.index(min_)\n",
    "            print(i, 'is not the same distribution. The reason is %d greater than expected(%0.2f) and %d is smaller(%0.2f)'%(idx1, max_,idx2,min_ ) )\n",
    "            \n",
    "        elif p<0.05:\n",
    "            error = list(  (expected-true) )\n",
    "            max_ = max(error)\n",
    "            min_ = min(error)\n",
    "            idx1, idx2 = error.index(max_),  error.index(min_)\n",
    "            print(i, '%0.3f is p value, might be the same distribution. %d greater than expected(%0.2f) and %d is smaller(%0.2f)'%(p,idx1, max_,idx2,min_ ) )\n",
    "        else:\n",
    "            print(i, 'is the same distribution.')\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is not the same distribution. The reason is 1 greater than expected(1002.68) and 0 is smaller(-1944.87)\n",
      "1 is not the same distribution. The reason is 1 greater than expected(37.91) and 0 is smaller(-36.02)\n",
      "2 is the same distribution.\n",
      "3 is the same distribution.\n",
      "4 is the same distribution.\n",
      "5 is the same distribution.\n",
      "6 is the same distribution.\n",
      "\n",
      "offline\n",
      "0 is not the same distribution. The reason is 0 greater than expected(1458.70) and 1 is smaller(-1297.80)\n",
      "1 is not the same distribution. The reason is 2 greater than expected(50.34) and 5 is smaller(-68.11)\n",
      "2 is not the same distribution. The reason is 1 greater than expected(106.33) and 2 is smaller(-105.29)\n",
      "3 is not the same distribution. The reason is 2 greater than expected(36.68) and 0 is smaller(-158.75)\n",
      "4 is not the same distribution. The reason is 1 greater than expected(161.75) and 0 is smaller(-456.48)\n",
      "5 is not the same distribution. The reason is 1 greater than expected(246.92) and 0 is smaller(-557.64)\n",
      "6 is not the same distribution. The reason is 1 greater than expected(69.68) and 0 is smaller(-157.92)\n",
      "\n",
      "深思熟慮\n",
      "0 is not the same distribution. The reason is 2 greater than expected(37.26) and 1 is smaller(-109.82)\n",
      "1 is not the same distribution. The reason is 2 greater than expected(60.61) and 1 is smaller(-84.71)\n",
      "2 is not the same distribution. The reason is 5 greater than expected(37.45) and 2 is smaller(-106.48)\n",
      "3 is not the same distribution. The reason is 5 greater than expected(1.80) and 0 is smaller(-6.92)\n",
      "4 is not the same distribution. The reason is 5 greater than expected(18.59) and 2 is smaller(-18.29)\n",
      "5 0.033 is p value, might be the same distribution. 3 greater than expected(5.76) and 0 is smaller(-13.52)\n",
      "6 is not the same distribution. The reason is 2 greater than expected(6.82) and 0 is smaller(-6.57)\n",
      "\n",
      "一般人\n",
      "0 is not the same distribution. The reason is 5 greater than expected(35.56) and 1 is smaller(-103.91)\n",
      "1 is not the same distribution. The reason is 5 greater than expected(27.33) and 1 is smaller(-65.24)\n",
      "2 is not the same distribution. The reason is 0 greater than expected(30.13) and 2 is smaller(-97.68)\n",
      "3 is the same distribution.\n",
      "4 is not the same distribution. The reason is 1 greater than expected(12.37) and 3 is smaller(-9.45)\n",
      "5 is not the same distribution. The reason is 1 greater than expected(22.20) and 0 is smaller(-16.55)\n",
      "6 is not the same distribution. The reason is 5 greater than expected(8.52) and 6 is smaller(-8.71)\n",
      "\n",
      "衝動購物\n",
      "0 is not the same distribution. The reason is 0 greater than expected(105.77) and 1 is smaller(-157.83)\n",
      "1 is not the same distribution. The reason is 0 greater than expected(59.63) and 1 is smaller(-31.80)\n",
      "2 is not the same distribution. The reason is 1 greater than expected(32.35) and 2 is smaller(-27.91)\n",
      "3 is not the same distribution. The reason is 5 greater than expected(6.29) and 0 is smaller(-12.80)\n",
      "4 is not the same distribution. The reason is 1 greater than expected(18.96) and 0 is smaller(-25.10)\n",
      "5 is not the same distribution. The reason is 2 greater than expected(46.25) and 0 is smaller(-71.68)\n",
      "6 is not the same distribution. The reason is 2 greater than expected(14.83) and 0 is smaller(-21.23)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive', 'offline', '深思熟慮', '一般人', '衝動購物']\n",
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    a_df, test_df, n = test_chi2(to_be_printed_df[i])\n",
    "    chi2(a_df, test_df, n)\n",
    "    \n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把差距print出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p value = 2.6353512376900167e-306\n",
      "[ 1944.8682519  -1002.68297461  -297.16043191   -55.04906811\n",
      "  -219.04223031  -297.5649097    -73.36863726]\n",
      "1 p value = 5.15442587375762e-05\n",
      "[ 36.02281044 -37.90622756  -8.49936733  -0.05878732   6.853083\n",
      "   1.76491912   1.82356965]\n",
      "2 p value = nan\n",
      "[-0.18617933 -1.10527318 -0.47610889         nan  0.58918713  0.30477822\n",
      "  0.93679802]\n",
      "3 p value = nan\n",
      "[0.38238702 0.21436848        nan 1.53070684        nan        nan\n",
      "        nan]\n",
      "4 p value = nan\n",
      "[  6.96991847 -10.49732921          nan   2.78408771   1.20832162\n",
      "   0.20832162   0.51419736]\n",
      "5 p value = nan\n",
      "[  7.29205255 -11.60650442  -0.24186948   2.81972862   1.45918587\n",
      "          nan   1.55933664]\n",
      "6 p value = nan\n",
      "[ 0.23156089 -1.97169811  0.54802744  0.78730703         nan  0.09605489\n",
      "  0.60120069]\n",
      "\n",
      "offline\n",
      "0 p value = 0.0\n",
      "[-1458.70177302  1297.80185979   147.29487263   -40.69537513\n",
      "    -8.3453175     55.70621527     6.93951796]\n",
      "1 p value = 1.8053408700130813e-08\n",
      "[-39.0524869   -2.10638681 -50.33783784 -34.35512794  61.04290412\n",
      "  68.10574453  -3.29680917]\n",
      "2 p value = 1.0168488869548697e-07\n",
      "[ -51.17109437 -106.32652657  105.29183188   -5.52180809   12.46570182\n",
      "   48.78370341   -3.52180809]\n",
      "3 p value = 1.0217836386201128e-66\n",
      "[158.74713271 -17.96613872 -36.68214091 -34.56635718 -10.36045877\n",
      " -23.69142545 -35.48061169]\n",
      "4 p value = 2.0197175777301004e-227\n",
      "[ 456.4797663  -161.74602629 -127.77111436  -36.95274508  -33.0604863\n",
      "  -63.30956268  -33.6398316 ]\n",
      "5 p value = 0.0\n",
      "[ 5.57639462e+02 -2.46921146e+02 -2.34505478e+02 -1.11585713e+01\n",
      "  3.05150548e-01 -5.01249245e+01 -1.52344923e+01]\n",
      "6 p value = 6.581819188388974e-59\n",
      "[157.92379679 -69.67780749 -47.28475936  -2.2473262    7.29679144\n",
      " -38.30882353  -7.70187166]\n",
      "\n",
      "深思熟慮\n",
      "0 p value = 1.2067868934427665e-25\n",
      "[-33.00351391 109.81756955 -37.25534407  -4.4579795  -13.72796486\n",
      " -16.21698389  -5.15578331]\n",
      "1 p value = 3.1195778958604785e-06\n",
      "[-16.79515685  84.70776004 -60.60550358  -2.73571822  -3.00198129\n",
      "  -2.81397909   1.24457898]\n",
      "2 p value = 5.610089270197762e-05\n",
      "[-19.27987088 -21.80885405 106.4842979    0.67110906 -21.44961955\n",
      " -37.4522481   -7.16481439]\n",
      "3 p value = 3.2481320888851084e-08\n",
      "[ 6.91958495 -1.25810636 -0.97276265 -0.49546044 -0.92736706 -1.8002594\n",
      " -1.46562905]\n",
      "4 p value = 0.00012937214610978006\n",
      "[  9.84113093  -9.36216762  18.290138    -1.20363514   3.38269943\n",
      " -18.59171996  -2.35644564]\n",
      "5 p value = 0.03256337869431789\n",
      "[13.5206017   1.50752126 -4.82799215 -5.76193591 -3.47678221  3.49051668\n",
      " -4.45192937]\n",
      "6 p value = 0.0005334771826530521\n",
      "[ 6.57344398 -0.20912863 -6.82406639 -0.63900415 -4.78008299  4.72780083\n",
      "  1.15103734]\n",
      "\n",
      "一般人\n",
      "0 p value = 2.095964068244448e-26\n",
      "[ -0.97601933 103.91132453 -10.51555503 -15.67746877 -31.52993165\n",
      " -35.56322178  -9.64912798]\n",
      "1 p value = 1.3613509562055747e-05\n",
      "[-11.21739994  65.23696494   4.78528156  -5.86026418 -21.35693713\n",
      " -27.32982421  -4.25782103]\n",
      "2 p value = 9.217300504809814e-07\n",
      "[-30.13203763 -13.98630516  97.68446535 -14.78454835 -25.41720847\n",
      "  -3.85468253  -9.50968322]\n",
      "3 p value = 0.539343130319814\n",
      "[ 2.33908046  0.54022989  1.75287356  4.98850575 -3.35057471 -4.67241379\n",
      " -1.59770115]\n",
      "4 p value = 0.009022973341810084\n",
      "[  9.10442795 -12.37471206   0.71922191   9.45124136  -9.7911441\n",
      "   5.06987458  -2.17890965]\n",
      "5 p value = 0.001305965787836245\n",
      "[ 16.55141509 -22.1995283   -1.31933962  -3.37877358   3.01037736\n",
      "   0.1740566    7.16179245]\n",
      "6 p value = 0.007857124156567625\n",
      "[ 6.84993998 -4.30432173  0.81272509 -0.78931573 -2.75930372 -8.51860744\n",
      "  8.70888355]\n",
      "\n",
      "衝動購物\n",
      "0 p value = 5.396760152739762e-32\n",
      "[-105.7707917   157.83351268   -9.61921599   -0.39477325  -34.55203689\n",
      "   -8.60122982    1.10453497]\n",
      "1 p value = 2.7777956940222076e-09\n",
      "[-59.62716763  31.80057803  15.62283237  10.99855491 -18.15751445\n",
      "  -4.28612717  23.64884393]\n",
      "2 p value = 0.0007024428618374386\n",
      "[-21.41672458 -32.34769516  27.91104934   9.0196896   -5.97475098\n",
      "  11.8637943   10.94463748]\n",
      "3 p value = 0.0013610076248341864\n",
      "[12.80168776 -1.87763713 -5.66244726 -1.49367089  3.03375527 -6.28691983\n",
      " -0.51476793]\n",
      "4 p value = 7.362862929753037e-06\n",
      "[ 25.10277861 -18.95637885 -15.18255154  -1.29040932  -3.43979683\n",
      "   9.91574544   3.85061249]\n",
      "5 p value = 4.970512230606552e-35\n",
      "[ 71.68235978 -37.0749782  -46.24818367   4.78901482  -1.87939552\n",
      "   8.23307178   0.49811101]\n",
      "6 p value = 3.468173282927711e-10\n",
      "[ 21.23404255 -10.80425532 -14.82553191  -2.03829787   2.21276596\n",
      "  -2.57446809   6.79574468]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive', 'offline', '深思熟慮', '一般人', '衝動購物']\n",
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    a_df, test_df, n = test_chi2(to_be_printed_df[i])\n",
    "    chi2(a_df, test_df, n, True)\n",
    "    \n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
