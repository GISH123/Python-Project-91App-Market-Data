{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('91app_features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['memberid', 'online_ratio', 'total_day_using_percentage',\n",
       "       'actually_using_percentage', 'view_per_date', 'view_per_session',\n",
       "       'session_per_date', 'total_conversion_rate',\n",
       "       'converion_rate_without_offline_return', 'off_cart_c', 'off_fav_c',\n",
       "       'off_view_c', 'on_cart_c', 'on_fav_c', 'on_view_c', 'total_cart_c',\n",
       "       'total_fav_c', 'total_view_c', 'viewtime_ave', 'view_time_med',\n",
       "       '201803F', '201804F', '201805F', '201806F', '201807F', '201808F',\n",
       "       '201809F', '201810F', '201811F', '201812F', '201901F', '201902F',\n",
       "       '201903F', '201904F', '201803M', '201804M', '201805M', '201806M',\n",
       "       '201807M', '201808M', '201809M', '201810M', '201811M', '201812M',\n",
       "       '201901M', '201902M', '201903M', '201904M', '201803S', '201804S',\n",
       "       '201805S', '201806S', '201807S', '201808S', '201809S', '201810S',\n",
       "       '201811S', '201812S', '201901S', '201902S', '201903S', '201904S',\n",
       "       'total_F', 'total_M', 'total_S', 'ave_M', 'ave_M_not_offline_return',\n",
       "       'off_return_item_number', 'off_return_frequency',\n",
       "       'total_discount_percentage', 'online_ratio_without_offline_return',\n",
       "       'buy_time_without_offline_return', 'session_number', 'off_mix_c',\n",
       "       'on_mix_c', 'total_mix_c', 'cart_med_time', 'cart_ave_time',\n",
       "       'cart_within_3', 'cart_within_24', 'view_count_med', 'view_count_ave'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>memberid</th>\n",
       "      <th>online_ratio</th>\n",
       "      <th>total_day_using_percentage</th>\n",
       "      <th>actually_using_percentage</th>\n",
       "      <th>view_per_date</th>\n",
       "      <th>view_per_session</th>\n",
       "      <th>session_per_date</th>\n",
       "      <th>total_conversion_rate</th>\n",
       "      <th>converion_rate_without_offline_return</th>\n",
       "      <th>off_cart_c</th>\n",
       "      <th>...</th>\n",
       "      <th>session_number</th>\n",
       "      <th>off_mix_c</th>\n",
       "      <th>on_mix_c</th>\n",
       "      <th>total_mix_c</th>\n",
       "      <th>cart_med_time</th>\n",
       "      <th>cart_ave_time</th>\n",
       "      <th>cart_within_3</th>\n",
       "      <th>cart_within_24</th>\n",
       "      <th>view_count_med</th>\n",
       "      <th>view_count_ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022923</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027160</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>314792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>394660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>437828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>439730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>519517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>662692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>699538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>908710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>4.107143</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1021490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1033408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1047526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1088973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059946</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>3.590909</td>\n",
       "      <td>2.468750</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1150554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1177990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1210881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1223922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1257310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1257916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1260695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033573</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1266911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1346508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1385861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1387680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1423753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1425472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76371</th>\n",
       "      <td>58899632S3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062657</td>\n",
       "      <td>0.065274</td>\n",
       "      <td>23.480000</td>\n",
       "      <td>20.241379</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408560</td>\n",
       "      <td>0.408560</td>\n",
       "      <td>557.0</td>\n",
       "      <td>830.869565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76372</th>\n",
       "      <td>58899643S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>8.203704</td>\n",
       "      <td>5.034091</td>\n",
       "      <td>1.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76373</th>\n",
       "      <td>58899663S1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76374</th>\n",
       "      <td>58899682S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.110410</td>\n",
       "      <td>5.257143</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76375</th>\n",
       "      <td>58899732S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>3.068966</td>\n",
       "      <td>2.781250</td>\n",
       "      <td>1.103448</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76376</th>\n",
       "      <td>58899761S2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>0.089514</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>7.837838</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>1.054054</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76377</th>\n",
       "      <td>58899763S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76378</th>\n",
       "      <td>58899772S9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76379</th>\n",
       "      <td>58899784S0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.052493</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>8.958333</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533350</td>\n",
       "      <td>0.533350</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>7602.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76380</th>\n",
       "      <td>58899788S2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76381</th>\n",
       "      <td>58899795S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76382</th>\n",
       "      <td>58899867S9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>2.588235</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>152.0</td>\n",
       "      <td>454.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76383</th>\n",
       "      <td>58899873S0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154034</td>\n",
       "      <td>0.154034</td>\n",
       "      <td>10.349206</td>\n",
       "      <td>8.253165</td>\n",
       "      <td>1.253968</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>5598.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76384</th>\n",
       "      <td>58899904S1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.269122</td>\n",
       "      <td>1.305263</td>\n",
       "      <td>1.192308</td>\n",
       "      <td>1.094737</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76385</th>\n",
       "      <td>58899909S0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182957</td>\n",
       "      <td>0.185279</td>\n",
       "      <td>6.315068</td>\n",
       "      <td>5.488095</td>\n",
       "      <td>1.150685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76386</th>\n",
       "      <td>58899968S3</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>7.160305</td>\n",
       "      <td>4.609337</td>\n",
       "      <td>1.553435</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>0.073710</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>407</td>\n",
       "      <td>0.092994</td>\n",
       "      <td>0.384025</td>\n",
       "      <td>0.148429</td>\n",
       "      <td>16547.0</td>\n",
       "      <td>22978.823529</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76387</th>\n",
       "      <td>635588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76388</th>\n",
       "      <td>9238639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76389</th>\n",
       "      <td>9387834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76390</th>\n",
       "      <td>9440111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76391</th>\n",
       "      <td>9444853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76392</th>\n",
       "      <td>9451359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76393</th>\n",
       "      <td>9456161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76394</th>\n",
       "      <td>9482145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76395</th>\n",
       "      <td>9491040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76396</th>\n",
       "      <td>9589297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76397</th>\n",
       "      <td>9594328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083135</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>4.542857</td>\n",
       "      <td>3.697674</td>\n",
       "      <td>1.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76398</th>\n",
       "      <td>9621833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76399</th>\n",
       "      <td>9637776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76400</th>\n",
       "      <td>9754589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76401 rows  82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         memberid  online_ratio  total_day_using_percentage  \\\n",
       "0           23722           NaN                    0.002849   \n",
       "1           44751           NaN                    0.022923   \n",
       "2           66732           NaN                    0.027160   \n",
       "3          108059           NaN                    0.003058   \n",
       "4          257559           NaN                    0.006061   \n",
       "5          314792           NaN                    0.006116   \n",
       "6          394660           NaN                    0.012019   \n",
       "7          437828           NaN                    0.002770   \n",
       "8          439730           NaN                    0.002817   \n",
       "9          519517           NaN                    0.002488   \n",
       "10         662692           NaN                    0.002941   \n",
       "11         699538           NaN                    0.003125   \n",
       "12         908710           NaN                    0.057279   \n",
       "13        1021490           NaN                    0.002410   \n",
       "14        1033408           NaN                    0.002695   \n",
       "15        1047526           NaN                    0.002469   \n",
       "16        1088973           NaN                    0.059946   \n",
       "17        1150554           NaN                    0.016627   \n",
       "18        1177990           NaN                    0.003257   \n",
       "19        1210881           NaN                    0.002545   \n",
       "20        1223922           NaN                    0.009639   \n",
       "21        1257310           NaN                    0.007481   \n",
       "22        1257916           NaN                    0.010309   \n",
       "23        1260695           NaN                    0.033573   \n",
       "24        1266911           NaN                    0.020460   \n",
       "25        1346508           NaN                    0.005076   \n",
       "26        1385861           NaN                    0.002849   \n",
       "27        1387680           NaN                    0.033981   \n",
       "28        1423753           NaN                    0.002421   \n",
       "29        1425472           NaN                    0.013405   \n",
       "...           ...           ...                         ...   \n",
       "76371  58899632S3      1.000000                    0.062657   \n",
       "76372  58899643S0           NaN                    0.580645   \n",
       "76373  58899663S1      0.000000                    0.027027   \n",
       "76374  58899682S0           NaN                    0.084746   \n",
       "76375  58899732S3      0.000000                    0.252174   \n",
       "76376  58899761S2      0.000000                    0.088161   \n",
       "76377  58899763S0           NaN                    0.026634   \n",
       "76378  58899772S9      0.000000                    0.004292   \n",
       "76379  58899784S0      1.000000                    0.050251   \n",
       "76380  58899788S2      0.000000                    0.085714   \n",
       "76381  58899795S3           NaN                    0.008403   \n",
       "76382  58899867S9      1.000000                    0.089552   \n",
       "76383  58899873S0      1.000000                    0.154034   \n",
       "76384  58899904S1      0.000000                    0.237500   \n",
       "76385  58899909S0           NaN                    0.182957   \n",
       "76386  58899968S3      0.129032                    0.655000   \n",
       "76387      635588           NaN                    0.005495   \n",
       "76388     9238639           NaN                    0.003077   \n",
       "76389     9387834           NaN                    0.009317   \n",
       "76390     9440111           NaN                    0.020050   \n",
       "76391     9444853           NaN                    0.003125   \n",
       "76392     9451359           NaN                    0.026316   \n",
       "76393     9456161           NaN                    0.029484   \n",
       "76394     9482145           NaN                    0.013441   \n",
       "76395     9491040           NaN                    0.026634   \n",
       "76396     9589297           NaN                    0.005128   \n",
       "76397     9594328           NaN                    0.083135   \n",
       "76398     9621833           NaN                    0.013193   \n",
       "76399     9637776           NaN                    0.018182   \n",
       "76400     9754589           NaN                    0.005970   \n",
       "\n",
       "       actually_using_percentage  view_per_date  view_per_session  \\\n",
       "0                       1.000000       1.000000          1.000000   \n",
       "1                       0.026846       3.875000          2.583333   \n",
       "2                       0.108911       4.363636          4.000000   \n",
       "3                       1.000000       2.000000          2.000000   \n",
       "4                       0.250000       1.500000          1.500000   \n",
       "5                       0.016529       1.000000          1.000000   \n",
       "6                       0.016129       1.600000          1.600000   \n",
       "7                       1.000000       1.000000          1.000000   \n",
       "8                       1.000000       3.000000          1.500000   \n",
       "9                       1.000000       4.000000          4.000000   \n",
       "10                      1.000000       4.000000          4.000000   \n",
       "11                      1.000000       5.000000          5.000000   \n",
       "12                      0.068182       4.791667          4.107143   \n",
       "13                      1.000000       1.000000          1.000000   \n",
       "14                      1.000000       1.000000          1.000000   \n",
       "15                      1.000000       1.000000          1.000000   \n",
       "16                      0.261905       3.590909          2.468750   \n",
       "17                      0.122807       2.285714          2.285714   \n",
       "18                      1.000000       3.000000          3.000000   \n",
       "19                      1.000000       1.000000          1.000000   \n",
       "20                      0.040816       4.000000          3.200000   \n",
       "21                      0.076923       1.333333          1.333333   \n",
       "22                      0.072727       2.750000          2.750000   \n",
       "23                      0.264151       4.857143          4.250000   \n",
       "24                      0.093023       4.375000          3.888889   \n",
       "25                      0.038462       2.000000          1.333333   \n",
       "26                      1.000000       3.000000          3.000000   \n",
       "27                      0.038462       2.142857          2.142857   \n",
       "28                      1.000000       1.000000          1.000000   \n",
       "29                      0.121951       2.800000          2.333333   \n",
       "...                          ...            ...               ...   \n",
       "76371                   0.065274      23.480000         20.241379   \n",
       "76372                   0.586957       8.203704          5.034091   \n",
       "76373                   0.030769       1.500000          1.500000   \n",
       "76374                   0.110410       5.257143          4.600000   \n",
       "76375                   0.252174       3.068966          2.781250   \n",
       "76376                   0.089514       8.285714          7.837838   \n",
       "76377                   0.177419       6.090909          6.090909   \n",
       "76378                   1.000000       1.000000          1.000000   \n",
       "76379                   0.052493      10.750000          8.958333   \n",
       "76380                   0.187500       1.666667          1.666667   \n",
       "76381                   0.035714       3.000000          3.000000   \n",
       "76382                   0.094937       2.933333          2.588235   \n",
       "76383                   0.154034      10.349206          8.253165   \n",
       "76384                   0.269122       1.305263          1.192308   \n",
       "76385                   0.185279       6.315068          5.488095   \n",
       "76386                   0.655000       7.160305          4.609337   \n",
       "76387                   0.034483       5.500000          5.500000   \n",
       "76388                   1.000000       4.000000          4.000000   \n",
       "76389                   0.018072       5.333333          5.333333   \n",
       "76390                   0.020888       1.625000          1.625000   \n",
       "76391                   1.000000       2.000000          2.000000   \n",
       "76392                   0.057895       2.636364          2.636364   \n",
       "76393                   0.110092       5.166667          3.444444   \n",
       "76394                   0.059524       3.600000          3.600000   \n",
       "76395                   0.103774       3.000000          2.200000   \n",
       "76396                   0.058824       1.000000          1.000000   \n",
       "76397                   0.330189       4.542857          3.697674   \n",
       "76398                   0.094340       1.200000          1.000000   \n",
       "76399                   0.055046       4.833333          3.625000   \n",
       "76400                   0.125000       2.000000          1.333333   \n",
       "\n",
       "       session_per_date  total_conversion_rate  \\\n",
       "0              1.000000               0.000000   \n",
       "1              1.500000               0.000000   \n",
       "2              1.090909               0.000000   \n",
       "3              1.000000               0.000000   \n",
       "4              1.000000               0.000000   \n",
       "5              1.000000               0.000000   \n",
       "6              1.000000               0.000000   \n",
       "7              1.000000               0.000000   \n",
       "8              2.000000               0.000000   \n",
       "9              1.000000               0.000000   \n",
       "10             1.000000               0.000000   \n",
       "11             1.000000               0.000000   \n",
       "12             1.166667               0.000000   \n",
       "13             1.000000               0.000000   \n",
       "14             1.000000               0.000000   \n",
       "15             1.000000               0.000000   \n",
       "16             1.454545               0.000000   \n",
       "17             1.000000               0.000000   \n",
       "18             1.000000               0.000000   \n",
       "19             1.000000               0.000000   \n",
       "20             1.250000               0.000000   \n",
       "21             1.000000               0.000000   \n",
       "22             1.000000               0.000000   \n",
       "23             1.142857               0.000000   \n",
       "24             1.125000               0.000000   \n",
       "25             1.500000               0.000000   \n",
       "26             1.000000               0.000000   \n",
       "27             1.000000               0.000000   \n",
       "28             1.000000               0.000000   \n",
       "29             1.200000               0.000000   \n",
       "...                 ...                    ...   \n",
       "76371          1.160000               0.172414   \n",
       "76372          1.629630               0.000000   \n",
       "76373          1.000000               0.500000   \n",
       "76374          1.142857               0.000000   \n",
       "76375          1.103448               0.031250   \n",
       "76376          1.057143               1.054054   \n",
       "76377          1.000000               0.000000   \n",
       "76378          1.000000               1.000000   \n",
       "76379          1.200000               0.083333   \n",
       "76380          1.000000               0.666667   \n",
       "76381          1.000000               0.000000   \n",
       "76382          1.133333               0.029412   \n",
       "76383          1.253968               0.012658   \n",
       "76384          1.094737               0.009615   \n",
       "76385          1.150685               0.000000   \n",
       "76386          1.553435               0.076167   \n",
       "76387          1.000000               0.000000   \n",
       "76388          1.000000               0.000000   \n",
       "76389          1.000000               0.000000   \n",
       "76390          1.000000               0.000000   \n",
       "76391          1.000000               0.000000   \n",
       "76392          1.000000               0.000000   \n",
       "76393          1.500000               0.000000   \n",
       "76394          1.000000               0.000000   \n",
       "76395          1.363636               0.000000   \n",
       "76396          1.000000               0.000000   \n",
       "76397          1.228571               0.000000   \n",
       "76398          1.200000               0.000000   \n",
       "76399          1.333333               0.000000   \n",
       "76400          1.500000               0.000000   \n",
       "\n",
       "       converion_rate_without_offline_return  off_cart_c  ...  session_number  \\\n",
       "0                                   0.000000         NaN  ...               1   \n",
       "1                                   0.000000         NaN  ...              12   \n",
       "2                                   0.000000         NaN  ...              12   \n",
       "3                                   0.000000         NaN  ...               1   \n",
       "4                                   0.000000         NaN  ...               2   \n",
       "5                                   0.000000         NaN  ...               2   \n",
       "6                                   0.000000         NaN  ...               5   \n",
       "7                                   0.000000         NaN  ...               1   \n",
       "8                                   0.000000         NaN  ...               2   \n",
       "9                                   0.000000         NaN  ...               1   \n",
       "10                                  0.000000         NaN  ...               1   \n",
       "11                                  0.000000         NaN  ...               1   \n",
       "12                                  0.000000         NaN  ...              28   \n",
       "13                                  0.000000         NaN  ...               1   \n",
       "14                                  0.000000         NaN  ...               1   \n",
       "15                                  0.000000         NaN  ...               1   \n",
       "16                                  0.000000         NaN  ...              32   \n",
       "17                                  0.000000         NaN  ...               7   \n",
       "18                                  0.000000         NaN  ...               1   \n",
       "19                                  0.000000         NaN  ...               1   \n",
       "20                                  0.000000         NaN  ...               5   \n",
       "21                                  0.000000         NaN  ...               3   \n",
       "22                                  0.000000         NaN  ...               4   \n",
       "23                                  0.000000         NaN  ...              16   \n",
       "24                                  0.000000         NaN  ...               9   \n",
       "25                                  0.000000         NaN  ...               3   \n",
       "26                                  0.000000         NaN  ...               1   \n",
       "27                                  0.000000         NaN  ...              14   \n",
       "28                                  0.000000         NaN  ...               1   \n",
       "29                                  0.000000         NaN  ...               6   \n",
       "...                                      ...         ...  ...             ...   \n",
       "76371                               0.172414         NaN  ...              29   \n",
       "76372                               0.000000         NaN  ...              88   \n",
       "76373                               0.500000         NaN  ...               2   \n",
       "76374                               0.000000         NaN  ...              40   \n",
       "76375                               0.031250         NaN  ...              32   \n",
       "76376                               0.783784         NaN  ...              37   \n",
       "76377                               0.000000         NaN  ...              11   \n",
       "76378                               0.000000         NaN  ...               1   \n",
       "76379                               0.083333         NaN  ...              24   \n",
       "76380                               0.666667         NaN  ...               3   \n",
       "76381                               0.000000         NaN  ...               2   \n",
       "76382                               0.029412         NaN  ...              34   \n",
       "76383                               0.012658         NaN  ...              79   \n",
       "76384                               0.009615         NaN  ...             104   \n",
       "76385                               0.000000         NaN  ...              84   \n",
       "76386                               0.073710    0.142857  ...             407   \n",
       "76387                               0.000000         NaN  ...               2   \n",
       "76388                               0.000000         NaN  ...               1   \n",
       "76389                               0.000000         NaN  ...               3   \n",
       "76390                               0.000000         NaN  ...               8   \n",
       "76391                               0.000000         NaN  ...               1   \n",
       "76392                               0.000000         NaN  ...              11   \n",
       "76393                               0.000000         NaN  ...              18   \n",
       "76394                               0.000000         NaN  ...               5   \n",
       "76395                               0.000000         NaN  ...              15   \n",
       "76396                               0.000000         NaN  ...               2   \n",
       "76397                               0.000000         NaN  ...              43   \n",
       "76398                               0.000000         NaN  ...               6   \n",
       "76399                               0.000000         NaN  ...               8   \n",
       "76400                               0.000000         NaN  ...               3   \n",
       "\n",
       "       off_mix_c  on_mix_c  total_mix_c  cart_med_time  cart_ave_time  \\\n",
       "0            NaN       NaN          NaN            NaN            NaN   \n",
       "1            NaN       NaN          NaN            NaN            NaN   \n",
       "2            NaN       NaN          NaN            NaN            NaN   \n",
       "3            NaN       NaN          NaN            NaN            NaN   \n",
       "4            NaN       NaN          NaN            NaN            NaN   \n",
       "5            NaN       NaN          NaN            NaN            NaN   \n",
       "6            NaN       NaN          NaN            NaN            NaN   \n",
       "7            NaN       NaN          NaN            NaN            NaN   \n",
       "8            NaN       NaN          NaN            NaN            NaN   \n",
       "9            NaN       NaN          NaN            NaN            NaN   \n",
       "10           NaN       NaN          NaN            NaN            NaN   \n",
       "11           NaN       NaN          NaN            NaN            NaN   \n",
       "12           NaN       NaN          NaN            NaN            NaN   \n",
       "13           NaN       NaN          NaN            NaN            NaN   \n",
       "14           NaN       NaN          NaN            NaN            NaN   \n",
       "15           NaN       NaN          NaN            NaN            NaN   \n",
       "16           NaN       NaN          NaN            NaN            NaN   \n",
       "17           NaN       NaN          NaN            NaN            NaN   \n",
       "18           NaN       NaN          NaN            NaN            NaN   \n",
       "19           NaN       NaN          NaN            NaN            NaN   \n",
       "20           NaN       NaN          NaN            NaN            NaN   \n",
       "21           NaN       NaN          NaN            NaN            NaN   \n",
       "22           NaN       NaN          NaN            NaN            NaN   \n",
       "23           NaN       NaN          NaN            NaN            NaN   \n",
       "24           NaN       NaN          NaN            NaN            NaN   \n",
       "25           NaN       NaN          NaN            NaN            NaN   \n",
       "26           NaN       NaN          NaN            NaN            NaN   \n",
       "27           NaN       NaN          NaN            NaN            NaN   \n",
       "28           NaN       NaN          NaN            NaN            NaN   \n",
       "29           NaN       NaN          NaN            NaN            NaN   \n",
       "...          ...       ...          ...            ...            ...   \n",
       "76371        NaN  0.408560     0.408560          557.0     830.869565   \n",
       "76372        NaN       NaN          NaN            NaN            NaN   \n",
       "76373   0.000000       NaN     0.000000            NaN            NaN   \n",
       "76374        NaN       NaN          NaN            NaN            NaN   \n",
       "76375        NaN       NaN          NaN            NaN            NaN   \n",
       "76376        NaN       NaN          NaN            NaN            NaN   \n",
       "76377        NaN       NaN          NaN            NaN            NaN   \n",
       "76378        NaN       NaN          NaN            NaN            NaN   \n",
       "76379        NaN  0.533350     0.533350         1064.0    7602.500000   \n",
       "76380        NaN       NaN          NaN            NaN            NaN   \n",
       "76381        NaN       NaN          NaN            NaN            NaN   \n",
       "76382        NaN  0.750000     0.750000          152.0     454.666667   \n",
       "76383        NaN  0.400000     0.400000         5598.0    5598.000000   \n",
       "76384        NaN       NaN          NaN            NaN            NaN   \n",
       "76385        NaN       NaN          NaN            NaN            NaN   \n",
       "76386   0.092994  0.384025     0.148429        16547.0   22978.823529   \n",
       "76387        NaN       NaN          NaN            NaN            NaN   \n",
       "76388        NaN       NaN          NaN            NaN            NaN   \n",
       "76389        NaN       NaN          NaN            NaN            NaN   \n",
       "76390        NaN       NaN          NaN            NaN            NaN   \n",
       "76391        NaN       NaN          NaN            NaN            NaN   \n",
       "76392        NaN       NaN          NaN            NaN            NaN   \n",
       "76393        NaN       NaN          NaN            NaN            NaN   \n",
       "76394        NaN       NaN          NaN            NaN            NaN   \n",
       "76395        NaN       NaN          NaN            NaN            NaN   \n",
       "76396        NaN       NaN          NaN            NaN            NaN   \n",
       "76397        NaN       NaN          NaN            NaN            NaN   \n",
       "76398        NaN       NaN          NaN            NaN            NaN   \n",
       "76399        NaN       NaN          NaN            NaN            NaN   \n",
       "76400        NaN       NaN          NaN            NaN            NaN   \n",
       "\n",
       "       cart_within_3  cart_within_24  view_count_med  view_count_ave  \n",
       "0                NaN             NaN             NaN             NaN  \n",
       "1                NaN             NaN             NaN             NaN  \n",
       "2                NaN             NaN             NaN             NaN  \n",
       "3                NaN             NaN             NaN             NaN  \n",
       "4                NaN             NaN             NaN             NaN  \n",
       "5                NaN             NaN             NaN             NaN  \n",
       "6                NaN             NaN             NaN             NaN  \n",
       "7                NaN             NaN             NaN             NaN  \n",
       "8                NaN             NaN             NaN             NaN  \n",
       "9                NaN             NaN             NaN             NaN  \n",
       "10               NaN             NaN             NaN             NaN  \n",
       "11               NaN             NaN             NaN             NaN  \n",
       "12               NaN             NaN             NaN             NaN  \n",
       "13               NaN             NaN             NaN             NaN  \n",
       "14               NaN             NaN             NaN             NaN  \n",
       "15               NaN             NaN             NaN             NaN  \n",
       "16               NaN             NaN             NaN             NaN  \n",
       "17               NaN             NaN             NaN             NaN  \n",
       "18               NaN             NaN             NaN             NaN  \n",
       "19               NaN             NaN             NaN             NaN  \n",
       "20               NaN             NaN             NaN             NaN  \n",
       "21               NaN             NaN             NaN             NaN  \n",
       "22               NaN             NaN             NaN             NaN  \n",
       "23               NaN             NaN             NaN             NaN  \n",
       "24               NaN             NaN             NaN             NaN  \n",
       "25               NaN             NaN             NaN             NaN  \n",
       "26               NaN             NaN             NaN             NaN  \n",
       "27               NaN             NaN             NaN             NaN  \n",
       "28               NaN             NaN             NaN             NaN  \n",
       "29               NaN             NaN             NaN             NaN  \n",
       "...              ...             ...             ...             ...  \n",
       "76371       1.000000             1.0             1.0        1.636364  \n",
       "76372            NaN             NaN             NaN             NaN  \n",
       "76373            NaN             NaN             NaN             NaN  \n",
       "76374            NaN             NaN             NaN             NaN  \n",
       "76375            NaN             NaN             NaN             NaN  \n",
       "76376            NaN             NaN             1.0        1.200000  \n",
       "76377            NaN             NaN             NaN             NaN  \n",
       "76378            NaN             NaN             NaN             NaN  \n",
       "76379       0.750000             1.0             2.0        2.200000  \n",
       "76380            NaN             NaN             NaN             NaN  \n",
       "76381            NaN             NaN             NaN             NaN  \n",
       "76382       1.000000             1.0             2.0        1.666667  \n",
       "76383       1.000000             1.0             2.5        2.500000  \n",
       "76384            NaN             NaN             NaN             NaN  \n",
       "76385            NaN             NaN             NaN             NaN  \n",
       "76386       0.470588             1.0             2.0        2.619048  \n",
       "76387            NaN             NaN             NaN             NaN  \n",
       "76388            NaN             NaN             NaN             NaN  \n",
       "76389            NaN             NaN             NaN             NaN  \n",
       "76390            NaN             NaN             NaN             NaN  \n",
       "76391            NaN             NaN             NaN             NaN  \n",
       "76392            NaN             NaN             NaN             NaN  \n",
       "76393            NaN             NaN             NaN             NaN  \n",
       "76394            NaN             NaN             NaN             NaN  \n",
       "76395            NaN             NaN             NaN             NaN  \n",
       "76396            NaN             NaN             NaN             NaN  \n",
       "76397            NaN             NaN             NaN             NaN  \n",
       "76398            NaN             NaN             NaN             NaN  \n",
       "76399            NaN             NaN             NaN             NaN  \n",
       "76400            NaN             NaN             NaN             NaN  \n",
       "\n",
       "[76401 rows x 82 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76401, 82)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18015.0\n",
       "mean         1.0\n",
       "std          0.0\n",
       "min          1.0\n",
       "25%          1.0\n",
       "50%          1.0\n",
       "75%          1.0\n",
       "max          1.0\n",
       "Name: cart_within_24, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cart_within_24'].describe() # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inactive users are those whose total_day_using_percentage < 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inactive = df[df['total_day_using_percentage'] < 0.02]\n",
    "df_active =   df[~(df['total_day_using_percentage'] < 0.02)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25676, 50725)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inactive.shape[0], df_active.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# offline buyer are those who purchases only offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_never_buy = df_active[df_active['online_ratio'].isnull()]\n",
    "df_buy = df_active[~df_active['online_ratio'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14429, 82), (36296, 82))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_never_buy.shape, df_buy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_percentile(df, keyword, n):\n",
    "    a_list = df[keyword].tolist()\n",
    "    null_df = df[df[keyword].isnull()]\n",
    "    remaining_df = df[~df[keyword].isnull()]\n",
    "    return_list = []\n",
    "    number_list = []\n",
    "    for i in range(1, n):\n",
    "        number = np.nanpercentile(a_list, int(100/n*i) )\n",
    "        number_list.append(number)\n",
    "        a_df = remaining_df[ remaining_df[keyword] <= number]\n",
    "        remaining_df = remaining_df[~ (remaining_df[keyword] <= number)]      \n",
    "        return_list.append(a_df)\n",
    "    return_list.append(remaining_df)\n",
    "    return return_list, number_list, null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_buy[df_buy['online_ratio_without_offline_return'] <= 0.2]\n",
    "df2 = df_buy[df_buy['online_ratio_without_offline_return'] > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_drop = df_buy[df_buy['online_ratio_without_offline_return'].isnull()] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21804, 13535, 957)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape[0] , df2.shape[0], df_drop.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_rate(df1, df2, key_word):\n",
    "    \n",
    "    newdf1, newdf2 = df1[~df1[key_word].isnull()],  df2[~df2[key_word].isnull()]\n",
    "    n1, n2 = newdf1.shape[0] , newdf2.shape[0]\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return (0,0)\n",
    "    \n",
    "    m1, m2 = np.nanmean( newdf1[key_word].tolist() ), np.nanmean( newdf2[key_word].tolist() )\n",
    "    s1, s2 = np.nanstd(newdf1[key_word].tolist()), np.nanstd(newdf2[key_word].tolist())\n",
    "    differnce = m1 - m2\n",
    "    \n",
    "    sp2 = ((n1-1)*(s1**2) + (n2-1)*(s2**2)) / (n1+n2-2)\n",
    "    t = differnce / sqrt(sp2 * (1/n1+1/n2))\n",
    "    return differnce, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_important_difference(df1, df2):\n",
    "    for key_word in ['converion_rate_without_offline_return', 'total_conversion_rate','ave_M', 'ave_M_not_offline_return', 'total_M', 'total_F', 'total_S', 'session_number', 'buy_time_without_offline_return','total_day_using_percentage', 'actually_using_percentage', 'view_per_date', 'view_per_session',\n",
    "       'session_per_date', 'off_return_item_number', 'off_return_frequency', \n",
    "       'off_cart_c', 'off_fav_c', 'off_view_c', 'on_cart_c', 'on_fav_c',\n",
    "       'on_view_c', 'total_cart_c', 'total_fav_c', 'total_view_c',\n",
    "       'viewtime_ave', 'view_time_med', 'total_discount_percentage', 'online_ratio', 'online_ratio_without_offline_return', 'off_mix_c',\n",
    "       'on_mix_c', 'total_mix_c', 'cart_med_time', 'cart_ave_time',\n",
    "       'cart_within_3', 'cart_within_24', 'view_count_med', 'view_count_ave']:\n",
    "        differnce, t = difference_in_rate(df1, df2, key_word)\n",
    "        if abs( t ) > 1.96:\n",
    "            print(key_word, round(differnce, 4)  )\n",
    "        elif  abs( t ) >= 1.5:\n",
    "            print(key_word, round(differnce, 4) ,  'Not so significant' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_important_difference_all(df1, df2):\n",
    "    for key_word in ['converion_rate_without_offline_return', 'total_conversion_rate','ave_M', 'ave_M_not_offline_return', 'total_M', 'total_F', 'total_S', 'session_number', 'buy_time_without_offline_return','total_day_using_percentage', 'actually_using_percentage', 'view_per_date', 'view_per_session',\n",
    "       'session_per_date', 'off_return_item_number', 'off_return_frequency', \n",
    "       'off_cart_c', 'off_fav_c', 'off_view_c', 'on_cart_c', 'on_fav_c',\n",
    "       'on_view_c', 'total_cart_c', 'total_fav_c', 'total_view_c',\n",
    "       'viewtime_ave', 'view_time_med', 'total_discount_percentage', 'online_ratio', 'online_ratio_without_offline_return', 'off_mix_c',\n",
    "       'on_mix_c', 'total_mix_c', 'cart_med_time', 'cart_ave_time',\n",
    "       'cart_within_3', 'cart_within_24', 'view_count_med', 'view_count_ave']:\n",
    "        differnce, t = difference_in_rate(df1, df2, key_word)\n",
    "        if abs( t ) > 1.96:\n",
    "            print(key_word, round(differnce, 4)  )\n",
    "        elif  abs( t ) >= 1.5:\n",
    "            print(key_word, round(differnce, 4) ,  'Not so significant' )\n",
    "        else:\n",
    "            print(key_word, round(differnce, 4) ,  'Not significant' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.2258\n",
      "total_conversion_rate 0.2625\n",
      "ave_M 630.057\n",
      "ave_M_not_offline_return 832.6407\n",
      "total_M 2723.1448\n",
      "total_F 0.5703\n",
      "total_S -328.0011\n",
      "session_number -51.5379\n",
      "buy_time_without_offline_return 0.1441\n",
      "total_day_using_percentage -0.0577\n",
      "actually_using_percentage 0.0179\n",
      "view_per_date -2.8865\n",
      "view_per_session -1.8229\n",
      "session_per_date -0.1354\n",
      "off_return_item_number 0.4775\n",
      "off_return_frequency 0.4262\n",
      "off_fav_c -0.0124\n",
      "on_cart_c 0.1322\n",
      "on_fav_c 0.0727\n",
      "on_view_c 0.0728\n",
      "total_cart_c -0.3243\n",
      "total_fav_c -0.0782\n",
      "total_view_c -0.0655\n",
      "viewtime_ave 3.2647\n",
      "view_time_med 4.8789\n",
      "total_discount_percentage 0.005\n",
      "online_ratio -0.7815\n",
      "online_ratio_without_offline_return -0.7942\n",
      "off_mix_c -0.0126\n",
      "on_mix_c 0.1167\n",
      "total_mix_c -0.3285\n",
      "cart_med_time 18718.0155\n",
      "cart_ave_time 17068.7963\n",
      "cart_within_3 -0.3195\n",
      "view_count_med -0.9525\n",
      "view_count_ave -1.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df1 offline, df2 online, df3, df4, df5 view conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008075642857142872, 0.0656, 'inactive user')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(df['total_view_c'], 33), np.nanpercentile(df['total_view_c'], 67), 'inactive user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df3, df4, df5], number_list2, null_df2 = split_by_percentile(df2, 'total_view_c', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4497, 82), (4421, 82), (4594, 82), [0.04, 0.09555259999999999], (23, 82))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape , df4.shape , df5.shape  , number_list2, null_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.1043\n",
      "total_conversion_rate -0.1078\n",
      "ave_M -316.056\n",
      "ave_M_not_offline_return -317.1675\n",
      "total_M -4518.1208\n",
      "total_F -0.9893\n",
      "total_S 435.5347\n",
      "session_number 67.5933\n",
      "buy_time_without_offline_return -0.9743\n",
      "total_day_using_percentage 0.0985\n",
      "actually_using_percentage 0.0567\n",
      "view_per_date 1.8443\n",
      "view_per_session 0.9569\n",
      "session_per_date 0.0941\n",
      "off_cart_c -0.0934\n",
      "off_fav_c -0.0512\n",
      "off_view_c -0.0967\n",
      "on_cart_c -0.3215\n",
      "on_fav_c -0.1361\n",
      "on_view_c -0.2512\n",
      "total_cart_c -0.3291\n",
      "total_fav_c -0.125\n",
      "total_view_c -0.2323\n",
      "viewtime_ave -7.8972\n",
      "view_time_med -8.1997\n",
      "total_discount_percentage 0.0116\n",
      "online_ratio -0.0537\n",
      "online_ratio_without_offline_return -0.0511\n",
      "off_mix_c -0.0932\n",
      "on_mix_c -0.365\n",
      "total_mix_c -0.3653\n",
      "cart_med_time 4810.1133\n",
      "cart_ave_time 4471.6021\n",
      "cart_within_3 -0.0899\n",
      "view_count_med 1.6264\n",
      "view_count_ave 1.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df3, df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.0208\n",
      "total_conversion_rate -0.0213\n",
      "ave_M -303.9562\n",
      "ave_M_not_offline_return -300.196\n",
      "total_M -4801.0222\n",
      "total_F -1.3039\n",
      "total_S 192.4816\n",
      "session_number 24.6455\n",
      "buy_time_without_offline_return -1.2486\n",
      "total_day_using_percentage 0.0356\n",
      "actually_using_percentage 0.031\n",
      "view_per_date 0.839\n",
      "view_per_session 0.472\n",
      "session_per_date 0.029\n",
      "off_return_item_number -0.0638\n",
      "off_return_frequency -0.0553\n",
      "off_cart_c -0.0534\n",
      "off_fav_c -0.048\n",
      "off_view_c -0.0276\n",
      "on_cart_c -0.1508\n",
      "on_fav_c -0.0572\n",
      "on_view_c -0.046\n",
      "total_cart_c -0.1476\n",
      "total_fav_c -0.053\n",
      "total_view_c -0.0416\n",
      "viewtime_ave -2.0993\n",
      "view_time_med -1.7038\n",
      "total_discount_percentage 0.0076\n",
      "online_ratio -0.0195\n",
      "online_ratio_without_offline_return -0.0183\n",
      "off_mix_c -0.0517\n",
      "on_mix_c -0.1618\n",
      "total_mix_c -0.1554\n",
      "cart_med_time 2244.8885\n",
      "cart_ave_time 1182.0008\n",
      "cart_within_3 -0.0218\n",
      "view_count_med 0.9568\n",
      "view_count_ave 0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df3, df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.0835\n",
      "total_conversion_rate -0.0865\n",
      "total_F 0.3146\n",
      "total_S 243.0531\n",
      "session_number 42.9478\n",
      "buy_time_without_offline_return 0.2743\n",
      "total_day_using_percentage 0.0629\n",
      "actually_using_percentage 0.0257\n",
      "view_per_date 1.0054\n",
      "view_per_session 0.4849\n",
      "session_per_date 0.0651\n",
      "off_return_item_number 0.0404\n",
      "off_return_frequency 0.0403\n",
      "off_cart_c -0.04\n",
      "off_view_c -0.0691\n",
      "on_cart_c -0.1708\n",
      "on_fav_c -0.0789\n",
      "on_view_c -0.2053\n",
      "total_cart_c -0.1815\n",
      "total_fav_c -0.072\n",
      "total_view_c -0.1907\n",
      "viewtime_ave -5.7978\n",
      "view_time_med -6.4958\n",
      "total_discount_percentage 0.004\n",
      "online_ratio -0.0342\n",
      "online_ratio_without_offline_return -0.0328\n",
      "off_mix_c -0.0415\n",
      "on_mix_c -0.2032\n",
      "total_mix_c -0.2099\n",
      "cart_med_time 2565.2249\n",
      "cart_ave_time 3289.6013\n",
      "cart_within_3 -0.0681\n",
      "view_count_med 0.6696\n",
      "view_count_ave 0.7415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    " find_important_difference(df4, df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view_conversion_ratedf3, df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRICE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = df['ave_M']\n",
    "X = df['total_discount_percentage']\n",
    "T = np.arctan2(Y,X) # for color value\n",
    "plt.scatter(X, Y, s=75,c=T, alpha=.5)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = df['total_M']\n",
    "X = df['total_discount_percentage']\n",
    "T = np.arctan2(Y,X) # for color value\n",
    "plt.scatter(X, Y, s=75,c=T, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# price_sensitive group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_the_effect_of_price_sensitive(df, p = 0.1):\n",
    "    other_sensitive = df[df['total_discount_percentage'] >=p]\n",
    "    other_normal = df[df['total_discount_percentage'] < p]\n",
    "    print( find_important_difference(other_sensitive, other_normal) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.067\n",
      "total_conversion_rate -0.0782\n",
      "ave_M -1048.197\n",
      "ave_M_not_offline_return -1202.288\n",
      "total_M -6578.1091\n",
      "total_F -1.0153\n",
      "total_S 11.8281 Not so significant\n",
      "session_number 4.6849\n",
      "buy_time_without_offline_return -0.8703\n",
      "total_day_using_percentage -0.0094\n",
      "actually_using_percentage -0.0183\n",
      "view_per_session -0.1097 Not so significant\n",
      "session_per_date 0.028\n",
      "off_return_item_number -0.1845\n",
      "off_return_frequency -0.145\n",
      "off_cart_c -0.0345\n",
      "off_view_c -0.0094\n",
      "on_view_c -0.0418 Not so significant\n",
      "total_cart_c -0.0684\n",
      "total_view_c -0.0109\n",
      "viewtime_ave 3.4797\n",
      "view_time_med 1.5904 Not so significant\n",
      "total_discount_percentage 0.1531\n",
      "off_mix_c -0.0267\n",
      "total_mix_c -0.0479\n",
      "cart_med_time 2380.7779 Not so significant\n",
      "cart_within_3 -0.0528\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_M -669.1478\n",
      "ave_M_not_offline_return -701.3459\n",
      "total_M -2017.8737\n",
      "total_S -58.4754 Not so significant\n",
      "view_per_date -0.3405 Not so significant\n",
      "view_per_session -0.2684 Not so significant\n",
      "total_view_c -0.0008 Not so significant\n",
      "viewtime_ave 2.3555\n",
      "total_discount_percentage 0.1492\n",
      "online_ratio -0.0581\n",
      "online_ratio_without_offline_return -0.051\n",
      "total_mix_c -0.0227\n",
      "cart_med_time -1192.3344 Not so significant\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.0056 Not so significant\n",
      "total_conversion_rate 0.0076\n",
      "ave_M -816.5092\n",
      "ave_M_not_offline_return -843.6505\n",
      "total_M -4908.5528\n",
      "total_F -0.4268 Not so significant\n",
      "total_S -84.8243\n",
      "session_number -7.9026 Not so significant\n",
      "buy_time_without_offline_return -0.4957\n",
      "total_day_using_percentage -0.0136 Not so significant\n",
      "view_per_date -0.6497\n",
      "view_per_session -0.3108\n",
      "session_per_date -0.0344\n",
      "off_return_item_number 0.0812 Not so significant\n",
      "off_return_frequency 0.0689 Not so significant\n",
      "total_cart_c -0.0209 Not so significant\n",
      "total_view_c -0.0014\n",
      "total_discount_percentage 0.1467\n",
      "online_ratio -0.0748\n",
      "online_ratio_without_offline_return -0.0655\n",
      "on_mix_c -0.037\n",
      "total_mix_c -0.0476\n",
      "cart_within_3 0.0237 Not so significant\n",
      "view_count_med 0.1968 Not so significant\n",
      "view_count_ave 0.1887 Not so significant\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.0359\n",
      "total_conversion_rate 0.0369\n",
      "ave_M -966.7364\n",
      "ave_M_not_offline_return -998.4339\n",
      "total_M -6749.0223\n",
      "total_F -1.1052\n",
      "total_S -57.7643\n",
      "session_number -7.248\n",
      "buy_time_without_offline_return -1.1005\n",
      "actually_using_percentage 0.0303\n",
      "view_per_date -0.6943\n",
      "view_per_session -0.3976\n",
      "session_per_date -0.038\n",
      "off_fav_c -0.0585\n",
      "on_cart_c 0.0268\n",
      "on_view_c 0.0758\n",
      "total_view_c 0.0679\n",
      "view_time_med 2.5592 Not so significant\n",
      "total_discount_percentage 0.1431\n",
      "online_ratio -0.0356\n",
      "online_ratio_without_offline_return -0.023 Not so significant\n",
      "cart_ave_time -1037.6839 Not so significant\n",
      "cart_within_3 0.0227 Not so significant\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "look_the_effect_of_price_sensitive(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.6%)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045875397739231646"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(df5['total_discount_percentage'], 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return 0.0354\n",
      "total_conversion_rate 0.0384\n",
      "ave_M -624.7669\n",
      "ave_M_not_offline_return -626.6557\n",
      "total_M 2938.3914\n",
      "total_F 1.8225\n",
      "total_S 87.5151\n",
      "session_number 16.6812\n",
      "buy_time_without_offline_return 1.657\n",
      "total_day_using_percentage 0.0359\n",
      "actually_using_percentage 0.0548\n",
      "view_per_date -0.2244 Not so significant\n",
      "view_per_session -0.2247 Not so significant\n",
      "session_per_date 0.0071 Not significant\n",
      "off_return_item_number 0.1727\n",
      "off_return_frequency 0.1655\n",
      "off_cart_c -0.0003 Not significant\n",
      "off_fav_c -0.0387 Not so significant\n",
      "off_view_c -0.0097 Not significant\n",
      "on_cart_c -0.0071 Not significant\n",
      "on_fav_c -0.0173 Not significant\n",
      "on_view_c 0.0494\n",
      "total_cart_c -0.0239\n",
      "total_fav_c -0.0264 Not so significant\n",
      "total_view_c 0.0331\n",
      "viewtime_ave 3.2129\n",
      "view_time_med 2.0852\n",
      "total_discount_percentage 0.0903\n",
      "online_ratio -0.1099\n",
      "online_ratio_without_offline_return -0.1004\n",
      "off_mix_c -0.0218 Not significant\n",
      "on_mix_c -0.0289\n",
      "total_mix_c -0.0502\n",
      "cart_med_time -561.7518 Not significant\n",
      "cart_ave_time -53.3865 Not significant\n",
      "cart_within_3 -0.0039 Not significant\n",
      "cart_within_24 0.0 Not significant\n",
      "view_count_med -0.0495 Not significant\n",
      "view_count_ave -0.0285 Not significant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "find_important_difference_all(df5[df5['total_discount_percentage'] >= 0.046], df5[df5['total_discount_percentage'] < 0.046])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05547778330369031"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(df1['total_discount_percentage'], 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converion_rate_without_offline_return -0.012 Not significant\n",
      "total_conversion_rate -0.0191 Not so significant\n",
      "ave_M -1185.5791\n",
      "ave_M_not_offline_return -1327.1678\n",
      "total_M -1502.2387\n",
      "total_F 0.6565\n",
      "total_S 33.3761\n",
      "session_number 6.6995\n",
      "buy_time_without_offline_return 0.59\n",
      "total_day_using_percentage 0.0041\n",
      "actually_using_percentage 0.0095\n",
      "view_per_date -0.0972 Not so significant\n",
      "view_per_session -0.1533\n",
      "session_per_date 0.0164\n",
      "off_return_item_number 0.0551\n",
      "off_return_frequency 0.0665\n",
      "off_cart_c -0.0268\n",
      "off_fav_c -0.0099 Not so significant\n",
      "off_view_c -0.0021 Not significant\n",
      "on_cart_c 0.0021 Not significant\n",
      "on_fav_c -0.0077 Not significant\n",
      "on_view_c -0.0057 Not significant\n",
      "total_cart_c 0.0092 Not significant\n",
      "total_fav_c -0.0035 Not significant\n",
      "total_view_c -0.0006 Not significant\n",
      "viewtime_ave 1.6619 Not so significant\n",
      "view_time_med 0.6486 Not significant\n",
      "total_discount_percentage 0.0969\n",
      "online_ratio 0.0032\n",
      "online_ratio_without_offline_return 0.0037\n",
      "off_mix_c -0.0214\n",
      "on_mix_c -0.0251 Not significant\n",
      "total_mix_c -0.0013 Not significant\n",
      "cart_med_time -3982.5887\n",
      "cart_ave_time -3503.8708\n",
      "cart_within_3 0.0599\n",
      "cart_within_24 0.0 Not significant\n",
      "view_count_med -0.0855\n",
      "view_count_ave -0.0532 Not significant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "find_important_difference_all(df1[df1['total_discount_percentage'] >= 0.0555], df1[df1['total_discount_percentage'] < 0.0555])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## online_view_conversion_rate()()!!!\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. (), 2. , 3. , 4. , 5.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1. (), 2. , 3. , 4. , 5.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 25676)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'',df_inactive.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 21804)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'', df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 4497)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'', df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 4421)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'', df4.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 4594)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'', df5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 980)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'', null_df2.shape[0] + df_drop.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('()', 14429)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'()', df_never_buy.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2280.0, 1.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile( df['ave_M'], 50), np.nanpercentile( df['total_F'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24456, 48450)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ave_M']<=2280].shape[0], df[df['total_F']<=1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24347, 27951)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ave_M']>2280].shape[0], df[df['total_F']>1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('memberid', '201803F', '201803M', '201803S', '201904S')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.columns[0], df5.columns[20], df5.columns[34], df5.columns[48], df5.columns[61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'session'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'session'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "11.0\n",
      "12.0\n",
      "10.0\n",
      "17.0\n",
      "10.0\n",
      "9.0\n",
      "11.0\n",
      "17.0\n",
      "12.0\n",
      "19.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "total_session = []\n",
    "for col_name in df.columns[48:62]:\n",
    "    with_session_df = df[df[col_name]>0]\n",
    "    print( np.median(with_session_df[col_name]) )\n",
    "    total_session+= with_session_df[col_name].tolist()\n",
    "    counter += with_session_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.0, 12.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(total_session, 49), np.nanpercentile(total_session, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path propotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(a_dict, percent = True, return_count = False):\n",
    "    def pathname(from_,to):\n",
    "        return \"{}\".format(from_) + \" to \" \"{}\".format(to)\n",
    "    #dict, ex: 1->6,2->6  \n",
    "    path_dict = {}\n",
    "\n",
    "    #\n",
    "    last_classification = 0\n",
    "\n",
    "    #iterate through every list in the group\n",
    "    for i in a_dict.values():\n",
    "        #iterate every classification in each member in the group\n",
    "        first = True\n",
    "        for j in i:     \n",
    "            #\n",
    "            if(first):\n",
    "                last_classification = j\n",
    "                first = False    \n",
    "                continue\n",
    "            \n",
    "            #ex: {5 to 6 : 1} 56\n",
    "            else:\n",
    "                #count+1\n",
    "                try:\n",
    "                    path_dict.update( { pathname(last_classification,j) : path_dict[pathname(last_classification,j)] + 1 } )\n",
    "                #1\n",
    "                except:\n",
    "                    path_dict.update( { pathname(last_classification,j) : 1 } )\n",
    "                last_classification = j\n",
    "        \n",
    "    path_divided_by_classification_proportion = {}\n",
    "    \n",
    "    #from_count classification  Ex : 5 to 12 ,5 to 6 3  from count{ 5 : 2+3}\n",
    "    from_count = {}\n",
    "\n",
    "    for key, value in path_dict.items():\n",
    "        try:\n",
    "            from_count.update({str.split(key)[0] : from_count[str.split(key)[0]]+value})\n",
    "        except: #dictkey\n",
    "            from_count.update({str.split(key)[0] : value})\n",
    "            \n",
    "    for key, value in path_dict.items():\n",
    "        for from_key, from_count_value in from_count.items():\n",
    "            if(str.split(key)[0]==from_key):\n",
    "                path_divided_by_classification_proportion.update({key : (value/from_count_value)})\n",
    "    all_data = []    \n",
    "    last_item = -1\n",
    "    tem_data = dict()\n",
    "    for i in  sorted(path_divided_by_classification_proportion.keys()):\n",
    "        if percent:\n",
    "            ratio = '%0.2f%%' %(path_divided_by_classification_proportion[i]*100)\n",
    "        else:\n",
    "            ratio =(path_divided_by_classification_proportion[i])\n",
    "        item = int(i[5])\n",
    "        if item <= last_item:\n",
    "            all_data.append(tem_data)\n",
    "            tem_data = dict()\n",
    "        tem_data[item] = ratio\n",
    "        last_item = item\n",
    "    all_data.append(tem_data)\n",
    "    if return_count:\n",
    "        return pd.DataFrame(all_data), from_count\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "0112()212()3,4,5,6FM(FM)3FM4FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_group_to_dict_of_path(df, percent = True):\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "        a_dict_for_markov[memberID] = [0]*14\n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 session\n",
    "            34+j  M\n",
    "            20+J  F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            if  S == 0:\n",
    "                continue\n",
    "            elif  F == 0:\n",
    "                a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "            elif M_ave <= 2280 and F<= 1:\n",
    "                a_dict_for_markov[memberID][j] = 5\n",
    "            elif M_ave > 2280 and F<= 1:\n",
    "                a_dict_for_markov[memberID][j] = 4\n",
    "            elif M_ave <= 2280 and F > 1:\n",
    "                a_dict_for_markov[memberID][j] = 6\n",
    "            elif M_ave > 2280 and F > 1:\n",
    "                a_dict_for_markov[memberID][j] = 3\n",
    "        \n",
    "        \n",
    "    return path(a_dict_for_markov, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "path_df = from_group_to_dict_of_path(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.24%</td>\n",
       "      <td>10.47%</td>\n",
       "      <td>3.65%</td>\n",
       "      <td>1.31%</td>\n",
       "      <td>3.51%</td>\n",
       "      <td>4.50%</td>\n",
       "      <td>1.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.13%</td>\n",
       "      <td>37.03%</td>\n",
       "      <td>16.77%</td>\n",
       "      <td>1.91%</td>\n",
       "      <td>6.34%</td>\n",
       "      <td>7.00%</td>\n",
       "      <td>1.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.16%</td>\n",
       "      <td>23.93%</td>\n",
       "      <td>40.17%</td>\n",
       "      <td>4.91%</td>\n",
       "      <td>8.71%</td>\n",
       "      <td>7.85%</td>\n",
       "      <td>4.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.37%</td>\n",
       "      <td>11.16%</td>\n",
       "      <td>24.72%</td>\n",
       "      <td>24.25%</td>\n",
       "      <td>14.71%</td>\n",
       "      <td>10.06%</td>\n",
       "      <td>8.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.91%</td>\n",
       "      <td>25.68%</td>\n",
       "      <td>30.02%</td>\n",
       "      <td>9.14%</td>\n",
       "      <td>12.38%</td>\n",
       "      <td>6.37%</td>\n",
       "      <td>3.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.01%</td>\n",
       "      <td>29.09%</td>\n",
       "      <td>29.01%</td>\n",
       "      <td>4.01%</td>\n",
       "      <td>6.51%</td>\n",
       "      <td>12.15%</td>\n",
       "      <td>5.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.49%</td>\n",
       "      <td>17.47%</td>\n",
       "      <td>31.49%</td>\n",
       "      <td>8.61%</td>\n",
       "      <td>7.10%</td>\n",
       "      <td>13.58%</td>\n",
       "      <td>13.26%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6\n",
       "0  75.24%  10.47%   3.65%   1.31%   3.51%   4.50%   1.32%\n",
       "1  29.13%  37.03%  16.77%   1.91%   6.34%   7.00%   1.83%\n",
       "2  10.16%  23.93%  40.17%   4.91%   8.71%   7.85%   4.27%\n",
       "3   6.37%  11.16%  24.72%  24.25%  14.71%  10.06%   8.72%\n",
       "4  12.91%  25.68%  30.02%   9.14%  12.38%   6.37%   3.49%\n",
       "5  14.01%  29.09%  29.01%   4.01%   6.51%  12.15%   5.21%\n",
       "6   8.49%  17.47%  31.49%   8.61%   7.10%  13.58%  13.26%"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09827479196358788"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df1['buy_time_without_offline_return']) / sum( df1['session_number'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive Their merged conversion rate is:31.18%.\n",
      "Their median of conversion rate is:0.00%.   The path:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1      2      3      4      5      6\n",
      "0  88.02%   7.30%  1.41%  0.28%  1.14%  1.47%  0.37%\n",
      "1  77.82%  18.59%  2.12%  0.13%  0.47%  0.72%  0.14%\n",
      "2  76.25%  18.08%  4.17%  0.07%  0.49%  0.84%  0.09%\n",
      "3  75.96%  13.71%  1.01%  1.91%  1.57%  3.71%  2.13%\n",
      "4  76.80%  17.78%  1.83%  0.33%  1.26%  1.26%  0.74%\n",
      "5  77.35%  18.71%  1.33%  0.19%  0.59%  1.35%  0.49%\n",
      "6  76.63%  15.86%  1.50%  0.67%  1.00%  3.01%  1.34%\n",
      "\n",
      "never_buy Their merged conversion rate is:0.00%.\n",
      "Their median of conversion rate is:0.00%.   The path:\n",
      "        0       1       2\n",
      "0  78.65%  13.39%   7.96%\n",
      "1  32.99%  45.08%  21.93%\n",
      "2  16.43%  32.86%  50.71%\n",
      "\n",
      "offline Their merged conversion rate is:9.83%.\n",
      "Their median of conversion rate is:13.33%.   The path:\n",
      "        0       1       2       3      4       5       6\n",
      "0  79.90%   7.49%   2.35%   1.72%  3.68%   3.31%   1.55%\n",
      "1  30.71%  41.43%  14.43%   2.11%  4.72%   4.56%   2.04%\n",
      "2  10.44%  22.57%  44.53%   3.84%  7.43%   7.25%   3.94%\n",
      "3  12.91%  15.81%  21.59%  17.00%  9.91%   9.60%  13.18%\n",
      "4  17.46%  26.96%  27.39%   6.02%  8.12%   8.43%   5.62%\n",
      "5  16.91%  28.58%  29.25%   3.93%  5.43%   9.54%   6.37%\n",
      "6  13.69%  18.74%  23.76%   7.83%  6.71%  12.24%  17.03%\n",
      "\n",
      " Their merged conversion rate is:2.48%.\n",
      "Their median of conversion rate is:2.67%.   The path:\n",
      "        0       1       2      3       4       5       6\n",
      "0  66.55%  12.56%  11.85%  0.85%   2.86%   4.23%   1.11%\n",
      "1  19.68%  33.77%  34.30%  0.65%   3.82%   6.74%   1.04%\n",
      "2   4.95%  14.43%  57.87%  1.47%   7.63%  11.50%   2.15%\n",
      "3   2.56%   8.65%  43.48%  7.06%  14.01%  13.28%  10.96%\n",
      "4   5.85%  14.18%  55.03%  2.92%   8.58%   9.81%   3.62%\n",
      "5   6.67%  15.88%  55.59%  1.97%   4.58%  10.92%   4.39%\n",
      "6   3.11%   7.69%  45.73%  5.36%   7.92%  18.63%  11.57%\n",
      "\n",
      " Their merged conversion rate is:4.38%.\n",
      "Their median of conversion rate is:4.69%.   The path:\n",
      "        0       1       2       3       4       5       6\n",
      "0  69.20%  12.88%   7.68%   1.25%   3.69%   4.16%   1.14%\n",
      "1  22.73%  36.29%  24.46%   1.44%   6.01%   7.71%   1.36%\n",
      "2   7.22%  18.28%  46.24%   3.90%  10.22%  10.38%   3.76%\n",
      "3   2.69%   8.01%  35.14%  18.05%  15.37%  10.32%  10.42%\n",
      "4   6.63%  17.48%  42.62%   6.49%  13.07%   8.92%   4.80%\n",
      "5   8.27%  20.17%  42.48%   3.75%   6.94%  13.23%   5.16%\n",
      "6   3.61%   9.17%  35.91%   8.95%   8.23%  16.56%  17.57%\n",
      "\n",
      " Their merged conversion rate is:7.30%.\n",
      "Their median of conversion rate is:8.33%.   The path:\n",
      "        0       1       2       3       4       5       6\n",
      "0  75.24%  10.47%   3.65%   1.31%   3.51%   4.50%   1.32%\n",
      "1  29.13%  37.03%  16.77%   1.91%   6.34%   7.00%   1.83%\n",
      "2  10.16%  23.93%  40.17%   4.91%   8.71%   7.85%   4.27%\n",
      "3   6.37%  11.16%  24.72%  24.25%  14.71%  10.06%   8.72%\n",
      "4  12.91%  25.68%  30.02%   9.14%  12.38%   6.37%   3.49%\n",
      "5  14.01%  29.09%  29.01%   4.01%   6.51%  12.15%   5.21%\n",
      "6   8.49%  17.47%  31.49%   8.61%   7.10%  13.58%  13.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df_never_buy, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive','never_buy', 'offline', '', '', '']\n",
    "\n",
    "for i in range(6):\n",
    "    conversion_r = sum(to_be_printed_df[i]['buy_time_without_offline_return']) / sum( to_be_printed_df[i]['session_number'] )\n",
    "    print(to_be_printed_df_name[i],  'Their merged conversion rate is:%0.2f%%.' %(conversion_r*100)) \n",
    "    print( 'Their median of conversion rate is:%0.2f%%.   The path:'  % (np.nanmedian(to_be_printed_df[i]['converion_rate_without_offline_return'])*100))\n",
    "    print(from_group_to_dict_of_path(to_be_printed_df[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_randomly(a_list):\n",
    "    random_v = random()\n",
    "    new = 0\n",
    "\n",
    "    for i in range( len(a_list) ):\n",
    "        new += a_list[i] \n",
    "        if random_v <= new:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_confusion_metrrix(df, n_month = 13):\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    test_dict = dict()\n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "        a_dict_for_markov[memberID] = [0]*n_month\n",
    "        test_dict[memberID] = [0]*(14-n_month)\n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 session\n",
    "            34+j  M\n",
    "            +J  F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            \n",
    "            if j+1 > n_month:\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    test_dict[memberID][j-n_month] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 3\n",
    "            else:\n",
    "                \n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 3\n",
    "                \n",
    "    a_df = path(a_dict_for_markov, False)\n",
    "    a_dict_for_predict = dict() # \n",
    "    \n",
    "    for i in range(7):\n",
    "        a_dict_for_predict[i] = list( a_df.iloc[i, :] )\n",
    "        \n",
    "\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    " \n",
    "    for key in test_dict.keys():\n",
    "        last = a_dict_for_markov[key][-1]\n",
    "        next_ = test_dict[key][0]\n",
    "\n",
    "        \n",
    "        # update martix\n",
    "        true_list.append(next_)\n",
    "        pred_list.append( pred_randomly(a_dict_for_predict[last])  )\n",
    "        \n",
    "        if n_month == 12:\n",
    "            last = test_dict[key][0]\n",
    "            next_ = test_dict[key][1]\n",
    "            \n",
    "\n",
    "            true_list.append(next_)\n",
    "            pred_list.append( pred_randomly(a_dict_for_predict[last])  )\n",
    "\n",
    "    return true_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.8710    0.9117     24518\n",
      "           1     0.0411    0.1000    0.0582       860\n",
      "           2     0.0000    0.0000    0.0000        83\n",
      "           3     0.0000    0.0000    0.0000        27\n",
      "           4     0.0034    0.0156    0.0056        64\n",
      "           5     0.0026    0.0108    0.0042        93\n",
      "           6     0.0000    0.0000    0.0000        31\n",
      "\n",
      "   micro avg     0.8351    0.8351    0.8351     25676\n",
      "   macro avg     0.1433    0.1425    0.1400     25676\n",
      "weighted avg     0.9146    0.8351    0.8725     25676\n",
      "\n",
      "\n",
      "offline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5165    0.6054    0.5574      8708\n",
      "           1     0.3146    0.2585    0.2838      5411\n",
      "           2     0.2812    0.3136    0.2965      3138\n",
      "           3     0.0394    0.0387    0.0390       724\n",
      "           4     0.0691    0.0524    0.0596      1413\n",
      "           5     0.0786    0.0557    0.0652      1580\n",
      "           6     0.0816    0.0735    0.0773       830\n",
      "\n",
      "   micro avg     0.3626    0.3626    0.3626     21804\n",
      "   macro avg     0.1973    0.1997    0.1970     21804\n",
      "weighted avg     0.3394    0.3626    0.3486     21804\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4880    0.4709    0.4793       996\n",
      "           1     0.2703    0.2158    0.2400       987\n",
      "           2     0.4716    0.5229    0.4959      1746\n",
      "           3     0.0164    0.0204    0.0182        49\n",
      "           4     0.0802    0.0854    0.0827       246\n",
      "           5     0.0743    0.0724    0.0733       387\n",
      "           6     0.0268    0.0349    0.0303        86\n",
      "\n",
      "   micro avg     0.3665    0.3665    0.3665      4497\n",
      "   macro avg     0.2039    0.2032    0.2028      4497\n",
      "weighted avg     0.3620    0.3665    0.3630      4497\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5278    0.5216    0.5247      1275\n",
      "           1     0.2896    0.2601    0.2741      1011\n",
      "           2     0.3724    0.3771    0.3747      1265\n",
      "           3     0.0763    0.0692    0.0726       130\n",
      "           4     0.0793    0.0959    0.0868       271\n",
      "           5     0.0979    0.1135    0.1051       326\n",
      "           6     0.0676    0.0699    0.0687       143\n",
      "\n",
      "   micro avg     0.3363    0.3363    0.3363      4421\n",
      "   macro avg     0.2158    0.2153    0.2152      4421\n",
      "weighted avg     0.3415    0.3363    0.3386      4421\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5907    0.6018    0.5962      1856\n",
      "           1     0.3188    0.2791    0.2976      1125\n",
      "           2     0.2562    0.2761    0.2658       746\n",
      "           3     0.0977    0.1062    0.1018       160\n",
      "           4     0.0778    0.0775    0.0776       271\n",
      "           5     0.0708    0.0772    0.0738       298\n",
      "           6     0.0690    0.0725    0.0707       138\n",
      "\n",
      "   micro avg     0.3718    0.3718    0.3718      4594\n",
      "   macro avg     0.2116    0.2129    0.2119      4594\n",
      "weighted avg     0.3730    0.3718    0.3720      4594\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive', 'offline', '', '', '']\n",
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    true_list, pred_list = test_confusion_metrrix(to_be_printed_df[i], n_month = 13)\n",
    "    print( classification_report(true_list, pred_list,   digits = 4))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_confusion_metrrix_seperated(df):\n",
    "    n_month = 13\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    test_dict = dict()\n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "        a_dict_for_markov[memberID] = [0]*n_month\n",
    "        test_dict[memberID] = [0]*(14-n_month)\n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 session\n",
    "            34+j  M\n",
    "            +J  F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            \n",
    "            if j+1 > n_month:\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    test_dict[memberID][j-n_month] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 3\n",
    "            else:\n",
    "                \n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 3\n",
    "                \n",
    "    a_df = path(a_dict_for_markov, False)\n",
    "    a_dict_for_predict = dict() # \n",
    "    true_dict = dict()\n",
    "    pred_dict = dict()\n",
    "    for i in range(7):\n",
    "        a_dict_for_predict[i] = list( a_df.iloc[i, :] )\n",
    "\n",
    "        true_dict[i] = []\n",
    "        pred_dict[i] = []\n",
    "\n",
    "    for key in test_dict.keys():\n",
    "        last = a_dict_for_markov[key][-1]\n",
    "        next_ = test_dict[key][0]\n",
    "\n",
    "        \n",
    "        # update martix\n",
    "        true_dict[last].append(next_)\n",
    "        pred_dict[last].append( pred_randomly(a_dict_for_predict[last])  )\n",
    "    \n",
    "\n",
    "    return true_dict, pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "true_dict, pred_dict = test_confusion_metrrix_seperated(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.8719    0.9142     23344\n",
      "           1     0.0236    0.0640    0.0344       703\n",
      "           2     0.0088    0.0476    0.0149        63\n",
      "           3     0.0000    0.0000    0.0000        21\n",
      "           4     0.0000    0.0000    0.0000        56\n",
      "           5     0.0052    0.0253    0.0086        79\n",
      "           6     0.0000    0.0000    0.0000        24\n",
      "\n",
      "   micro avg     0.8400    0.8400    0.8400     24290\n",
      "   macro avg     0.1426    0.1441    0.1389     24290\n",
      "weighted avg     0.9242    0.8400    0.8797     24290\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8547    0.7815    0.8165       888\n",
      "           1     0.1270    0.1935    0.1534       124\n",
      "           2     0.0952    0.1429    0.1143        14\n",
      "           3     0.0000    0.0000    0.0000         4\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "           5     0.0000    0.0000    0.0000         6\n",
      "           6     0.0000    0.0000    0.0000         3\n",
      "\n",
      "   micro avg     0.6923    0.6923    0.6923      1040\n",
      "   macro avg     0.1538    0.1597    0.1549      1040\n",
      "weighted avg     0.7462    0.6923    0.7170      1040\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8226    0.6800    0.7445        75\n",
      "           1     0.0588    0.1000    0.0741        10\n",
      "           2     0.0000    0.0000    0.0000         3\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           4     0.0000    0.0000    0.0000         0\n",
      "           5     0.0000    0.0000    0.0000         1\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.5778    0.5778    0.5778        90\n",
      "   macro avg     0.1259    0.1114    0.1169        90\n",
      "weighted avg     0.6920    0.5778    0.6287        90\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6190    0.7647    0.6842        17\n",
      "           1     0.0000    0.0000    0.0000         1\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "           4     0.0000    0.0000    0.0000         3\n",
      "           5     0.0000    0.0000    0.0000         3\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.4815    0.4815    0.4815        27\n",
      "   macro avg     0.1032    0.1275    0.1140        27\n",
      "weighted avg     0.3898    0.4815    0.4308        27\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8421    0.7805    0.8101        82\n",
      "           1     0.1765    0.2727    0.2143        11\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           4     0.0000    0.0000    0.0000         2\n",
      "           5     0.0000    0.0000    0.0000         2\n",
      "           6     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.6837    0.6837    0.6837        98\n",
      "   macro avg     0.1698    0.1755    0.1707        98\n",
      "weighted avg     0.7244    0.6837    0.7019        98\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8875    0.8068    0.8452        88\n",
      "           1     0.0000    0.0000    0.0000         8\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.7172    0.7172    0.7172        99\n",
      "   macro avg     0.1775    0.1614    0.1690        99\n",
      "weighted avg     0.7889    0.7172    0.7513        99\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7600    0.7917    0.7755        24\n",
      "           1     0.0000    0.0000    0.0000         3\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "           5     0.0000    0.0000    0.0000         2\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.5938    0.5938    0.5938        32\n",
      "   macro avg     0.1267    0.1319    0.1293        32\n",
      "weighted avg     0.5700    0.5938    0.5816        32\n",
      "\n",
      "\n",
      "offline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5910    0.8087    0.6829      5610\n",
      "           1     0.1790    0.0762    0.1069      1587\n",
      "           2     0.0046    0.0036    0.0040       277\n",
      "           3     0.0195    0.0120    0.0149       249\n",
      "           4     0.0793    0.0376    0.0510       692\n",
      "           5     0.1028    0.0358    0.0532       809\n",
      "           6     0.0452    0.0262    0.0332       267\n",
      "\n",
      "   micro avg     0.4977    0.4977    0.4977      9491\n",
      "   macro avg     0.1459    0.1429    0.1352      9491\n",
      "weighted avg     0.3957    0.4977    0.4312      9491\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3632    0.3177    0.3389      1901\n",
      "           1     0.4207    0.4113    0.4159      2237\n",
      "           2     0.1283    0.1625    0.1434       603\n",
      "           3     0.0145    0.0206    0.0170        97\n",
      "           4     0.0648    0.0734    0.0688       218\n",
      "           5     0.0611    0.0773    0.0682       207\n",
      "           6     0.0111    0.0114    0.0112        88\n",
      "\n",
      "   micro avg     0.3097    0.3097    0.3097      5351\n",
      "   macro avg     0.1519    0.1535    0.1519      5351\n",
      "weighted avg     0.3248    0.3097    0.3164      5351\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0907    0.0917    0.0912       349\n",
      "           1     0.2120    0.2162    0.2141       754\n",
      "           2     0.4297    0.4331    0.4314      1503\n",
      "           3     0.0547    0.0583    0.0565       120\n",
      "           4     0.0864    0.0784    0.0822       268\n",
      "           5     0.0656    0.0675    0.0665       237\n",
      "           6     0.0299    0.0258    0.0277       155\n",
      "\n",
      "   micro avg     0.2640    0.2640    0.2640      3386\n",
      "   macro avg     0.1384    0.1387    0.1385      3386\n",
      "weighted avg     0.2620    0.2640    0.2630      3386\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2029    0.1346    0.1618       104\n",
      "           1     0.1414    0.1707    0.1547        82\n",
      "           2     0.2195    0.2328    0.2259       116\n",
      "           3     0.1500    0.1348    0.1420        89\n",
      "           4     0.0938    0.1224    0.1062        49\n",
      "           5     0.0526    0.0392    0.0449        51\n",
      "           6     0.1500    0.1935    0.1690        62\n",
      "\n",
      "   micro avg     0.1573    0.1573    0.1573       553\n",
      "   macro avg     0.1443    0.1469    0.1435       553\n",
      "weighted avg     0.1593    0.1573    0.1561       553\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2723    0.1775    0.2149       293\n",
      "           1     0.2329    0.2336    0.2333       321\n",
      "           2     0.2156    0.2828    0.2447       244\n",
      "           3     0.0392    0.0323    0.0354        62\n",
      "           4     0.0900    0.1084    0.0984        83\n",
      "           5     0.0521    0.0575    0.0546        87\n",
      "           6     0.0137    0.0159    0.0147        63\n",
      "\n",
      "   micro avg     0.1847    0.1847    0.1847      1153\n",
      "   macro avg     0.1308    0.1297    0.1280      1153\n",
      "weighted avg     0.1929    0.1847    0.1852      1153\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2551    0.1582    0.1953       316\n",
      "           1     0.2575    0.2687    0.2630       320\n",
      "           2     0.2099    0.2744    0.2379       277\n",
      "           3     0.2333    0.1522    0.1842        46\n",
      "           4     0.0141    0.0175    0.0156        57\n",
      "           5     0.0492    0.0588    0.0536       102\n",
      "           6     0.0606    0.0635    0.0620        63\n",
      "\n",
      "   micro avg     0.1948    0.1948    0.1948      1181\n",
      "   macro avg     0.1542    0.1419    0.1445      1181\n",
      "weighted avg     0.2045    0.1948    0.1952      1181\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2188    0.1556    0.1818       135\n",
      "           1     0.1800    0.1636    0.1714       110\n",
      "           2     0.1411    0.1949    0.1637       118\n",
      "           3     0.0926    0.0820    0.0870        61\n",
      "           4     0.0545    0.0652    0.0594        46\n",
      "           5     0.1204    0.1494    0.1333        87\n",
      "           6     0.1593    0.1364    0.1469       132\n",
      "\n",
      "   micro avg     0.1466    0.1466    0.1466       689\n",
      "   macro avg     0.1381    0.1353    0.1348       689\n",
      "weighted avg     0.1533    0.1466    0.1477       689\n",
      "\n",
      "\n",
      "\n",
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6635    0.6635    0.6635       630\n",
      "           1     0.2154    0.1618    0.1848       173\n",
      "           2     0.0261    0.0441    0.0328        68\n",
      "           3     0.0000    0.0000    0.0000         8\n",
      "           4     0.0370    0.0417    0.0392        24\n",
      "           5     0.0606    0.0513    0.0556        39\n",
      "           6     0.1250    0.1111    0.1176         9\n",
      "\n",
      "   micro avg     0.4763    0.4763    0.4763       951\n",
      "   macro avg     0.1611    0.1534    0.1562       951\n",
      "weighted avg     0.4852    0.4763    0.4799       951\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2406    0.1948    0.2153       231\n",
      "           1     0.3866    0.2958    0.3352       409\n",
      "           2     0.2012    0.2969    0.2399       229\n",
      "           3     0.0000    0.0000    0.0000         3\n",
      "           4     0.0256    0.0400    0.0312        25\n",
      "           5     0.0462    0.0484    0.0472        62\n",
      "           6     0.0000    0.0000    0.0000         6\n",
      "\n",
      "   micro avg     0.2466    0.2466    0.2466       965\n",
      "   macro avg     0.1286    0.1251    0.1241       965\n",
      "weighted avg     0.2728    0.2466    0.2544       965\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0581    0.0595    0.0588        84\n",
      "           1     0.1793    0.1799    0.1796       289\n",
      "           2     0.5849    0.5771    0.5810      1116\n",
      "           3     0.0000    0.0000    0.0000        20\n",
      "           4     0.0979    0.0909    0.0943       154\n",
      "           5     0.0977    0.0991    0.0984       212\n",
      "           6     0.0000    0.0000    0.0000        33\n",
      "\n",
      "   micro avg     0.3857    0.3857    0.3857      1908\n",
      "   macro avg     0.1454    0.1438    0.1446      1908\n",
      "weighted avg     0.3906    0.3857    0.3881      1908\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         4\n",
      "           1     0.1429    0.2500    0.1818         4\n",
      "           2     0.4706    0.2963    0.3636        27\n",
      "           3     0.0000    0.0000    0.0000         3\n",
      "           4     0.2000    0.1667    0.1818         6\n",
      "           5     0.1111    0.5000    0.1818         2\n",
      "           6     0.0000    0.0000    0.0000         4\n",
      "\n",
      "   micro avg     0.2200    0.2200    0.2200        50\n",
      "   macro avg     0.1321    0.1733    0.1299        50\n",
      "weighted avg     0.2940    0.2200    0.2400        50\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0769    0.0667    0.0714        15\n",
      "           1     0.2143    0.1667    0.1875        36\n",
      "           2     0.5804    0.5856    0.5830       111\n",
      "           3     0.1250    0.1667    0.1429         6\n",
      "           4     0.0588    0.0417    0.0488        24\n",
      "           5     0.0000    0.0000    0.0000        15\n",
      "           6     0.0000    0.0000    0.0000         2\n",
      "\n",
      "   micro avg     0.3541    0.3541    0.3541       209\n",
      "   macro avg     0.1508    0.1468    0.1476       209\n",
      "weighted avg     0.3610    0.3541    0.3567       209\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        26\n",
      "           1     0.2041    0.1562    0.1770        64\n",
      "           2     0.5130    0.6037    0.5546       164\n",
      "           3     0.0000    0.0000    0.0000         5\n",
      "           4     0.0000    0.0000    0.0000         6\n",
      "           5     0.1842    0.1556    0.1687        45\n",
      "           6     0.0000    0.0000    0.0000        21\n",
      "\n",
      "   micro avg     0.3505    0.3505    0.3505       331\n",
      "   macro avg     0.1287    0.1308    0.1286       331\n",
      "weighted avg     0.3187    0.3505    0.3320       331\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         6\n",
      "           1     0.0000    0.0000    0.0000        12\n",
      "           2     0.3571    0.4839    0.4110        31\n",
      "           3     0.0000    0.0000    0.0000         4\n",
      "           4     0.1111    0.1429    0.1250         7\n",
      "           5     0.1111    0.1667    0.1333        12\n",
      "           6     0.4286    0.2727    0.3333        11\n",
      "\n",
      "   micro avg     0.2530    0.2530    0.2530        83\n",
      "   macro avg     0.1440    0.1523    0.1432        83\n",
      "weighted avg     0.2156    0.2530    0.2275        83\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7031    0.6864    0.6947       880\n",
      "           1     0.1753    0.1256    0.1463       215\n",
      "           2     0.0112    0.0161    0.0132        62\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.0333    0.0741    0.0460        27\n",
      "           5     0.1034    0.1364    0.1176        44\n",
      "           6     0.0000    0.0000    0.0000        12\n",
      "\n",
      "   micro avg     0.5136    0.5136    0.5136      1246\n",
      "   macro avg     0.1466    0.1484    0.1454      1246\n",
      "weighted avg     0.5318    0.5136    0.5217      1246\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2617    0.2121    0.2343       264\n",
      "           1     0.4511    0.3897    0.4181       426\n",
      "           2     0.2314    0.2719    0.2500       217\n",
      "           3     0.0000    0.0000    0.0000        11\n",
      "           4     0.0545    0.0857    0.0667        35\n",
      "           5     0.0241    0.0455    0.0315        44\n",
      "           6     0.0000    0.0000    0.0000         9\n",
      "\n",
      "   micro avg     0.2843    0.2843    0.2843      1006\n",
      "   macro avg     0.1461    0.1436    0.1429      1006\n",
      "weighted avg     0.3125    0.2843    0.2962      1006\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0957    0.1000    0.0978        90\n",
      "           1     0.2122    0.2039    0.2080       255\n",
      "           2     0.4607    0.4315    0.4456       679\n",
      "           3     0.0351    0.0417    0.0381        48\n",
      "           4     0.0719    0.0948    0.0818       116\n",
      "           5     0.0496    0.0511    0.0504       137\n",
      "           6     0.0577    0.0566    0.0571        53\n",
      "\n",
      "   micro avg     0.2736    0.2736    0.2736      1378\n",
      "   macro avg     0.1404    0.1399    0.1398      1378\n",
      "weighted avg     0.2870    0.2736    0.2799      1378\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         1\n",
      "           1     0.0769    0.1111    0.0909         9\n",
      "           2     0.2162    0.2286    0.2222        35\n",
      "           3     0.3333    0.2143    0.2609        28\n",
      "           4     0.3810    0.2963    0.3333        27\n",
      "           5     0.0714    0.1111    0.0870         9\n",
      "           6     0.0714    0.0833    0.0769        12\n",
      "\n",
      "   micro avg     0.2066    0.2066    0.2066       121\n",
      "   macro avg     0.1643    0.1492    0.1530       121\n",
      "weighted avg     0.2428    0.2066    0.2199       121\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0526    0.0588    0.0556        17\n",
      "           1     0.2381    0.2381    0.2381        42\n",
      "           2     0.4706    0.4528    0.4615       106\n",
      "           3     0.0000    0.0000    0.0000        16\n",
      "           4     0.1622    0.2308    0.1905        26\n",
      "           5     0.0588    0.0400    0.0476        25\n",
      "           6     0.0714    0.1111    0.0870         9\n",
      "\n",
      "   micro avg     0.2780    0.2780    0.2780       241\n",
      "   macro avg     0.1505    0.1617    0.1543       241\n",
      "weighted avg     0.2785    0.2780    0.2771       241\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0690    0.1111    0.0851        18\n",
      "           1     0.1290    0.1481    0.1379        54\n",
      "           2     0.3884    0.3672    0.3775       128\n",
      "           3     0.0000    0.0000    0.0000         9\n",
      "           4     0.1667    0.1034    0.1277        29\n",
      "           5     0.2857    0.2326    0.2564        43\n",
      "           6     0.0556    0.0667    0.0606        15\n",
      "\n",
      "   micro avg     0.2399    0.2399    0.2399       296\n",
      "   macro avg     0.1563    0.1470    0.1493       296\n",
      "weighted avg     0.2564    0.2399    0.2464       296\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         5\n",
      "           1     0.0833    0.1000    0.0909        10\n",
      "           2     0.2553    0.3158    0.2824        38\n",
      "           3     0.0667    0.0833    0.0741        12\n",
      "           4     0.0714    0.0909    0.0800        11\n",
      "           5     0.3125    0.2083    0.2500        24\n",
      "           6     0.2174    0.1515    0.1786        33\n",
      "\n",
      "   micro avg     0.1880    0.1880    0.1880       133\n",
      "   macro avg     0.1438    0.1357    0.1366       133\n",
      "weighted avg     0.2015    0.1880    0.1902       133\n",
      "\n",
      "\n",
      "\n",
      "0               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7077    0.7710    0.7380      1297\n",
      "           1     0.1350    0.0833    0.1030       264\n",
      "           2     0.0141    0.0179    0.0157        56\n",
      "           3     0.0000    0.0000    0.0000        22\n",
      "           4     0.0274    0.0333    0.0301        60\n",
      "           5     0.1059    0.0811    0.0918       111\n",
      "           6     0.0000    0.0000    0.0000        32\n",
      "\n",
      "   micro avg     0.5613    0.5613    0.5613      1842\n",
      "   macro avg     0.1414    0.1409    0.1398      1842\n",
      "weighted avg     0.5254    0.5613    0.5414      1842\n",
      "\n",
      "\n",
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3280    0.2939    0.3100       347\n",
      "           1     0.3948    0.3431    0.3671       443\n",
      "           2     0.1087    0.1389    0.1220       144\n",
      "           3     0.0000    0.0000    0.0000        15\n",
      "           4     0.0137    0.0196    0.0161        51\n",
      "           5     0.0141    0.0196    0.0164        51\n",
      "           6     0.0455    0.0833    0.0588        12\n",
      "\n",
      "   micro avg     0.2606    0.2606    0.2606      1063\n",
      "   macro avg     0.1292    0.1284    0.1272      1063\n",
      "weighted avg     0.2882    0.2606    0.2730      1063\n",
      "\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0676    0.0847    0.0752        59\n",
      "           1     0.2660    0.2404    0.2525       208\n",
      "           2     0.4361    0.4080    0.4216       326\n",
      "           3     0.0244    0.0294    0.0267        34\n",
      "           4     0.0806    0.0746    0.0775        67\n",
      "           5     0.0615    0.0952    0.0748        42\n",
      "           6     0.0323    0.0333    0.0328        30\n",
      "\n",
      "   micro avg     0.2598    0.2598    0.2598       766\n",
      "   macro avg     0.1383    0.1380    0.1373       766\n",
      "weighted avg     0.2758    0.2598    0.2671       766\n",
      "\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1667    0.0833    0.1111        24\n",
      "           1     0.1000    0.0606    0.0755        33\n",
      "           2     0.2545    0.3043    0.2772        46\n",
      "           3     0.2391    0.2895    0.2619        38\n",
      "           4     0.1200    0.1304    0.1250        23\n",
      "           5     0.0476    0.0588    0.0526        17\n",
      "           6     0.0833    0.1000    0.0909        10\n",
      "\n",
      "   micro avg     0.1780    0.1780    0.1780       191\n",
      "   macro avg     0.1445    0.1467    0.1420       191\n",
      "weighted avg     0.1702    0.1780    0.1704       191\n",
      "\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1667    0.1613    0.1639        31\n",
      "           1     0.1692    0.2000    0.1833        55\n",
      "           2     0.2794    0.3220    0.2992        59\n",
      "           3     0.0556    0.0370    0.0444        27\n",
      "           4     0.0667    0.0667    0.0667        30\n",
      "           5     0.0000    0.0000    0.0000        17\n",
      "           6     0.0000    0.0000    0.0000        12\n",
      "\n",
      "   micro avg     0.1645    0.1645    0.1645       231\n",
      "   macro avg     0.1054    0.1124    0.1082       231\n",
      "weighted avg     0.1492    0.1645    0.1559       231\n",
      "\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2439    0.1370    0.1754        73\n",
      "           1     0.2766    0.3377    0.3041        77\n",
      "           2     0.1889    0.2361    0.2099        72\n",
      "           3     0.0000    0.0000    0.0000        10\n",
      "           4     0.0417    0.0370    0.0392        27\n",
      "           5     0.0909    0.0909    0.0909        44\n",
      "           6     0.1500    0.1765    0.1622        17\n",
      "\n",
      "   micro avg     0.1906    0.1906    0.1906       320\n",
      "   macro avg     0.1417    0.1450    0.1402       320\n",
      "weighted avg     0.1887    0.1906    0.1848       320\n",
      "\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3077    0.1600    0.2105        25\n",
      "           1     0.1667    0.1111    0.1333        45\n",
      "           2     0.1429    0.2326    0.1770        43\n",
      "           3     0.0556    0.0714    0.0625        14\n",
      "           4     0.0769    0.0769    0.0769        13\n",
      "           5     0.0000    0.0000    0.0000        16\n",
      "           6     0.1765    0.1200    0.1429        25\n",
      "\n",
      "   micro avg     0.1326    0.1326    0.1326       181\n",
      "   macro avg     0.1323    0.1103    0.1147       181\n",
      "weighted avg     0.1521    0.1326    0.1344       181\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    true_dict, pred_dict = test_confusion_metrrix_seperated(to_be_printed_df[i])\n",
    "    for i in range(len(true_dict)):\n",
    "        true_list, pred_list = true_dict[i], pred_dict[i]\n",
    "        print(i, classification_report(true_list, pred_list,   digits = 4))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chi2(df, n_month = 13, cut_first_month = False):\n",
    "    a_dict_for_markov = dict() # 'id: [] shape of 1*14'\n",
    "    test_dict = dict()\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        memberID = str( df.iloc[i,0] )\n",
    "\n",
    "        a_dict_for_markov[memberID] = [0]*n_month\n",
    "        test_dict[memberID] = [0]*(15-n_month)\n",
    "\n",
    "            \n",
    "        for j in range(14): \n",
    "            '''\n",
    "            48+j, j = 0,1,...13 session\n",
    "            34+j  M\n",
    "            20+J  F\n",
    "            '''\n",
    "            S = df.iloc[i,48+j]\n",
    "            M =  df.iloc[i,34+j]\n",
    "            F =  df.iloc[i,20+j]\n",
    "            M_ave = M/F\n",
    "            \n",
    "            if j > n_month - 2 :\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    test_dict[memberID][j-n_month] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    test_dict[memberID][j-n_month] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    test_dict[memberID][j-n_month] = 3\n",
    "          \n",
    "            if j < n_month  :\n",
    "                if  S == 0:\n",
    "                    continue\n",
    "                elif  F == 0:\n",
    "                    a_dict_for_markov[memberID][j] = 1 if S < 12 else 2\n",
    "                elif M_ave <= 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 5\n",
    "                elif M_ave > 2280 and F<= 1:\n",
    "                    a_dict_for_markov[memberID][j] = 4\n",
    "                elif M_ave <= 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 6\n",
    "                elif M_ave > 2280 and F > 1:\n",
    "                    a_dict_for_markov[memberID][j] = 3\n",
    "                    \n",
    "        if cut_first_month:\n",
    "            a_dict_for_markov[memberID] = a_dict_for_markov[memberID][1:]\n",
    "            \n",
    "    a_df = path(a_dict_for_markov, False)\n",
    "    test_df, cnt =  path(test_dict, False, True)\n",
    "    \n",
    "    return a_df, test_df, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "def chi2(a_df, test_df, n_dict, print_out = False):\n",
    "    \n",
    "    for i in range(len(n_dict)):\n",
    "        n = n_dict[str(i)]\n",
    "        \n",
    "        expected = np.array( a_df.iloc[i,:] * n )\n",
    "        true = np.array( test_df.iloc[i,:] * n )\n",
    "        chi, p = chisquare( true, expected  )\n",
    "        \n",
    "        if print_out:\n",
    "            print(i, 'p value =', p)\n",
    "            print( true - expected   )\n",
    "            continue\n",
    "            \n",
    "        if p < 0.01:\n",
    "            error = list(  (expected-true) )\n",
    "            max_ = max(error)\n",
    "            min_ = min(error)\n",
    "            idx1, idx2 = error.index(max_),  error.index(min_)\n",
    "            print(i, 'is not the same distribution. The reason is %d greater than expected(%0.2f) and %d is smaller(%0.2f)'%(idx1, max_,idx2,min_ ) )\n",
    "            \n",
    "        elif p<0.05:\n",
    "            error = list(  (expected-true) )\n",
    "            max_ = max(error)\n",
    "            min_ = min(error)\n",
    "            idx1, idx2 = error.index(max_),  error.index(min_)\n",
    "            print(i, '%0.3f is p value, might be the same distribution. %d greater than expected(%0.2f) and %d is smaller(%0.2f)'%(p,idx1, max_,idx2,min_ ) )\n",
    "        else:\n",
    "            print(i, 'is the same distribution.')\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is not the same distribution. The reason is 1 greater than expected(1002.68) and 0 is smaller(-1944.87)\n",
      "1 is not the same distribution. The reason is 1 greater than expected(37.91) and 0 is smaller(-36.02)\n",
      "2 is the same distribution.\n",
      "3 is the same distribution.\n",
      "4 is the same distribution.\n",
      "5 is the same distribution.\n",
      "6 is the same distribution.\n",
      "\n",
      "offline\n",
      "0 is not the same distribution. The reason is 0 greater than expected(1458.70) and 1 is smaller(-1297.80)\n",
      "1 is not the same distribution. The reason is 2 greater than expected(50.34) and 5 is smaller(-68.11)\n",
      "2 is not the same distribution. The reason is 1 greater than expected(106.33) and 2 is smaller(-105.29)\n",
      "3 is not the same distribution. The reason is 2 greater than expected(36.68) and 0 is smaller(-158.75)\n",
      "4 is not the same distribution. The reason is 1 greater than expected(161.75) and 0 is smaller(-456.48)\n",
      "5 is not the same distribution. The reason is 1 greater than expected(246.92) and 0 is smaller(-557.64)\n",
      "6 is not the same distribution. The reason is 1 greater than expected(69.68) and 0 is smaller(-157.92)\n",
      "\n",
      "\n",
      "0 is not the same distribution. The reason is 2 greater than expected(37.26) and 1 is smaller(-109.82)\n",
      "1 is not the same distribution. The reason is 2 greater than expected(60.61) and 1 is smaller(-84.71)\n",
      "2 is not the same distribution. The reason is 5 greater than expected(37.45) and 2 is smaller(-106.48)\n",
      "3 is not the same distribution. The reason is 5 greater than expected(1.80) and 0 is smaller(-6.92)\n",
      "4 is not the same distribution. The reason is 5 greater than expected(18.59) and 2 is smaller(-18.29)\n",
      "5 0.033 is p value, might be the same distribution. 3 greater than expected(5.76) and 0 is smaller(-13.52)\n",
      "6 is not the same distribution. The reason is 2 greater than expected(6.82) and 0 is smaller(-6.57)\n",
      "\n",
      "\n",
      "0 is not the same distribution. The reason is 5 greater than expected(35.56) and 1 is smaller(-103.91)\n",
      "1 is not the same distribution. The reason is 5 greater than expected(27.33) and 1 is smaller(-65.24)\n",
      "2 is not the same distribution. The reason is 0 greater than expected(30.13) and 2 is smaller(-97.68)\n",
      "3 is the same distribution.\n",
      "4 is not the same distribution. The reason is 1 greater than expected(12.37) and 3 is smaller(-9.45)\n",
      "5 is not the same distribution. The reason is 1 greater than expected(22.20) and 0 is smaller(-16.55)\n",
      "6 is not the same distribution. The reason is 5 greater than expected(8.52) and 6 is smaller(-8.71)\n",
      "\n",
      "\n",
      "0 is not the same distribution. The reason is 0 greater than expected(105.77) and 1 is smaller(-157.83)\n",
      "1 is not the same distribution. The reason is 0 greater than expected(59.63) and 1 is smaller(-31.80)\n",
      "2 is not the same distribution. The reason is 1 greater than expected(32.35) and 2 is smaller(-27.91)\n",
      "3 is not the same distribution. The reason is 5 greater than expected(6.29) and 0 is smaller(-12.80)\n",
      "4 is not the same distribution. The reason is 1 greater than expected(18.96) and 0 is smaller(-25.10)\n",
      "5 is not the same distribution. The reason is 2 greater than expected(46.25) and 0 is smaller(-71.68)\n",
      "6 is not the same distribution. The reason is 2 greater than expected(14.83) and 0 is smaller(-21.23)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive', 'offline', '', '', '']\n",
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    a_df, test_df, n = test_chi2(to_be_printed_df[i])\n",
    "    chi2(a_df, test_df, n)\n",
    "    \n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inactive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p value = 2.6353512376900167e-306\n",
      "[ 1944.8682519  -1002.68297461  -297.16043191   -55.04906811\n",
      "  -219.04223031  -297.5649097    -73.36863726]\n",
      "1 p value = 5.15442587375762e-05\n",
      "[ 36.02281044 -37.90622756  -8.49936733  -0.05878732   6.853083\n",
      "   1.76491912   1.82356965]\n",
      "2 p value = nan\n",
      "[-0.18617933 -1.10527318 -0.47610889         nan  0.58918713  0.30477822\n",
      "  0.93679802]\n",
      "3 p value = nan\n",
      "[0.38238702 0.21436848        nan 1.53070684        nan        nan\n",
      "        nan]\n",
      "4 p value = nan\n",
      "[  6.96991847 -10.49732921          nan   2.78408771   1.20832162\n",
      "   0.20832162   0.51419736]\n",
      "5 p value = nan\n",
      "[  7.29205255 -11.60650442  -0.24186948   2.81972862   1.45918587\n",
      "          nan   1.55933664]\n",
      "6 p value = nan\n",
      "[ 0.23156089 -1.97169811  0.54802744  0.78730703         nan  0.09605489\n",
      "  0.60120069]\n",
      "\n",
      "offline\n",
      "0 p value = 0.0\n",
      "[-1458.70177302  1297.80185979   147.29487263   -40.69537513\n",
      "    -8.3453175     55.70621527     6.93951796]\n",
      "1 p value = 1.8053408700130813e-08\n",
      "[-39.0524869   -2.10638681 -50.33783784 -34.35512794  61.04290412\n",
      "  68.10574453  -3.29680917]\n",
      "2 p value = 1.0168488869548697e-07\n",
      "[ -51.17109437 -106.32652657  105.29183188   -5.52180809   12.46570182\n",
      "   48.78370341   -3.52180809]\n",
      "3 p value = 1.0217836386201128e-66\n",
      "[158.74713271 -17.96613872 -36.68214091 -34.56635718 -10.36045877\n",
      " -23.69142545 -35.48061169]\n",
      "4 p value = 2.0197175777301004e-227\n",
      "[ 456.4797663  -161.74602629 -127.77111436  -36.95274508  -33.0604863\n",
      "  -63.30956268  -33.6398316 ]\n",
      "5 p value = 0.0\n",
      "[ 5.57639462e+02 -2.46921146e+02 -2.34505478e+02 -1.11585713e+01\n",
      "  3.05150548e-01 -5.01249245e+01 -1.52344923e+01]\n",
      "6 p value = 6.581819188388974e-59\n",
      "[157.92379679 -69.67780749 -47.28475936  -2.2473262    7.29679144\n",
      " -38.30882353  -7.70187166]\n",
      "\n",
      "\n",
      "0 p value = 1.2067868934427665e-25\n",
      "[-33.00351391 109.81756955 -37.25534407  -4.4579795  -13.72796486\n",
      " -16.21698389  -5.15578331]\n",
      "1 p value = 3.1195778958604785e-06\n",
      "[-16.79515685  84.70776004 -60.60550358  -2.73571822  -3.00198129\n",
      "  -2.81397909   1.24457898]\n",
      "2 p value = 5.610089270197762e-05\n",
      "[-19.27987088 -21.80885405 106.4842979    0.67110906 -21.44961955\n",
      " -37.4522481   -7.16481439]\n",
      "3 p value = 3.2481320888851084e-08\n",
      "[ 6.91958495 -1.25810636 -0.97276265 -0.49546044 -0.92736706 -1.8002594\n",
      " -1.46562905]\n",
      "4 p value = 0.00012937214610978006\n",
      "[  9.84113093  -9.36216762  18.290138    -1.20363514   3.38269943\n",
      " -18.59171996  -2.35644564]\n",
      "5 p value = 0.03256337869431789\n",
      "[13.5206017   1.50752126 -4.82799215 -5.76193591 -3.47678221  3.49051668\n",
      " -4.45192937]\n",
      "6 p value = 0.0005334771826530521\n",
      "[ 6.57344398 -0.20912863 -6.82406639 -0.63900415 -4.78008299  4.72780083\n",
      "  1.15103734]\n",
      "\n",
      "\n",
      "0 p value = 2.095964068244448e-26\n",
      "[ -0.97601933 103.91132453 -10.51555503 -15.67746877 -31.52993165\n",
      " -35.56322178  -9.64912798]\n",
      "1 p value = 1.3613509562055747e-05\n",
      "[-11.21739994  65.23696494   4.78528156  -5.86026418 -21.35693713\n",
      " -27.32982421  -4.25782103]\n",
      "2 p value = 9.217300504809814e-07\n",
      "[-30.13203763 -13.98630516  97.68446535 -14.78454835 -25.41720847\n",
      "  -3.85468253  -9.50968322]\n",
      "3 p value = 0.539343130319814\n",
      "[ 2.33908046  0.54022989  1.75287356  4.98850575 -3.35057471 -4.67241379\n",
      " -1.59770115]\n",
      "4 p value = 0.009022973341810084\n",
      "[  9.10442795 -12.37471206   0.71922191   9.45124136  -9.7911441\n",
      "   5.06987458  -2.17890965]\n",
      "5 p value = 0.001305965787836245\n",
      "[ 16.55141509 -22.1995283   -1.31933962  -3.37877358   3.01037736\n",
      "   0.1740566    7.16179245]\n",
      "6 p value = 0.007857124156567625\n",
      "[ 6.84993998 -4.30432173  0.81272509 -0.78931573 -2.75930372 -8.51860744\n",
      "  8.70888355]\n",
      "\n",
      "\n",
      "0 p value = 5.396760152739762e-32\n",
      "[-105.7707917   157.83351268   -9.61921599   -0.39477325  -34.55203689\n",
      "   -8.60122982    1.10453497]\n",
      "1 p value = 2.7777956940222076e-09\n",
      "[-59.62716763  31.80057803  15.62283237  10.99855491 -18.15751445\n",
      "  -4.28612717  23.64884393]\n",
      "2 p value = 0.0007024428618374386\n",
      "[-21.41672458 -32.34769516  27.91104934   9.0196896   -5.97475098\n",
      "  11.8637943   10.94463748]\n",
      "3 p value = 0.0013610076248341864\n",
      "[12.80168776 -1.87763713 -5.66244726 -1.49367089  3.03375527 -6.28691983\n",
      " -0.51476793]\n",
      "4 p value = 7.362862929753037e-06\n",
      "[ 25.10277861 -18.95637885 -15.18255154  -1.29040932  -3.43979683\n",
      "   9.91574544   3.85061249]\n",
      "5 p value = 4.970512230606552e-35\n",
      "[ 71.68235978 -37.0749782  -46.24818367   4.78901482  -1.87939552\n",
      "   8.23307178   0.49811101]\n",
      "6 p value = 3.468173282927711e-10\n",
      "[ 21.23404255 -10.80425532 -14.82553191  -2.03829787   2.21276596\n",
      "  -2.57446809   6.79574468]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_be_printed_df = [df_inactive, df1, df3, df4, df5]\n",
    "to_be_printed_df_name= ['inactive', 'offline', '', '', '']\n",
    "\n",
    "for i in range(5):\n",
    "    print(to_be_printed_df_name[i])\n",
    "    a_df, test_df, n = test_chi2(to_be_printed_df[i])\n",
    "    chi2(a_df, test_df, n, True)\n",
    "    \n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
